TODO
-----

NOW: 

[ ] "monitor": database ...
     [ ] status -- put periodic information in database about state of watched processes
     [ ] memcached + monitor: store something in memcached at same time as put in database, so 
         query about latest status can be done instantly using memcached if in cache.
     [ ] add support to admin.py to easily query the database:
           - list of running processes and last status
           - status of lifetime of process
           - should use memcache too, so must use clear API defined in monitor.py
     [ ] create query that will be used by backend to determine which
         sage_server to use, and use that -- might choose based on
         lowest load, etc.
     [ ] create query that will be used by backend to determine which
         memcache server to use??? or does this make sense -- just give all of them as a pool and let it decide.
     [ ] add support to admin.py to clean out old entries from the
         database, i.e., something like capped collection via a delete call: calls db.cap_table somehow...


SOON:

   [ ] setup a VPN and deploy something...

   [ ] fix this, which is caused by postgresql[0].createdb('monitor') in config1.py:
 8787 | postgresql-0.log | 2012-08-08 11:18:05.854365 | STATEMENT:  CREATE DATABASE monitor;
 8786 | postgresql-0.log | 2012-08-08 11:18:05.854365 | ERROR:  database "monitor" already exists

   [ ] decide on what computers to buy from Dell to deploy in a few weeks

   [ ] update apple dev network account and make a first PhoneGap app for iphone
   [ ] make a first PhoneGap app for iphone

   [ ] database: function to check validity of entries; if anything not current, then updated.

   [ ] database: table of connected browers and which tornado server they are connected to

   [ ] admin: make it so this doesn't happen every time: 
          INFO:root:running 'sudo cp /var/folders/fc/tdg_b00d2rv0_0c940cxttjc0000gp/T/tmp3XEkwZ data/haproxy-0.conf'
  
   [ ] tornado: implement sending message to any connected browser, possibly connected to a different tornado

   [ ] sage_server: "./config1 --restart=sage_server" doesn't work
   [ ] sage_server: sage_server.py dies when run in daemon mode -- for now just run as subproc, but need to fix this
   [ ] sage_server/tornado: range(10^4 ) *reliably* fails to get the final I/O terminate message through from tornado to browser.
   [ ] sage_server: specify tornado sage_servers by putting them in a config file, which the
       tornado monitors for changes (via file descriptor)
   [ ] sage_server: when sage_server.py killed, it doesn't properly clean up the processes that it forked off.   
   [ ] sage_server: max limit on number of simultaneous sage_server processes allowed by sage_server server
   [ ] sage_server: sudo sage_server.py -- executing commands doesn't work at all on Linux
       (but does on OS X), so probably a resource issue?

   [ ] tornado: dropbox oauth: dropbox too 
   [ ] haproxy: this line in haproxy conf looks wrong/misleading since I settled on a file, right? 
             #daemon   -- commented out so I can just log to stdout 
   [ ] haproxy: two different haproxies at once (so either can be used if the other dies)
   [ ] logging: format for date part of every log message, so in
       database the time when log row was *record* could be set,
       instead of the time of insertion in DB.  
   [ ] browser/sage_server/tornado: interacts
   [ ] browser/sage_server/tornado: 2d graphics
   [ ] tornado/database: shortened url database
   [ ] I didn't build openVPN with LZO, but I should so all network traffic is compressed, saving money.
   [ ] come up with deployment plan
   [ ] setup openVPN
   [ ] admin: make default admin import less verbose
     [ ] decide on what computers to buy...

VAGUE:



   [ ] sqlalchemy postgresql central DB server
        - do test: what is overhead of storing a BLOB of a git bundle?
   [ ] scalability test: using sage_server.py, but running on a different VM
   [ ] scalability test: test using tornado.py(s), also running on different VM's
   [ ] think about how to separate my data into multiple database for scalability
   [ ] multiple haproxies for high availability:
    - do what stackoverflow does: heartbeat + haproxy: http://blog.stackoverflow.com/2010/01/stack-overflow-network-configuration/; http://www.linux-ha.org/wiki/Main_Page
    - this discussion says to use "DNS failover":  
        * http://www.webhostingtalk.com/archive/index.php/t-1117385.html
        * http://www.dnsmadeeasy.com/
    - this page talks about round robin DNS, which seems sensible to me:
      http://blog.engelke.com/2011/06/07/web-resilience-with-round-robin-dns/
   [ ] reduce number of mime types in nginx.conf, since I will barely serve anything??
   [ ] move all certfile generation stuff to a single master control / launcher module
   [ ] startup time -- after fork even after importing sage -- is *very* slow.  Fix.
   [ ] make it so client knows port of server?
   [ ] sage_server.py -- anti DOS measures (from users on own machine?)
   [ ] configuration framework
   [ ] rewrite reset_all_accounts/reset_account to use that sage_server.py is root.
   [ ] log server going down is *fatal* to sage_server

DONE:
   [x] tornado: decide on way for any tornado to send a message to any connected
       user, possibly connected to a different tornado:
       Proposal 2 (accepted):
         - tornados will have token from database
         - add to ioloop listening on SSL+TCP socket (encrypted); only accept connection when given token
         - send ProtoBuf messages
         - connection terminated if no messages sent over it for t seconds
         - *maybe* connections proxied through haproxy, so that tornado is not actually on an external network.
           I don't know if using haproxy is needed or a good idea; it is a small detail in the implementation.
       Proposal 1 (rejected):
         - tornados will have access to a token they read from database, which they know but
           not publicly available (since tornados have to be able to get personal user data, 
           the database must support this).
         - Add another url handler:  /message
            POST message with variables:
                 token: the token
                 message: the message, as a ProtoBuf -- the message format should have user id of recipient as part of message
         - haproxy will also map 
                /tornado[n]/... to the n-th tornado.
         - each tornado has an id number (the n above)
         - tornado communication will go via stunnel, so is secure
           outside of LAN, where it matters
         - messages might suggest pulling down static web content (e.g, describing an image), 
           and url will be /tornado[n]/static/[id].[ext]
         Thoughts: the above seems untenable because of the overhead in estabilishing a complete 
         HTTPS connection for every single message. 
   [x] tornado: find a way to move the code for "Persistent connections to sage_servers" into another file (like
       is done with "Authentication with Facebook, Google, and DropBox (TODO)")
   [x] yes, use a vpn???
         I'm thinking about how to structure services, define their location,
         make it so every service can connect to every other one, etc. 
         One possibility is that I setup a VPN connecting all the
         physical sites.   Hmmm.  
         It looks like openVPN is a good choice. 
            http://openvpn.net/index.php/open-source/overview.html
         It takes only a few seconds to build from source.  It's small.  The documentation
         seems excellent.  And using this will make it so I can easily use exactly one
         config script to manage all the sites at once, that any node can talk to any 
         other node, while they are all still behind a layer of security (not directly
         on the web), etc. 
   [x] add openvpn to build.py -- easy to build on linux; not sure how yet on OS X!
   [x] tornado: postgresql async client for tornado -- needed to
       implement tornado socket communication (just a little), and
       will be generally very important.   This is the canonical
       solution, but might be substantial work to implement with sqlalchemy
           https://gist.github.com/861193
       Another possibility that looks better:
           [x] do not use SQLalchemy at all (sad, but I have only written
               a few lines in logwatch.py so far in my newest version, so this
               shouldn't be hard).
           [x] Directly use psycopg2 (which has builtin async support) and 
               momoko which officially supports using PostgreSQL + Tornado.
       This would explicitly tie us to PostgreSQL.
    
    [x] tornado communication system working with ports hardcoded and no encryption
    [x] tornado communication system with encryption
    [x] html: make "Thyme" name clear.

   [x] haproxy: put in a port 80 redirect to port 443
       XX sadly, haproxy alone *can't* do this -- http://www.mentby.com/Group/haproxy/http-https-redirects.html
       XX but haproxy + nginx should be able to, but that is complicated.
       ---> we will in the long run have a canonical site name, so let's just make that work with a template.
   [x] admin: config1 --status should default to status=all.
   [x] admin: redo the very limited use of templates to use python standard library templates.
   [x] haproxy, etc.: clean up specification of ports, especially for haproxy -- should be part of Process creation, not a file -- template the conf
   [x] admin: rename "backned" to "tornado_server"/Tornado, sage_server to sage_server/Sage
   [x] rename backend_sage to tornado_sage; rename backend_mesg to tornado_mesg
   [x] rebrand to "salvus"
   [x] gracefully degrade when memcached dies: this is evidently 100% automatic by the client! WOW
   [x] tornado: should degrade gracefully when sage server vanishes...
   [x] obtain an SSL certificate for https://salvusmath.com
         https://wiki.cac.washington.edu/display/infra/UW+Certificate+Services
       * Don't use UW's because their FAQ says: "Will all UW web servers
         eventually get certs from the UW Services CA?  No, not at
         all. Even when the UW Services CA expands its scope there
         will be many cases where it is still appropriate for a web
         server to use a certificate from a commercial CA. For
         example, if a web server has many users from outside the UW
         it will probably want to use a commercial CA certificate."
       * Good instructions: http://clearcove.ca/2010/11/how-to-secure-a-rails-app-on-heroku-with-ssl-firesheep/
       * Googling "godaddy ssl" really does provide a $12.99 deal for a year certificate!

   [x] delete thyme gmail account (see msecure)
   [x] create salvusmath gmail account
   [x] change github repo to be called salvus (instead of sagews)
   [x] massive renames and moves

   [x] get everything to work after the big rename: just rebuild.
   [x] clean checkout and build on linux

   [x] Address this comment I found: "Site note: our 2gb VPS's memcahed is set up to accept over 40k requests. The default setting in memcached is 1024 which is WAY too low."
           http://blog.dpn.name/asyncronous-memcache-driver-for-tornado

   [x] async tornado memcached:  
           Solution: https://github.com/dpnova/tornado-memcache
         Add to build system.

   [x] check-in upstream source tar.bz2's to github repo.
   [x] switch to using tornado-memcache client in tornado_server.py
   [x] Salvus favicon
   [x] salv.us certificate
   [x] need to use namespace for my use of memcached in tornado_server.py
   [x] decided not to add in-process ram cache to tornado_server that I check first, since this could easily lead to using up all available RAM if not implemented sensibly, and doing this sensibly is really complicated.
           
[...x] monitor database:
     [x] rename logwatch.py to monitor.py
     [x] change docs to indicate what monitor.py does
     [x] fix this doc, which must be wrong since we don't use sqlalchemy anymore:
           "SQLalchemy description of database server, e.g., postgresql://user@hostname:port/dbname"
     [x] instead of putting the log in "log" database, put it in log table in monitor database
     [x] add cap_table function in db.py, which deletes all but most recent entries from a table
     [x] code to define new monitoring table schemas:
services:
  - id - unique sequential integer
  - type - string: one of 'nginx', 'haproxy', 'sage', 'tornado', 'stunnel', 'openvpn', 'memcached', 'postgresql'
  - site - string: where this service is physically located
  - address - string (ip address or hostname)
  - port - integer  
  - running - boolean
  - user
  - pid
  - monitor_pid

status:
  - id -- unique id of service entry above
  - timestamp -- timestamp
  - load - integer
  - percent_mem -- float
  - percent_cpu -- float
  - cputime -- float
  - walltime -- float (etime in ps output)
  - virtual_size -- integer
  - resident_size -- integer

     [x] monitor: change to use -- options since - options are too short

   [x] "Failed to commit log messages to database (invalid byte sequence for encoding "UTF8": 0x8d)"
       Seen when doing 
            sudo ./monitor.py --debug --logfile data/logs/haproxy-0.log --database "dbname=monitor user=wstein" --pidfile data/pids/haproxy-0-log.pid --interval 6 --target_pidfile data/pids/haproxy-0.pid --target_name haproxy --target_address localhost --target_port 8000

     [x] add address command line option to monitor.py, which gives
         the address and port that the service listens on: 
           "--address 10.7.1.5 --port 6000 --site padelford".  This will get entered into the
         database when process starts.  When this happens, we will also 
         get the unique id that corresponds to this service, which will be used
         by the monitor for all future db interaction.  
     [x] make a command line option for when info is put in database
     [x] service startup -- put data in database
     [x] when monitored process terminates, update the corresponding entry (using id)
         to set running to false
