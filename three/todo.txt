Programming Todo
----------------

NOW: 

   [ ] backend: implement sendingmessage to any connected user,
       possibly connected to a different backend:
       [x] backend communication system working with ports hardcoded and no encryption
       [x] backend communication system with encryption
       [ ] backend comm: move ports to database

SOON:
   [ ] backend: postgresql async client for tornado -- needed to
       implement backend socket communication (just a little), and
       will be generally very important.   This is the canonical
       solution, but might be substantial work to implement with sqlalchemy
           https://gist.github.com/861193
   [ ] backend: find a way to move the code for "Persistent connections to workers" into another file (like
       is done with "Authentication with Facebook, Google, and DropBox (TODO)")
   [ ] admin: make default admin import less verbose
   [ ] worker: worker.py dies when run in daemon mode -- for now just run as subproc, but need to fix this
   [ ] worker/backend: range(10^4 ) *reliably* fails to get the final I/O terminate message through from backend to browser.
   [ ] worker: specify backend workers by putting them in a config file, which the
       backend monitors for changes (via file descriptor)
   [ ] worker: when worker.py killed, it doesn't properly clean up the processes that it forked off.   
   [ ] worker: "./config1 --restart=worker" doesn't work
   [ ] worker: max limit on number of simultaneous worker processes allowed by worker server
   [ ] worker: sudo worker.py -- executing commands doesn't work at all on Linux
       (but does on OS X), so probably a resource issue?
   [ ] backend: dropbox oauth: dropbox too 
   [ ] haproxy: this line in haproxy conf looks wrong/misleading since I settled on a file, right? 
             #daemon   -- commented out so I can just log to stdout 
   [ ] haproxy, etc.: clean up specification of ports, especially for haproxy -- should be part of Process creation, not a file -- template the conf!
   [ ] haproxy: two different haproxies at once (so either can be used if the other dies)
   [ ] logging: format for date part of every log message, so in
       database the time when log row was *record* could be set,
       instead of the time of insertion in DB.  
   [ ] browser/worker/backend: interacts
   [ ] browser/worker/backend: 2d graphics
   [ ] backend/database: shortened url database

VAGUE:
   [ ] sqlalchemy postgresql central DB server
        - do test: what is overhead of storing a BLOB of a git bundle?
   [ ] scalability test: using worker.py, but running on a different VM
   [ ] scalability test: test using backend.py(s), also running on different VM's
   [ ] think about how to separate my data into multiple database for scalability
   [ ] multiple haproxies for high availability:
    - do what stackoverflow does: heartbeat + haproxy: http://blog.stackoverflow.com/2010/01/stack-overflow-network-configuration/; http://www.linux-ha.org/wiki/Main_Page
    - this discussion says to use "DNS failover":  
        * http://www.webhostingtalk.com/archive/index.php/t-1117385.html
        * http://www.dnsmadeeasy.com/
    - this page talks about round robin DNS, which seems sensible to me:
      http://blog.engelke.com/2011/06/07/web-resilience-with-round-robin-dns/
   [ ] reduce number of mime types in nginx.conf, since I will barely serve anything??
   [ ] move all certfile generation stuff to a single master control / launcher module
   [ ] startup time -- after fork even after importing sage -- is *very* slow.  Fix.
   [ ] make it so client knows port of server?
   [ ] worker.py -- anti DOS measures (from users on own machine?)
   [ ] configuration framework
   [ ] rewrite reset_all_accounts/reset_account to use that worker.py is root.
   [ ] log server going down is *fatal* to worker

DONE:
   [x] backend: decide on way for any backend to send a message to any connected
       user, possibly connected to a different backend:
       Proposal 2 (accepted):
         - backends will have token from database
         - add to ioloop listening on SSL+TCP socket (encrypted); only accept connection when given token
         - send ProtoBuf messages
         - connection terminated if no messages sent over it for t seconds
         - *maybe* connections proxied through haproxy, so that backend is not actually on an external network.
           I don't know if using haproxy is needed or a good idea; it is a small detail in the implementation.
       Proposal 1 (rejected):
         - backends will have access to a token they read from database, which they know but
           not publicly available (since backends have to be able to get personal user data, 
           the database must support this).
         - Add another url handler:  /message
            POST message with variables:
                 token: the token
                 message: the message, as a ProtoBuf -- the message format should have user id of recipient as part of message
         - haproxy will also map 
                /backend[n]/... to the n-th backend.
         - each backend has an id number (the n above)
         - backend communication will go via stunnel, so is secure
           outside of LAN, where it matters
         - messages might suggest pulling down static web content (e.g, describing an image), 
           and url will be /backend[n]/static/[id].[ext]
         Thoughts: the above seems untenable because of the overhead in estabilishing a complete 
         HTTPS connection for every single message. 
