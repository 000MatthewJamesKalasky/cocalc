[x] proper basic worker.py logging
[x] fix Ctrl-D EOF bug in worker.py -- process gets left running full steam on EOF
[x] worker: forked process gets left as a zombie when it quits; fix this.
[x] implement auth token for worker
[x] user switching: How will this work?  
* It runs as either root or normal user
* Imports the sage library
* Client connects to socket
* Fork
* If running as root, change to user:
        import os, pwd
        if os.system('whoami') == 'root'
            user = 'sagews'
            os.setegid(pwd.getpwnam(user)[3])
            os.seteuid(pwd.getpwnam(user)[2])
  * then, fix any environment and PATH issues, e.g., DOT_SAGE
* If running as normal user, just gets new session as usual, running
  as same user as the server
[x] worker.py -- list of users for switching (command line option)
[x] todos near /tmp/xyz
[x] fix: server terminates when any client disconnects if we don't ignore SIGCHLD.

[x] clients must be killed after n seconds (another limit):
      - use a separate thread in the worker root process
      - it will check every n seconds to see if anything needs to be killed:
           use the Connection object
      - if so, sends SIGQUIT, SIGKILL, etc. 

[x] when main server terminates, it needs to kill the other thread that is watching
    for connections to kill.

[x] clean up certfile in worker a bit

[x] limiting memory usage doesn't work at all:
  -- this is a well-known OS X "bug"/feature?
   sage: import resource
sage: resource.setrlimit(resource.RLIMIT_DATA, (10,10))
sage: v = range(10^9)
/Users/wstein/sage/build/sage-5.0/spkg/bin/sage: line 311: 51632 Killed: 9               sage-ipython "$@" -i

This works perfectly on Linux:

  megs=1000; resource.setrlimit(resource.RLIMIT_AS, (megs * 1048576L, -1L))
[x] create basic launcher / master control script
-- ensure data directory exist and has right permissions
-- read configuration file
-- start relevant services on various machines:
   - haproxy
   - nginx
   - postgreSQL server
   - memcached
   - backend(s)
   - worker(s)


[x] build system working on linux
[x] serve static files with nginx
[x] haproxy to nginx
[x] psql database

[x] simple tornado+sockjs+haproxy demo
[x] simple load balancing + haproxy + sockjs demo
[x] move the one static file to nginx instead of tornado
   [x] optparse backend.py
   [x] new file: sagews.conf 
   [x] move conf files to a subdirectory conf/
   [x] rename "launch.py" to "admin.py". 

   [x] base class functionality for each component:
          * start(which='all')
          * status(which='all')
          * stop(which='all')
   [x] refactor existing code to work as above 

   [x] read about multiple ip addresses for one name (=round robin dns)
   [x] read through admin.py cleaning up; finish implementing postgresql options command
   [x] test starting/stopping haproxy, nginx, and database, and creating database
   [x] properly daemonize backend
   [x] admin: support start/stop/status backend
   [x] LOGGING THINKING: I've spent a while now thinking about logging, and have
       changed my mind about what I want to do.  
         * get rid of log.py; it is potentially too low performance and is
           tied to Python.
         * do what is suggested on stackoverflow: "Write locally to
           disk, then batch insert to the database periodically
           (e.g. at log rollover time). Do that in a separate,
           low-priority process. More efficient and more
           robust... (Make sure that your database log table contains
           a column for "which machine the log event came from" by the
           way - very handy!)": http://stackoverflow.com/questions/290304/is-writing-server-log-files-to-a-database-a-good-idea
         * Why *not* to log directly to a database: http://stackoverflow.com/questions/209497/using-a-sql-server-for-application-logging-pros-cons?lq=1

   [x] write logwatch script
   [x] postgres logging
   [x] create logwatch.py, which watches a file for changes, and when
       it changes, inserts it into a log database postgreSQL server
       securely
   [x] when admin starts anything, it also starts one logwatch.py;
       when it stops anything, it stops corresponding logwatch.py

   [-not-] idea about doing nginx right:
See http://www.ruby-forum.com/topic/134115   
      in particular,
       mv error.log error.log.0
       kill -USR1 `cat master.nginx.pid`
       wait 1 second and do anything with log
     But instead do "nginx -s reload"
   [x] nginx logging 
   [x] memcached logging
   [x] backend logging
   [x] issue with postgresql pid -- nothing; I was confused
   [x] worker pidfile, logging, Process object, etc. 
   [x] haproxy logging (hardest) -- have to patch/modify log.c to:
         print instead of send to network socket -- printf("%s", log_ptr); in "__send_log"

   [x] admin -- systematic logfile support: 
         - must specify logfile when creating Process
         - function to read what is new in logfile since last read
         - function to empty logfile
         - I will be able to build database on this, in uniform way
           that doesn't require python logger support.  So it was a
           day wasted on log.py...
  [x] simple single computation server using what I have
  [x] switch to testing with multiple backends instead of 1 in config1.py
  [x] test under linux
  [x] automatic reconnect
  [x] postgres logging is problematic due to: FATAL:  sorry, too many clients already
  [x] issues with anything but websocket -- needed to load balance by IP address
  [x] implement ssl (with a self-signed cert for now):
          - just encrypting between haproxy and backend doesn't work, and is insane
          - encrypting between backend and worker is probably insane too.
          - use stunnel!?  YES, it is awesome!
  [x] with stunnel haproxy sees everybody as coming from the same localhost ip, so load balancing  doesn't work at all:
        Evidently one must patch stunnel -- http://www.completefusion.com/ssl-load-balancing-with-haproxy-and-stunnel-on-debian/
  [x] make top-level mobile friendly index.html and also for cell
  [x] make top level index.html, etc. for desktop look jquery-ish
  [x] worker.py: 
        [x] running as root
        [x] making up a user
        [x] limitations
  [x] figure out how to use a proper ssl certificate
  [x] switch to using PB for worker.py, since without a sane and efficient
      message format I will be very, very unhappy.  
  [x] user PB in backend demo class that uses worker.py
  [x] use PB between backend and javascript client, if possible/sensible (?)
        nope; using protobuf with javascript evidently sucks, and isn't the right solution anyways.
  [x] openauth -- since it is an extremely important key component of my architecture -- better get it right!:
        - simple standalone auth demo using tornadoweb with both Google and Facebook auth
  [x] authentication -- integrate into backend.  the cookie-cached "username" is still very ugly, but fixing that up is easy.
  [x] add protobuf to build.py system
  [x] get it to work on linux again. 
  [x] ensure workers die when spawned
  [x] switch to use worker.py for backend
   [x] make it so the entry screen is live -- desktop
   [x] make it so the entry screen is live -- mobile
   [x] error when using Safari to connect via https (even locally):
           "Error during WebSocket handshake: location mismatch: wss://maththyme.com/backend/216/fcovda9f/websocket != ws://maththyme.com/backend/216/fcovda9f/websocket"
       this causes a fallback to xhr-streaming.  This happens on all devices
       I try to connect with.  We do get websocket when using http instead of https.

       See https://groups.google.com/forum/?fromgroups#!topic/sockjs/BeMG5MLKb0c

       Fact: Putting 'return "wss"'   as line 249 in data/local/lib/python2.7/site-packages/sockjs_tornado-0.0.4-py2.7.egg/sockjs/tornado/websocket.py fixes the problem.  
 
   [x] browser/platform testing with https all passes -- need external internet connection to do this due to checking certs:
         os x: chrom (websocket)e, firefox new (websocket), firefox old (xhr-streaming), opera (iframe-eventsource), safari (websocket)
         linux: chrome (websocket), firefox (websocket), opera (iframe-xhr-polling)
         windows 7: chrome, ie9 (iframe-xhr-polling), ie8 (iframe-eventsource), opera (iframe-eventsource), operanext (iframe-xhr-polling) ie7 -- I do *NOT* support this, firefox (websocket)
         android: chrome (xhr-streaming), firefox (websocket)
         iphone: safari (websocket), chrome (xhr-streaming).
         ipad: safari (websocket), chrome (xhr-streaming).

   [x] delete a bunch of old static/ html/js -- need to start cleaner 
   [x] the way haproxy is doing load balancing, it needs to stop trying a server when it is gone.
   [x] implement basic message routing between workers and connected clients (?)
   [x] admin: support start/stop/status worker
   [x] simplify worker for my particular application and properly daemonize worker using same options as for backend
   [x] use memcached to cache single cell evaluations 
   [x] if user submits a new stateless request in same session, then current one should be killed.
   [x] var x isn't defined
   [x] rewrite stateless execution as a separate class; 
       this may address the "done=True" message not getting through weirdness
   [x] implement limited backend stateful session support
   [x] log watcher should kill self if process it is watching dies 
   [x] refactor main() loop of logwatch -- too long!
   [x] implement very basic "single cell server"
   PLAN: Implement each component without UI polish.
  * Client -- Javascript library that runs in any modern web browser
    [ ] Write very simple ugly version that is fully functional.
  * Load Balancer -- HAProxy
    [ ] Learn how to deploy it and write config script.
        Example config script on some SockJS site.
  * Database -- PostgreSQL + SQLalchemy + Memcached + SSL
    [ ] Assemble SQLalchemy schema by combining what is current
        frontend and backend schema, plus actually store github bundle.
  * Worker -- forking SSL socket server + Sage + JSON
    [ ] Rewrite pulling code from backend.py in order to make this
        into a single integrated component with a straightforward API.
  * Backend -- HTTPS SockJS server; "create workspace" into DB queries; connect to worker
    [ ] Rewrite what I have to use SockJS (remove socket.io)
  * Static HTTP server -- simple nginx (no ssl)
    [ ] Configuration so my static/ directory served using nginx.
    [ ] Ability to serve static/ content created via statically publishing workspaces
  * Log server -- SSL socket server + database writer + Python logging
    [ ] update to use PostgreSQL database
    [ ] make it timeout connections that it forks off
    [ ] can I rewrite to use tornado so it's a single process (no forking)?  that would scale more
