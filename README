The Sage Workspace
------------------

https://github.com/williamstein/sagews

AUTHORS: 
   - William Stein

COPYRIGHT: 

  NOT released under *any* license yet.  This code is (c) Copyright William Stein, 2012.

DEPENDENCIES:

 PYTHON: 
 
   easy_install flask sqlalchemy pytest tornado tornadio2 requests pycurl

  * flask (includes: jinja2, werkzeug); BSD licensed
  * sqlalchemy; MIT license
  * pytest (for testing only); MIT license
  * tornado (suggests pycurl)
  * tornadio2 (https://github.com/mrjoes/tornadio2); Apache license

  * requests (http://docs.python-requests.org/); ISC license (basically BSD) -- TODO: remove this since performance *SUCKS*, leaks, etc.  -- maybe "poster" is a good alternative -- http://atlee.ca/software/poster/#download   [[TODO]]

 JAVASCRIPT:

  * jQuery (included): MIT license
  * socket.io-client (included, https://github.com/LearnBoost/socket.io-client)
  
Testing
-------

The code includes both doctests written using the standard Python
doctest format, and unit tests.  The point of the doctests is to
ensure that every function is tested and that it is easy to
interactively try out any given function.  The unit tests ensure that
more complicated examples behave as they should.

To run the test suite, install py.test (see http://pytest.org/) and
run the command

   py.test *.py


   
Components
----------

- Sage Session Server: serves a compute session that pushes results.

  API: 

   - new_session(push) --> id

   - execute(id, code) --> exec_id
   - interrupt(id)
   - status(id)

   - put(id, path, content):  creates file
   - get(id, path)     --> file
   - delete(id, path) 
   - files(id)         --> list of filenames
   
- simple.py -- a reference implementation of the above API.       

NEXT PLAN: Implement scalable http-based version of the above API. 

Components:

  - frontend_XXX.py -- A scalable web server that provides each of the
    above functions.  Scalable in the sense that it will of necessity
    queue up computations in a SQLAlchemy-based database and use
    memcache.

    [ hundreds of requests per second ]
    [     from appengine (say)        ]

                /|\
                 |
                 | http
                 |
                \|/

            [frontend]    (one frontend for each compute machine)

               /|||\
                |||
                |||    zeromq?
                |||
               \|||/

    [ 10-100s of Python processes (as different uid than frontend) ]
    [     running on same machine ]

 [ ] define simplest possible message protocol between frontend and
     python process and implement message protocol between frontend
     and python process

Approach 1: zeromq

     Using zeromq's REQ/REP pattern we do the following:

       * Start a Python session as a separate process and parameters:
              python session_zmq_url.py port url done_url
          port = ZMQ port to bind to as a REP socket
          url = URL to post results to (e.g., appengine)

       * The session_zmq_url process does the following in a loop:
             - using zmq, read block of code to execute, and send ack (ignored).
             - execute, sending output text (and list of created files) to url
             - when execution finishes, send zmq message saying "done" *and* GET's a certain url
      
       * When frontend receives code exec request:
             - checks for "done" zmq message from session
	     - if done, sends new code directly to session via zmq
             - if not, puts code in database for later.
             - when session calls frontend done url, it sends next
               block of code that is ready for evaluation to session,
               if there is any.

-- experiments show that something using zmq can work.  However, I'm
   not convinced it is the best approach.  Let's try a demo with a
   pure service-based HTTP approach. So...

Approach 2: HTTP-based approach

1. Start an HTTP session service

    python http_session.py FRONTEND_URL OUTPUT_URL

      FRONTEND_URL = url to get more work
      OUTPUT_URL = url to send output to
     
This will itself be an http server.  To get it to do work, one does a
POST request to the / path.  It immediately returns from the POST
request some "ok" response.  Then it stops being an http server and
starts exec'ing a block of code.  As output is produced, it is sent to
the OUTPUT_URL via POST's (using urllib2).  Once the code is done
being evaluated, it GET's the FRONTEND_URL, which establishes that it is
done. The result of the GET to the FRONTEND_URL may be another block of
code to execute, in which case the code execution starts again.  Or
the result may be a message to "stand by" (etc.).  In that case, it
switches back to webserver mode, as above.

2. Start a frontend service

    python http_frontend.py 

This will be a (maybe) multithreaded (partially) scalable http
server. It does not have to scale up that much really.  It provides
the session API. When asked for a new session, it will start a
session_http.py process as in 1 above, with FRONTEND_URL itself and
OUTPUT_URL as requested.  It deals with all file put/get/delete
itself.  When asked to execute code it:

    * checks if session is in wait state (stored in database); if so,
      POST's code to the / URL of session
    * if session is running a computation now, it saves code to a database for later
    * when FRONTEND_URL is hit, it checks database for code that needs to
      be executed; if there is any, it executes that.   If not, it sets
      (in database) that session is in 'ready' state.

Data Model:

sessions
   - id  (integer >= 0)
   - pid (UNIX process id)
   - path (e.g., '/tmp/foo/bar')
   - url (e.g., 'http://localhost:5000')
   - status ('running' or 'ready' or 'dead')
   - exec_id -- next exec_id (starts at 0)

code
   - exec_id -- the exec_id it will have when it is finally run
   - session_id  -- ForiegnKey (id of sessions table above)
   - input -- the actual code to evaluate
   - output -- usually blank (used in mode when frontend also stores results)




 [x] define the data model for the frontend
 [x] write sqlalchemy code for the frontend model
 [x] implement using flask the frontend webserver

 [x] We *must* find a way to make the frontend separate from the
     backend processes that are spawned.  There must be no
     parent/child relationship, and the frontend must be fully
     restartable without affecting the backend session.  This is
     because of *scalability*.

     This might be relevant: http://stackoverflow.com/questions/6442428/how-to-use-popen-to-run-backgroud-process-and-avoid-zombie

Ideas to solve this:

 [x] Create a backend spawner.  This will be a single very simple http
     server with two function: /spawn and /kill (same inputs as
     frontend.launch_backend_session), which when called spawns a
     blank new backend process and returns the pid.
     In production this would be run by the backend *user account*.
     There would also be some authentication, so only the frontend 
     would be able to call the given function.  
     Finally, a crontab could restart the backend-spawner if it is 
     killed, e.g., by a user doing "killall -u".
 
 [x] make frontend completely persistent between restarts and have a
     function to have it kill all processes it had the subprocess
     server spawn.

 [x] doctest coverage:

    [x] fix that fake wait() function in client.py
    [x] exec_id --> cell_id
    [x] in frontend: db --> model
    [x] rename: killall --> delete_all (in frontend and client); be sure to change docstring explanations too
    [x] backend: finished_url --> "ready_url"
    [x] doctest frontend.py
    [x] doctest client.py

 [x] deal with threading of frontend.py and the various database
     conflict issues that arise.

 [ ] implement use of websockets in sagews.js

 [ ] I really need to change all the GET's that change server state to
     POST's, since the official definition is: "a GET method can be
     executed at any time without side effects, a GET method will be
     re-executed by browsers and modern HttpClients automatically, if
     a network error occurs. A GET method must not change the
     server-side resource state by definition and is therefore safe."

 [ ] get tests working on Ubuntu 12.04 Linux

 [ ] TODOs in code:

     [ ] move app_port and subprocess_port to database?


 [ ] get tests working on Windows 7

 [ ] cleanup top-level README -- there is a lot from early design ideas that is no longer valid

 [ ] pylint 

 [ ] authentication

 [ ] Sphinx autogenerated API documentation

 [ ] extend so that we have *multiple* subprocess servers on the same
     machine, for security reasons

 [ ] rethink what everything is named; possibly refactor/rename, running test suite

 [ ] better logs

 [ ] For IE8, crossdomain it will be necessary to use XDomainRequest directly instead of jquery...

      See http://stackoverflow.com/questions/3362474/jquery-ajax-fails-in-ie-on-cross-domain-calls

 

 [ ] Tornado or gevent?  Performance is similar, but I can't get
     websockets + flash to work with tornado, though it does work with
     gevent.  I consider this important, not only for IE, but for
     Android chrome. 

     tornadio -- https://github.com/MrJoes/tornadio

 [x] GOAL NOW:  cross-domain tornadio on android
 [x] GOAL NOW:  cross-domain tornadio on IE9
 [x] GOAL NOW:  cross-domain tornadio on opera - it just can't, and that's that.

If I can do the above, then restructure code to commit to tornadio.

 [x] GOAL: get tornadia2 to work in frontend.py with chrome

 [x] GOAL: checkin then make demo4
      -- this works -- with execute handling fully using sockets instead of pollling!
      -- it does not work on IE for some reason; the socket.io part seems to, but
         not the cross-domain ajax.  I don't know why.
         It *does* work on iphone with or without flash server.
         For *android* it also works without flash, using xhr-polling, but 
         that seems very slow.  With flash, it works great on android!

 [ ] Next target: demo of the worspace_server, where there is some
     persisted worksheet.


----------------------------

2012-05-12:

I had a few days off and some technology surprises, so now i need to
'regroup'.

Plan.

1. Design/implement demo versions of the following that display/sync
   to multiple clients at once, in order to see what the backend.js
   api must provide:

  [ ] a div of draggable standard input/output cells (like in sagenb
      and ipython) as a class that converts a textarea, uses
      codemirror, etc.

- cell = input/output/name
   - div in the DOM
   - recipient of messages about changing: 
        input, output, position in DOM
        (codemirror allows for diffs for input)
  

  [ ] a command line

  [ ] simple spreadsheet; an nxm array of input's that when clicked on
      allow you to enter sage expressions, and when clicked out of
      evaluate and show result.  result of cell i,j is sorted in a
      variable c[i,j] that any cell can access.

  Have tab completion.

2. Based on the above, *re-define* and implement backend.js

3. Redesign and redo frontend.py -- it will be much simpler, with no
   database, etc.a

4. Design and implement workspace_server.py


-----

Standalone APPS:

  * PhoneGAP -- https://build.phonegap.com

[ ] I need to look carefully at RStudio, since that is another model
    for what to support as a web-based UI.

  - what's the big deal with Hadoop?

  - rado: look into http://d3js.org/


PEOPLE:

  - Josh Breeds <josh@servedby.net>




-------------------

What I plan to do today on sagews:
  
[ ] clarify and document the backend.js library; in particular,
    make sure attaching function via the data attribute works

[ ] implement a very robust snappy codemirror2 based command line: 
      - minimal possible code
      - persistent sqlite database
      - multiple simultaneous clients



[ ] http://www.jstat.org/  ??
