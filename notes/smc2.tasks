{"desc":"(2:00?) #today #gce\n\n- [x] increase gce nodes from 5 to 8\n- [ ] add new cassandra nodes:\n   - [x] dc5\n   - [x] dc5: (re-)start all hubs and haproxy in dc5:\n   \n            [a.restart('hub', host='smc%sdc5'%i, wait=False) for i in range(1,9)] \n            [a.restart('haproxy', host='smc%sdc5'%i, wait=False) for i in range(1,9)] \n   \n   - [x] dc6\n   - [x] dc6: (re-)start all hubs in dc6\n   \n        [a.restart('hub', host='smc%sdc6'%i, wait=False) for i in range(1,9)] \n        [a.restart('haproxy', host='smc%sdc6'%i, wait=False) for i in range(1,9)] \n        \n   - [x] dc7\n   - [x] dc7: (re-)start all hubs in dc7\n   \n        [a.restart('hub', host='smc%sdc7'%i, wait=False) for i in range(1,9)] \n        [a.restart('haproxy', host='smc%sdc7'%i, wait=False) for i in range(1,9)] \n   \n- [x] spin up nginx, haproxy, stunnel\n\n\n...\n\n- [ ] should do nodetool clean in each dc","position":-1,"last_edited":1424274866304,"task_id":"0932dd45-2c9a-4d41-aa84-e85725b9df8f","done":1424274865896}
{"desc":"(2:00?)  #gce\nswitch to gce load balancing","position":0,"last_edited":1425611822838,"task_id":"d63d12de-c90e-4c7c-a2cf-3c26870e1746","done":1425611822426}
{"desc":"#invalid #gce\nrewrite hub/bup_server, etc., to be able to use Google Data Store (and Google Cloud Store for blobs) as an alternative to Cassandra.\n","position":1,"last_edited":1425503202592,"task_id":"8847b690-dd6f-4a5c-936b-d0b2f9d04fc0","done":1425503202176}
{"desc":"#today\n","position":2,"last_edited":1424143447313,"task_id":"b89d32f7-754a-4de3-b743-9275f0b94dcb","deleted":true}
{"desc":"make compute vm's at UW use much more RAM and all cores.","position":-0.5,"last_edited":1424993183695,"task_id":"62f0c1ee-d4ef-4c85-9913-96b3e226c5f6","done":1424993183279}
{"desc":"#6\nalternative: instead of using nginx, use this: https://cloud.google.com/storage/docs/website-configuration\n\nhttps://cloud.google.com/storage/docs/website-configuration#tip-dynamic\n\nrejected -- this will lock us in but with no real win.","position":-0.75,"last_edited":1427287317984,"task_id":"ad05d59a-90ae-4984-af7f-1f36d1fd12c7","done":1427287317572}
{"desc":"#1 #bug #editor #sagews\ncorruption.\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14b9852c4c20ed4b\n\n    I can see that in the history around revision 294.  The list of changes is stored in the history file, which I've copied and will look at closely.\n\n    What web browser, operating system, and are there any javascript console errors?\n\n    https://cloud.sagemath.com/projects/4a5f0542-5873-4eed-a85c-a18c706e8bcd/files/tmp/Balbusaur.sagews.sage-history\n\n\nSolution/idea:\n\n- replace sync by a *local* sync on the cell level / do same with syncdb, ipython, etc.  That would fix a ton of problems.  A sort of sudo op transform...?","position":-0.875,"last_edited":1424791516590,"task_id":"7bf29e20-ec21-430e-b6b4-a86e9fdb419d","done":1424791516187}
{"desc":"#1 #today\nincrease quota from 10MB to 32MB for public files.","position":-0.8125,"last_edited":1424274824854,"task_id":"97322cae-1191-45b6-8b2b-83673e26455a","due_date":1424234908506,"done":1424274824438}
{"desc":"#1 #today \ndeal with compute firewall issues once for all.","position":-0.78125,"last_edited":1424286780506,"task_id":"c14cf799-27fa-44fe-9888-1c2068e4c448","done":1424286780104}
{"desc":"(1:00?) #0 #today\nrewrite code to make it possible to properly rebuild that email_address index, then run it. \n\n\n","position":-2,"last_edited":1424285604487,"task_id":"df7d7a00-65a2-43a9-8ecf-8e58c8f9c20b","done":1424285604073}
{"desc":"(1:30) #0 #today\nlocal_hub call just hangs sometimes....\n\nI think I fixed this -- we shall see.\n\nNew data: this may be caused when a project **moves**.\n\n    2015-02-18T15:49:24.809Z - debug: hub <-- client (client=QAJYGDE8p7f3UfAeAADa): {\"event\":\"project_exec\",\"project_id\":\"80496c4c-c705-46f5-b04f-34e7c031b21d\",\"path\":\"\",\"command\":\"git-ls\",\"args\":[\"--t...\n    2015-02-18T15:49:24.809Z - debug: project(80496c4c-c705-46f5-b04f-34e7c031b21d): call\n    2015-02-18T15:49:24.809Z - debug: local_hub(80496c4c-c705-46f5-b04f-34e7c031b21d): \"call\"\n    2015-02-18T15:49:49.813Z - debug: hub <-- client (client=QAJYGDE8p7f3UfAeAADa): {\"event\":\"project_exec\",\"project_id\":\"80496c4c-c705-46f5-b04f-34e7c031b21d\",\"path\":\"\",\"command\":\"git-ls\",\"args\":[\"--t...\n    2015-02-18T15:49:49.814Z - debug: project(80496c4c-c705-46f5-b04f-34e7c031b21d): call\n    2015-02-18T15:49:49.815Z - debug: local_hub(80496c4c-c705-46f5-b04f-34e7c031b21d): \"call\"\n    2015-02-18T15:50:12.875Z - debug: hub <-- client (client=QAJYGDE8p7f3UfAeAADa): {\"event\":\"project_exec\",\"project_id\":\"80496c4c-c705-46f5-b04f-34e7c031b21d\",\"path\":\"\",\"command\":\"touch\",\"args\":[\".sag...\n    2015-02-18T15:50:12.876Z - debug: project(80496c4c-c705-46f5-b04f-34e7c031b21d): call\n    2015-02-18T15:50:12.876Z - debug: local_hub(80496c4c-c705-46f5-b04f-34e7c031b21d): \"call\"\n    2015-02-18T15:50:14.813Z - debug: hub <-- client (client=QAJYGDE8p7f3UfAeAADa): {\"event\":\"project_exec\",\"project_id\":\"80496c4c-c705-46f5-b04f-34e7c031b21d\",\"path\":\"\",\"command\":\"git-ls\",\"args\":[\"--t...\n    2015-02-18T15:50:14.814Z - debug: project(80496c4c-c705-46f5-b04f-34e7c031b21d): call\n    2015-02-18T15:50:14.814Z - debug: local_hub(80496c4c-c705-46f5-b04f-34e7c031b21d): \"call\"\n    2015-02-18T15:50:39.821Z - debug: hub <-- client (client=QAJYGDE8p7f3UfAeAADa): {\"event\":\"project_exec\",\"project_id\":\"80496c4c-c705-46f5-b04f-34e7c031b21d\",\"path\":\"\",\"command\":\"git-ls\",\"args\":[\"--t...\n    2015-02-18T15:50:39.822Z - debug: project(80496c4c-c705-46f5-b04f-34e7c031b21d): call\n    2015-02-18T15:50:39.823Z - debug: local_hub(80496c4c-c705-46f5-b04f-34e7c031b21d): \"call\"","position":-3,"last_edited":1424886185364,"task_id":"86b4e172-da35-4741-b3ae-8e53e68c689c","done":1424886184955}
{"desc":"(0:30?) #gce #low-usage\nnodetool clean in each dc","position":-0.9375,"last_edited":1425611820100,"task_id":"35ede044-dc1d-479c-b8d8-1b0afcafe2e9","deleted":true}
{"desc":"(2:00?) #now #upgrade #today\nupgrade to sage-6.5 and sync out","position":-6.856689453125,"last_edited":1424753284301,"task_id":"7438c090-816a-490a-942e-ecd926e97350","done":1424753283887}
{"desc":"#today\nsetup new devel machines on sagemath, inc. infrastructure","position":-8,"last_edited":1424291393896,"task_id":"de7b6d2c-90b4-4bc2-a3aa-4613703d4259","done":1424291393489}
{"desc":"#today\nupdate my local virtualbox devel environment so I can code on the plane, etc. if I want.","position":-7,"last_edited":1424290639195,"task_id":"fbae0512-f889-4790-aa46-d5f582cf8cd0","done":1424290638777}
{"desc":"#now (1:00?) #vm #upgrade #install #today \n\n- [x] push it out\n- [x] as root in /root: `./update_salvus`\n- [x] `umask 022` then `sage -sh` then `pip install mrjob boto pattern seaborn`\n- [x] `apt-get update; apt-get dist-upgrade; apt-get autoremove`","position":-6.85675048828125,"last_edited":1424752389753,"task_id":"66ae9142-271b-4187-9c00-600ae964b28b","done":1424752389343}
{"desc":"(1:00?) #gce\ntest google datastore:\n\n- [ ] how the latency really is \n- [ ] compare with my cassandra latency\n- [ ] get a feel for using it.","position":-6,"last_edited":1425611717199,"task_id":"8cfcf70b-e99e-4fcc-8bee-4c088f5b9f37","done":1425611716784}
{"desc":"(1:00?) #gce\ntest google cloud storage for sharing files. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n - see https://cloud.google.com/storage/docs/website-configuration)","position":-6.75,"last_edited":1424993168197,"task_id":"15abe7db-fea5-4882-b336-4fe2febba40c","done":1424993167778}
{"desc":"(1:00?) #gce\ntest google load balancer...\n","position":-4.75,"last_edited":1425611719237,"task_id":"42816ea3-fc4a-41be-a0b1-b18457d68172","done":1425611718828}
{"desc":"(2:00?) #gce\nlearn/test switch to google DNS (instead of route 53)\n\nIt turns out that google dns is way behind route 53 in functionality, as keith said.\n\nSo instead I properly setup route 53, so now when a region fails another will automatically take over, etc.","position":-6.5,"last_edited":1425088297010,"task_id":"9a0c6905-655c-41fa-85cb-b76254bc55bb","done":1425088296598}
{"desc":"(4:00+) (1:30?) #check #0 #gce  #backup #today\n\nCome up with better approach that involves first rsyncing everything from the VM's and then (and only then) (possibly) running bup.  Right now bup uses too much RAM.\n\ncreate new automated back-up databases from cloud.\n\nPlan: \n\n0. [x] create zfs snapshot of filesystem across cluster\n\n   [x] delete all snapshots and backups directories:\n   \n     \t cd /mnt/cassandra/lib/data && time rm -rf */*/backups */*/snapshots\n      \n   [x] create new nodetool snapshot:\n   \n         nodetool snapshot\n\n1. [x] create backup entirely on a backup vm in same zone using cassandra snapshots/backups as usual\n    - [x] decide on a new PD size\n    - [x] create PD, format, mount\n    - [x] modify existing backup script\n\n2. [x] rsync the backup to bsd\n\n3. [x] rsync from bsd to other offline storage later...[ ] ","position":1.8125,"last_edited":1424459669181,"task_id":"34d3948a-9ee6-4a8b-97e1-a9be8b118ff1","done":1424459668769}
{"desc":"#gce\nbrand new gce machine template with sage-6.5 and minimal image size.","position":-2.25,"last_edited":1425611722555,"task_id":"681dafa5-b288-4d5a-9a96-ed10f6c59342","done":1425611722143}
{"desc":"(0:30) (0:45?) #now #today\nAdd another thing to home screen to add collaborators to encourage viral growth: \n\n\" Create or Import a File, Worksheet, Terminal or Directory...\"","position":1.75,"last_edited":1424395945486,"task_id":"5e71fc53-f186-4e07-b565-75555b9bcb2b","done":1424395945070}
{"desc":"(2:00?) #gce #cassandra #today\nreplace the cassandra node filesystems -- all of them -- with much smaller ext4 filesystems","position":1.625,"last_edited":1424390763273,"task_id":"fee727a9-9b11-425c-beea-51a274435641","deleted":true}
{"desc":"(1:00?) #security #6\ninvestigate this security scanner:\n\n   http://googleonlinesecurity.blogspot.com/2015/02/using-google-cloud-platform-for.html","position":1.875,"last_edited":1426254427633,"task_id":"1e15e912-1a6b-45ed-b1aa-baece5388c18"}
{"desc":"#gce\nseriously think through options for separating compute from storage\n\nIdeas:\n\n- store all snapshots of project in google cloud storage as a bup repo\n- when project isn't used for a while, delete it from compute vm or move to slower storage\n- when start project\n\n\n","position":-6.625,"last_edited":1425611714598,"task_id":"8730470e-01c1-4a9a-930a-9f88fd5fe451","done":1425611714188}
{"desc":"(1:00?) #upgrade\nupgrade to codemirror 5.0\n\nhttp://codemirror.net/codemirror-5.0.zip","position":-6.6875,"last_edited":1424468345411,"task_id":"8e8f3a41-75ec-4d02-91f4-8963afbc1055","done":1424468345411}
{"desc":"(1:03) #now (1:00?) #today\nget rid of password confirm and combine first/last name\nto reduce friction.  \npassword reset works fine.","position":-6.8125,"last_edited":1424472220316,"task_id":"a72958f2-e731-47e7-ae58-0571cbd8d331","done":1424472219915}
{"desc":"","position":-6.84375,"last_edited":1427813677083,"task_id":"f2e40a7f-9e59-427f-b65a-ff928ea113ff","deleted":true}
{"desc":"(1:00?) #today #now\ninvestigate longterm saving projects to google cloud storage via bup or https://github.com/moinakg/pcompress\n\n- Store bup repo of snapshots of project by simply updating, using rsync, and copying any files that might change.\n\n- Also use pcompress (?) to store complete copy of project as a single file, just in case (?).  Incremental based on timestamp (?).\n\n> HSY: except for the encryption (which is orthogonal anyways), this pcompress sounds similar to `lrzip`. It's an \"older\" standard linux utility and hence easily installed via apt-get install lrzip. `lrztar <directory>` and `lrzuntar` are all you need, see `man lrzip`. BTW: it compresses the sage binary tarball 7.6:1 in a few minutes (tried it for the last 6.5 release for ubuntu 14.4), which probably means it is mostly limited by I/O, not CPU.\n\n> William: I think bup is the best choice anyways.  I can't think of anything similarly efficient to solve this problem...\n\n- The current total space used by all bup repos is about 1.3TB, which would cost \\$34/month to store in Google cloud storage. \n\n- I think this isn't a viable approach since compute will often not be a GCE, but this must be at google... (?).\n\nOther ideas to test:\n\nIn each DC have a single global dedup'd compressed ZFS pool with rsync of all projects and also all bups.  It's fine if it is fairly slow. \n\n- Define the dream API I want, then list different ways of implementing it with different backends.\n- I can use that api to save/restore the bup repos to get fine-grained snapshots if I want.\n\nAPI: \n\n        storage save path     # efficiently saves changes to path since last save\n\n        storage restore path  # efficiently restores path from last save.\n\nSolutions:\n\n- rsync to/from a single big volume\n- rsync to/from distributed volumes with a cassandra index\n- rsync to/from gluster (or other cluster) filesystem\n- google cloud storage with incremental tarballs and repack every so often.\n- google cloud storage using bup repos and gsutil rsync\n- many individual persistent disks?!  (massively wasteful)\n- sparse image files stored in google cloud storage\n\nOR... don't change anything but just improve my current implementation to do solve additional problems:\n\n   - disk space running out: rebalance, increase volume size.\n   \nThe ultimate would be:\n\n   - a magic single multi-data-center global distributed filesystem that compute machines can mount, which is super fast.  Involves a local cache.\n   \nTest this:\n\n - glusterfs us in my sagemathcloud project on 3 nodes\n - another glusterfs in europe in my sagemathcloud project on 3 nodes\n - could then make the \"open project on compute\" process first check\n   for cached local files, and if not copy them from the glusterfs.\n   If so, just update them.  With state stored in cassandra (?) or filesystem.\n - then I could delete any projects from compute vm's without any loss in functionality (just speed), which since \n - could also move a project from any vm to another (even in same dc) without loss of files, just speed.\n - would just have to make the \"write to gluster\" operation write to all glusters via an rsync in parallel\n \n \nNone of the above solves any problems really.  Instead I should just improve the current system, which is pretty damn good -- just not finished.  I can decouple compute and storage enough this way. \n\n - add command to move all data for a project from one node to another in the same datacenter\n - make bup_repair properly get results in small batches rather than all at once.\n \n \nOr... the other option, which is:\n\n- In each DC have a single NFS server, and have all compute vm's mount from it over the LAN.\n- It will be a single zfs pool (so can snapshot) -- about 4TB for starters (could try to dedup compute data if possible... if that fails, rebuild without dedup.)\n\nNO.  That centralizes everything, which doesn't scale.  Even now it would barely work at UW.\n\n","position":-6.859375,"last_edited":1424661119535,"task_id":"e9b674f3-a438-473d-aa33-a90d5779005c","done":1424661119126}
{"desc":"(0:38) (0:10?) #today\nraise password reset email timeout to 1 hour.\n","position":-6.9296875,"last_edited":1424548524194,"task_id":"006a97da-3c28-433b-8ee8-ba5069a8a7cf","done":1424548523779}
{"desc":"(0:15?) #today\nchange collaboration link to go straight to \n","position":-6.84765625,"last_edited":1424460022382,"task_id":"3620595e-8d88-4446-9b65-09dcea44093e","deleted":true}
{"desc":"(3:00?) #terminal #feature #5\nterminal menu bar\n\nIdeas here: https://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14b9843b3d96f348","position":-6.85546875,"last_edited":1427813652415,"task_id":"ddfadeda-e4bd-4ef1-81d4-abd473a739f4"}
{"desc":"#now (0:07) (0:30?) #upgrade #today\nupgrade to font-awesome 4.3.0","position":-6.85693359375,"last_edited":1424726001104,"task_id":"6ef80028-e10b-47b4-b5dc-07f887bf71e3","done":1424726000702}
{"desc":"#bug #ipython\ntoo many servers getting left around\n\nSee https://mail.google.com/mail/u/1/?pli=1#inbox\n","position":-6.89453125,"last_edited":1424726574297,"task_id":"e65ddfab-a356-4150-ada8-6e6a0d612797","done":1424726573888}
{"desc":"#now #today\n(1:30?) #gce\nsave money -- replace all cassandra disks by new 50GB ext4 format disks, and delete any log disks.\n\nThis must have taken 5 or 6 hours.  Very tedious!\n\n\n\n\t\n    sudo su\n    echo \"UUID=`ls -l /dev/disk/by-uuid/|grep -v sda|awk '{print $9}'|xargs` /mnt/cassandra   ext4 defaults 0 1 \" >>/etc/fstab\n    echo \"/home/salvus/salvus/salvus/scripts/restart_tincd; sysctl -w vm.max_map_count=131072\" > /etc/rc.local\n \tkillall java && sleep 10 && rsync -axvH /mnt/cassandra/ /mnt/x/ && sudo shutdown -h now\n \n on startup\n \n \tsudo chown salvus. -R /home/salvus/salvus/salvus/data/logs\n    sudo rmdir /mnt/x\n    \nFrom admin ipython:\n \n     h='smc5dc5'; [a.start(s, host=h, wait=False) for s in ['cassandra', 'stunnel', 'haproxy', 'hub', 'nginx']] ","position":-6.876953125,"last_edited":1424661104346,"task_id":"df18c746-be80-438e-9f3f-0bffaf943bc3","done":1424661080145}
{"desc":"#3\nconcerns -- what happens if copy files (using rsync) to a project (e.g. sending homework), but that project is not on?  \n\n- do files get properly saved ever?  \n- Will \"it\" just forgot and randomly loose files?\n\n> My memory is that this is already handled perfectly, but I want to double-check...","position":-6.857421875,"last_edited":1427813451370,"task_id":"0c2e72f9-18bd-46ac-8a60-506b838f45d7","done":1427813450967}
{"desc":"(1:15?) #1\nfix monitor script so it can run on GCE rather than UW.\n- [ ] (easy) write to database via hostname (not using tinc network)\n- [ ] (harder) send email (can't use gmail; use sendgrid but via python)","position":-6.8564453125,"last_edited":1428069845155,"task_id":"a196661c-4ded-4abe-baa9-ba293b2a6b88"}
{"desc":"","position":-6.85595703125,"last_edited":1424707490941,"task_id":"0c148baf-fc39-4a39-9491-da30065e7647","deleted":true}
{"desc":"(0:10?) #today\nexport a public version","position":-0.76953125,"last_edited":1424709582231,"task_id":"19468fef-d3ba-4e97-9c0b-630cefc824fe","done":1424709581826}
{"desc":"(0:05) (0:15?) #today #install #now\nsome pip install requests\n\nhttps://mail.google.com/mail/u/1/#inbox/14bb082788a79dfc","position":-6.8565673828125,"last_edited":1424726569197,"task_id":"5a819142-d614-4476-86b9-692b63c1aecf","done":1424726568791}
{"desc":"(2:00?) #feature #ui #5\nimprove the project log\n\nsome ideas  -- https://mail.google.com/mail/u/1/#inbox/14bad8af5d04134d\n\nshould we get rid of the files/projects/messages buttons in the log -- I don't think they are anything but confusing?","position":-6.85650634765625,"last_edited":1427813673987,"task_id":"38037606-4819-4a1e-8586-8fe998e3506b"}
{"desc":"(1:30?) #bug #install #4\nfix fenics install\nhttps://mail.google.com/mail/u/0/#inbox/14bb737b3d010595\n\nAnother vote for it here: https://mail.google.com/mail/u/1/#inbox/14c68181958a1e45","position":-6.8568115234375,"last_edited":1427813622226,"task_id":"7c42ca95-7450-492f-b2d0-7f45860ddcf8"}
{"desc":"(2:16) (0:40?) #0 #upgrade #today\nmajor new cassandra driver: https://mail.google.com/mail/u/0/#inbox/14bb78b75048c585\n\n- problem: weird stuff with uuid's/buffers and data types breaking the driver...","position":-6.85723876953125,"last_edited":1424843719149,"task_id":"a446fb16-b230-4734-8489-709186b5abe1","done":1424843718743}
{"desc":"(1:00?) #1 #today\nmake this url display terms of usage, read from a static file (?)\n\n  https://cloud.sagemath.com/articles/terms","position":-6.856903076171875,"last_edited":1427215960795,"task_id":"7a7906f6-d8c4-4408-a3cd-725acf85429c","deleted":true}
{"desc":"(1:00?) #admin\ntry to get google cloud monitoring/logging to work","position":1.9375,"last_edited":1425503209396,"task_id":"f77ced38-65c2-4f8b-81ac-4f89179b990d","done":1425503208977}
{"desc":"#today #now (0:05) (0:10?) update usage numbers","position":-0.7578125,"last_edited":1424726274687,"task_id":"8b3807a3-0691-4679-86fa-8f096ed43d57","done":1424726274271}
{"desc":"(1:30?) #vm #upgrade #install #1\n\n","position":-0.76171875,"last_edited":1427286422993,"task_id":"d236f82b-5f81-4495-8d37-ae5cd2a90258","deleted":true}
{"desc":"(3:30) (1:00?) #0 #today\nmake it so that changing the password invalidates all remember me cookies for a given user.\n\n- [x] (0:34) make a plan\n\nWe have a big (about 70K entries) table right now that has all the cookies along with the account_id as a value.\n\nIf we come up with a new approach that uses the same cookies, we can iterate through that huge table of all cookies and read it, then write to a new table.\n\nHow about this:\n\n- [x] (0:27) (0:20?) Whenever we *create* a remember_me cookie, we also write the key of that cookie to a set attached to the account.  `alter table accounts add remember_me          set<varchar>;`\n- [x] (0:23) (0:20?) Whenever we change the password, we delete all cookies with keys in that accounts table, thus invalidating them.\n- [x] (1:13) (0:20?) Every 5 minutes (?) the hub will check that the cookie used to login a connected user is still valid.  If it disappears from the table, the user is logged out.  This means implementing a message from hub to client that logs a user out.\n- [x] (0:58) (0:45?) #now Once above is working, we run through the entire 70K big table of existing cookies and write them to the accounts table, so that the above works.\n\n","position":-0.7587890625,"last_edited":1424915734457,"task_id":"0f753947-13da-46be-a63c-c491d3592941","done":1424915734051}
{"desc":"(0:55) #now (1:00?) #terminal #bug #today\noutput doubling race condition\n\nhttps://mail.google.com/mail/u/1/#inbox/14bbbc497857c33c\n\nDid some things -- not sure if this will fix it or not.  If I ever hit it again, i need to know if it is entirely client-side by testing another console connected, looking at server logs, etc...","position":-6.8572540283203125,"last_edited":1424823566664,"task_id":"4ea24d63-885b-4e55-9d31-c7f9331ebac2","done":1424823566257}
{"desc":"(2:22) #now (0:30?) #database #admin #2 #today\nrewrite bup_repair to stream output rather than do one big query\n\nThis took much longer than expected since I did it *right* with integrated streaming support, which is used also for the user search functionality (which was about to die). ","position":-6.8572998046875,"last_edited":1424900938476,"task_id":"49b0ce1a-bd86-4541-8060-7a8a229c8515","done":1424900938074}
{"desc":"(2:00?) #com #1\nmake it so users can move their project to an available location of their choice.\n\n- [ ] first between UW data centers\n- [ ] then to nonfree data centers","position":-0.75860595703125,"last_edited":1429157083527,"task_id":"52fe0cf8-0a34-4c63-9141-9ec83cb54fe3"}
{"desc":"(0:28) (1:00?) #now #today #bug #0\nfix bug in load of remote files\n\nreport: https://mail.google.com/mail/u/0/#inbox/14bbd4b67dc9e275\n\nto sage-devel: https://mail.google.com/mail/u/0/#sent/14bbd62bdc92cec1?compose=new","position":-6.857269287109375,"last_edited":1424813067674,"task_id":"8dfedcd1-a7b6-4345-b79c-1564fb43a839","done":1424813067271}
{"desc":"(0:15?) #monitor #4\nmake check_hub_* also check for \n\n\tgrep \" Uncaught exception:\" hub*.log\n","position":-7.444186329579679,"last_edited":1428537028038,"task_id":"9ffbf978-c690-4601-a00d-51720d3492d1"}
{"desc":"(2:30) (3:00?) #today #bug try/test -- rewrite how #ipython sync works to use the syncdb infrastructure (which itself could get improved later).  \n\nMotivation: https://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14bc33cc2777f52e\n\nCurrently my \"sync friendly\" version of the ipynb file (the syncdb file) is basically NOT sync friendly, especially as the ipython notebook cell format has got a lot more complicated.  Ideas?\n\nRight now it looks like sync's that result in cell contents that are invalid json just result in an error.  But the client that caused that error doesn't know to retry. Think this through.  Possibly consider using a json patching to upstream... then use usual mechanism, i.e., some notion of purely local operational transform, repeated until it succeeds.  Could also apply to syncdb.","position":-0.75830078125,"last_edited":1425920139303,"task_id":"bc41b5a4-3208-4a35-86a2-97047e0a3d44","done":1425920138896}
{"desc":"(2:00?) #2 #database #backup\nplain text backups using database streaming.\n\nuse the streaming functionality of cassandra to make periodic \"proper\" CSV/text backups of the non-binary content \nof the database; can be nice to query from grep, etc.","position":-0.758544921875,"last_edited":1428069825899,"task_id":"6510c04c-bc2d-4797-a069-3135587d7828"}
{"desc":"(0:15?) #bug #5\nwhy does this project have 5 locations?\n\n      { project_id: '9a1eb6c1-9b97-48d8-aa42-306cb460439c',\n        bup_location: '3056288c-a78d-4f64-af21-633214e845ad',\n        bup_last_save:\n         { '3056288c-a78d-4f64-af21-633214e845ad': Wed Feb 25 2015 22:49:48 GMT+0000 (UTC),\n           '630910c8-d0ef-421f-894e-6f58a954f215': Wed Feb 25 2015 21:05:14 GMT+0000 (UTC),\n           '94d4ebc1-d5fc-4790-affe-ab4738ca0384': Wed Feb 25 2015 22:49:48 GMT+0000 (UTC),\n           'a7cc2a28-5e70-44d9-bbc7-1c5afea1fc9e': Wed Feb 25 2015 22:49:48 GMT+0000 (UTC),\n           'eec826ad-f395-4a1d-bfb1-20f5a19d4bb0': Wed Feb 25 2015 22:49:48 GMT+0000 (UTC) },\n        source_id: '3056288c-a78d-4f64-af21-633214e845ad',\n        timestamp: Wed Feb 25 2015 22:49:48 GMT+0000 (UTC),\n        targets:\n         [ '3056288c-a78d-4f64-af21-633214e845ad',\n           '630910c8-d0ef-421f-894e-6f58a954f215',\n           '94d4ebc1-d5fc-4790-affe-ab4738ca0384',\n           'a7cc2a28-5e70-44d9-bbc7-1c5afea1fc9e',\n           'eec826ad-f395-4a1d-bfb1-20f5a19d4bb0' ] } ]","position":-0.7586669921875,"last_edited":1427838576044,"task_id":"a2f80f7d-1969-4229-987d-9d1a96d428db"}
{"desc":"(1:00) #latex #bug #today\npages get randomly re-ordered, etc. when editing latex documents.  Instead, clean this up:\n\n- create one preview html div on load for each document page, as soon as we know number of pages\n- when changing state of a page (loading new version), show a spinner or something\n- always get the actual pages right","position":-0.758056640625,"last_edited":1424932758845,"task_id":"8e1ba602-a6c4-488b-827f-355f4aecb275","done":1424932758428}
{"desc":"#ipython #bug\n","position":-0.7579345703125,"last_edited":1424929208276,"task_id":"b59b023d-9eee-41d1-bf43-c199bc870f9b","deleted":true}
{"desc":"#bug #2 \ncode folding in latex documents now broken in new codemirror.\n\ne.g., in this file: https://cloud.sagemath.com/projects/50c2cd00-d0b7-4b9d-858a-657b587c0767/files/revision-critical-paper/chen.tex","position":-7.5,"last_edited":1425611450995,"task_id":"d6a1d123-60d0-45c0-b9cd-55edbd17bf69","done":1425611450587}
{"desc":"(0:15?) #com\nmachine type in database\n\n- add new database column to storage_servers indicating whether the machine is free or premium (or dedicated... needs to be flexible)","position":-6.856874465942383,"last_edited":1426253663552,"task_id":"065db1d1-a137-4c1d-864b-9d1803311369","deleted":true}
{"desc":"(1:00?) #com #2 #unclear\n- [ ] start one testing premium machine running at us-central1f on academic GCE project.\n- [ ] add to storage_servers table.","position":-7.444186328793876,"last_edited":1427286526207,"task_id":"be9e7714-14c7-40af-8f38-8a05ae3209d6"}
{"desc":"#0 #com #unclear\nadd function to bup_server to make a project premium, e.g., `premium_replication` which can either enable or disable replication of the project to premium machines in dc's. \n\nWill need something in database that indicates *what* is happening to the project, so multiple hubs don't compete to break it in half and make it vanish from existence.\n\nenable:\n\n- [ ] ensures it is replicated to one premium machine in each dc, if there are any\n- [ ] removes from all non-premium machines\n\ndisable:\n\n- [ ] make replicated to choice of non-premium machine in each dc that has one\n- [ ] removes from premium machines\n\nWhen user tries to do anything with a project that is getting upgraded/downgraded, show them an appropriate status message.","position":-6.856822967529297,"last_edited":1427737605314,"task_id":"16faee40-0392-4396-bab5-12d83074095f","done":1427737604907}
{"desc":"#com #1 #unclear\nbup_storage.py defaults\n\n(temporarily at very beginning, could just hard code something.)\n\n- [ ] add different default parameters to bup_storage.py for when a project starts on a premium machine versus a free machine.  This could just be a command line option that is passed to bup_storage.py from bup_server.  And it could be an option shen starting bup_server (?).  Or it could an option that is passed to bup_server with the start message.\n\n- [ ] alternatively, completely remove defaults from bup_storage.py.  They should instead be passed as options (from hub, got from database). ","position":-7.444186329317745,"last_edited":1427286350319,"task_id":"2f0680db-f7d2-429e-8279-c6bcad3d574e"}
{"desc":"#com #database\n\n- [ ] add column in database to projects that is called 'plan'.  this has\n    - account_id of the user that is paying for this plan\n    - the current plan name itself, e.g., 'premium'\n    - log: append-only list of objects '{timestamp:..., action:}' or maybe just a map from timestamps to actions, where the actions are 'start', 'stop'.\n    - include plan name in project information, so client can display it somehow, at top in project listings with better icon, etc.\n\n- [ ] add a column in database to accounts that is called pay_projects.  This is a set of project_id's of projects that the user is paying for.\n\n- [ ] add a column in database to accounts that has payment information.  This would be a token that identifiers the user's account at STRIPE.\n\n- [ ] new table in database called \"customer_activity\" that has columns:\n\n\t- timestamp_uuid as primary key, so can easily query by date range (is this even possible -- if not use a uuid and a date string??)\n    - account_id\n    - some sort of description of activity\n\n- [ ] Add functions to cassandra:\n\t- set_plan(plan, account_id)   where plan is one of 'free', 'premium'.\n      which will put something in all of the relevant tables above.\n    - is_paying_customer(account_id)  -- whether or not user is a paying customer (so cc number is known)","position":-6.856880187988281,"last_edited":1426253608531,"task_id":"c879fae5-e210-4f07-8968-d5eb2230de83","done":1426253608126}
{"desc":"#com #4\nif a user is paying for the project, don't allow them to be deleted from the project.","position":-6.856812953948975,"last_edited":1426253027324,"task_id":"bcec95e7-61a4-49fc-a058-bfa3c79bba56","deleted":true}
{"desc":"(2:30?) #0 #today\nsingle sign on/oauth2, etc.\n","position":-6.856813669204712,"last_edited":1427287465388,"task_id":"ec51f454-c972-439c-ad71-2a5288d1396c","deleted":true}
{"desc":"(2:00?) #com #0\n\n- [ ] update base template vm for machines\n- [ ] add one high-mem premium machine to each of dc5 and dc6 with 50GB SSD zpool for /projects, and slower zpool for bup repos.","position":-6.856845855712891,"last_edited":1426736873819,"task_id":"c6bac0c9-64d7-41fa-a179-fbcbd7f5feee","deleted":true}
{"desc":"#billing #stripe #today\n","position":-6.856900215148926,"last_edited":1425434827912,"task_id":"36a56a48-630d-4acc-9244-67d809dee8d4","deleted":true}
{"desc":"#gce\nprobably just disable the asia dc -- there is just so little usage. Not sure.","position":-6.85688591003418,"last_edited":1425611701537,"task_id":"f80a96f8-4252-448e-adb3-c1920fcf2fb3","done":1425611701121}
{"desc":"#billing #stripe #1\nmeta task\n\n- [ ] (0:20?) make https://william.wstein.org/#billing work\n\n- [ ] (1:30?) Also make it so that right when creating a project you get an easy option to create it as nonfree and even enter your credit card there if not done yet.  (So at least three chances/places to upgrade all integrated into the UI....)\n\n- [ ] (1:30?) get backend part of project move to work\n\n- [ ] (1:30?) get backend part of project move to respect subscription settings.\n\n\nthoughts: actually make subscription useful (e.g., move project, etc.):\n   - make we could add a notion of \"resources\" to a project, namely server(s) on which project can be run, which have certain quotas.\n   - for-pay projects will get *option* of running on different resources, which will change their quotas\n   - resource display will show current sync state of everything, load, etc.\n\nOptions:\n\n- Right when you open a project, instead of seeing Files..., you see a homepage for the project, with status information about it.  This could be a re-organized settings page with a pane about the project's location/state.\n\n- Just add a pane to project settings about project location.  Move it later.\n\nhttp://silviomoreto.github.io/bootstrap-select/\n\n   \n   \n\n- [ ] (1:00?)  function in hub to determine what subscriptions definitely really apply to a given project:\n - consult what's in database\n - then query stripe for confirmation (?)\n     \n\n## version 1 (usable by public to do something?)\n\n- [ ] (1:00?) for **now** only allow the owner to pay for a project or move it (change later)\n- [ ] (0:30?) when making card, put in default name based on their name, etc.\n- [ ] (1:00?) require password for some billing-related api operations.\n- [ ] (1:00?) admin setting so admins can change the stripe api keys\n- [ ] (1:00?) display subscriptions -- button to show more\n- [ ] (1:00?) display charges\n   - more details of each\n   - button to show more\n- [ ] (2:00?) non-US currency\n- [ ] (1:00?) define our first subscription.\n- [ ] (1:00?) replace ugly bootbox dialogs with nice modals in account billing page.\n\n## version 2 (polish)\n\n- [ ] a very simple summary box clearly stating, what a user is about to pay with the current settings. E.g. \"In total, SageMath Inc will recurringly charge you X every 1. day of a month.\" \n- [ ] consider switching to using https://github.com/stripe/jquery.payment for input formatting/validation\n- [ ] (1:00?) display charge cards -- button to show more\n\n### DONE\n\n\n## version 0 (before anybody uses)\n\n- [x] (0:32) (0:30?) refactor html of project quota to bootstrap columns\n\n- [x] (3:30+) (1:30?) ui -- get project move with nonfree upgrade implemented\n    - [x] move dialog\n    - [ ] redo with a proper modal dialog that can be used to:\n        - [ ] if select nonfree target and no subscription, ask to confirm upgrade request (checkbox)\n        - [ ] if select nonfree target and no card, ask for card\n\n- [x] (0:51) (0:45?) set default card\n- [x] (0:42) cancel subscription\n- [x] (0:05) (0:45?) #invalid -- seems to be not supported by stripe.  OK. change default billing method\n   - how to set payment method for subscription - by specifying card token using the source param.\n\n\n- [x] (1:00?)  edit billing method -- decided not to; instead user will delete and add new\n- [x] display customer info (so top 10 info about billing, subscriptions, and charge history), and display it all nicely.\n   - [x] (0:22) (0:45?) get customer info whenever billing tab clicked on (put a refresh button too)\n   - [x] (2:10) (1:00?) display charge cards \n   - [x] (0:55) (1:00?) display subscriptions\n   - [x] (0:24) (1:00?) display charges\n\n\n- [x] (0:58) (0:30?) remove billing method\n- [x] (1:20) (0:45?) add new billing method\n- [x] (2:45) (1:30?) create subscription\n\n- [x] (1:00?) list subscriptions\n- [x] (2:00) (0:30?) stripe_create_card\n- [x] (0:29) (0:30?) stripe_delete_card\n- [x] (0:11) (0:30?) stripe_update_card\n- [x] (0:45?) stripe_get_customer\n- [x] (0:15) (0:45?) stripe_get_plans\n- [x] (1:15) (0:45?) stripe_create_subscription\n- [x] (0:25) (0:30?) stripe_cancel_subscription\n- [x] (0:45) (0:30?) stripe_update_subscription\n- [x] (0:21) (0:45?) stripe_get_charges\n\n- [x] (0:17) (1:00?) create new stripe.[coffee/html/css] files and Stripe object, created at right time, etc., with all ui stuff invisible until creation, so can release safely.\n- [x] (0:45) (0:30?) add new subscription\n\n\n- [ ] (3:00?) actually make subscription useful (e.g., move project, etc.):\n   - make we could add a notion of \"resources\" to a project, namely server(s) on which project can be run, which have certain quotas.\n   - for-pay projects will get *option* of running on different resources, which will change their quotas\n   - resource display will show current sync state of everything, load, etc.\n\n","position":-7.444186327746138,"last_edited":1427737596126,"task_id":"7e645381-0a3b-47be-9fc2-273d30916907"}
{"desc":"","position":-6.856888771057129,"last_edited":1425251397117,"task_id":"6877a20e-3766-42f6-b028-0413ff1ecc94","deleted":true}
{"desc":"(0:04) (0:30?) #0 #bug #today\n\nThe new +New button ignores the directory when uploading files...","position":-7.40625,"last_edited":1426826519956,"task_id":"3ad16685-8063-48ee-befd-76aa7874caff","done":1426826519956}
{"desc":"(1:00?) #6 #bug\nlook carefully into whether images get their ttl properly extended on worksheet save for R images.\n\nExample with problems:\n\n   https://cloud.sagemath.com/projects/868087e6-5719-485a-b908-6217b437742c/files/Mathematical%20Statistics.sagews\n   \nRequestor: https://mail.google.com/mail/u/2/#inbox/149dd9a5ff8e5aeb   ","position":-6.856900930404663,"last_edited":1427813589087,"task_id":"ec91c0e1-ecb8-4676-b929-5afafe3cad0d"}
{"desc":"(1:15?) #1 #editor\nimplement copy-from-history button\n\nCould do all this:\n- pop up a dialog that requests filename, defaulting to current filename.\n- have a warning that a file will be overwritten (if it will be)\n\nOr just *do it*, which is probably fine given that it can be undone easily.\n\n- motivated by https://mail.google.com/mail/u/0/#inbox/14be518bc6d7a2ae","position":-6.856901288032532,"last_edited":1427813566858,"task_id":"b540570a-6b76-4b32-92e7-6df8ef9ddb51"}
{"desc":"(3:00?) #1 #com\nimplement account deletion\n\n- needed for commercialization\n- will have to decide where to \"put\" the corresponding projects -- maybe a special DELETED project (?).\n- otherwise probably straightforward.\n\nPeople to email:\n- [ ] https://mail.google.com/mail/u/2/#inbox/14c4603ff576620b\n- [ ] https://mail.google.com/mail/u/1/?ui=2&view=btop&ver=15iwqxmrupss2&search=inbox&th=14c94181bdd49595&cvid=10\n\nI will not throw away data until a waiting period.\n\nAny ideas on semantics?   I'm thinking:\n\n   - set a field in the database saying that the account is deleted\n   - delete password\n   - move any other authentication related info to a different field\n(e.g. email) and remove from the email_address_to_account_id table\n   - remove account_id from all projects user collaborates on\n   - if number of collaborators reaches 0 for any project, add that\nproject to a table of \"orphaned projects\"\n\nSomeday delete orphaned projects.\n\nThis seems like a safe way to have people delete accounts, but it can\nbe recovered from eventually...\n\nHarald says:\n> So, I don't know the database details, but in any case I would argue\nfor a \"grace period\" (correct word?) and be very cautious ... I mean,\nsomething where you just set a field \"deleted\" in the table for the\nusers to the \"current timestamp\" when they want to be deleted, and do\nnothing else, except:\n1. delete all cookies (like the sign-out everywhere does, right?)\n2. when a user who is \"deleted!=None\" tries to log in, give the\nmessage \"your account is deleted, please contact help@...\"\n2.1 if he then tries to sign up, *also* show the \"your account is\ndeleted, please contact help@...\" message.\n3. keep the all collaborators for projects, but do not show those who\nare deleted!=None\n4. if there is ever a way to contact collaborators (or some other way\nto contact users via the SMC platform), do not send messages to those\nwho are marked as deleted.\n5. 4. does also include mass-marketing emails, I saw that you have\nsome code for mass emails\nThis keeps everything in place and an account can be restored easily.\nFor the user, it looks like everything is reset.\nOnce every week, do a query for those who want to be deleted. Since\nthere is this deleted timestamp field, you can query for those who\nare, lets say, 2 weeks old or more, and then start that actual removal\nyou mentioned.\nA remaining issue are backups. IIRC the current TOS do give SMC a\npermission to store the data indefinitely, right? Hence, you do not\nhave to think about changing your backup strategy in order to get rid\nof the deleted project data.     (I'm pretty sure, this wouldn't be the case in the EU, but there are\nother things SMC would have to take care of to operate here)","position":-6.856901466846466,"last_edited":1428709697916,"task_id":"086eecf6-2c66-46c0-ab64-25a6db52be40"}
{"desc":"#6\nimplement realtime messaging between users (e.g., chat)\n\n- Article about google pub/sub: https://news.ycombinator.com/item?id=9145908","position":-7.25,"last_edited":1427813426495,"task_id":"31295a17-1dd7-4396-8073-6f832ac25df0"}
{"desc":"(0:12) (0:15?) #2\nmake smc=salvus as suggested by Jason Grout\n","position":-6.856901556253433,"last_edited":1425621322506,"task_id":"c33a6ed8-a5ec-4c91-b3dc-e9c03f24d23a","done":1425621322087}
{"desc":"(1:00?) #1 #bug #sagews #editor\ncan't insert new line in weird edge case involving ].  \n\nExample here: https://cloud.sagemath.com/projects/4a5f0542-5873-4eed-a85c-a18c706e8bcd/files/Last%20Bracket%20in%20comment.sagews\n\nFrom this list post: https://groups.google.com/forum/#!topic/sage-cloud/xOm5u6HqnGU","position":-6.85690151154995,"last_edited":1427813522716,"task_id":"63f43b05-ba70-43d2-94bd-30716c7e12d8"}
{"desc":"(1:15?) #sagews #3\nimprove figure sizes in print to pdf\n\nhttps://groups.google.com/forum/#!topic/sage-cloud/NOqwwqJj480\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14c1dda214be1da2","position":-6.856901600956917,"last_edited":1427286618879,"task_id":"dfdd5e1f-6971-4ef0-8eba-d093fe2eedcf"}
{"desc":"#feature #5\nmake it so users can easily customize css\n\nhttps://groups.google.com/forum/#!topic/sage-cloud/gyjPXkMm8Lc","position":-6.856901623308659,"last_edited":1426253562375,"task_id":"f217e2b7-2996-4577-bf63-9e3a68741d38"}
{"desc":"(1:15?) #1 #bug #sagews\nblock parsing issue\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14beb5e201d68cf0\n\n    the \"else\" in the following code raises a \"syntax\" error when run in a Sage Cloud cell:\n\n    try:\n        print \"try now\"\n    except:\n        print \"some exception\"\n    else:\n        print \"made it to else\"\n\n    *but* it runs normally if the code is in a function definition or even a junk for loop, like:\n\n    for i in [0]:\n        try:\n            print \"try now\"\n        except:\n            print \"some exception\"\n        else:\n            print \"made it to else\"\n\n    is this a bug, or is there some other reason to explain the difference in behavior?\n\n    thanks,\n\n    craig","position":-6.856901533901691,"last_edited":1426253580823,"task_id":"ac0ebc3f-9128-4cd0-83e1-fae832653864"}
{"desc":"(2:04) (0:45?) #now #bug #0 #today\ntwo people can't use the same terminal session!  \n\nit just keeps resetting\n\nThis turned out to be a basic problem with how sockets were setup/cached between the local and global hub, which wasn't reported by others since it was very unlikely to happen due to multiple hubs.   I also made sure tcp connections are being properly cleaned up, and generally improved reaping when client is destroyed.","position":-6.856902360916138,"last_edited":1425948958335,"task_id":"08389a79-93e8-47e7-859d-93431db27250","done":1425948957930}
{"desc":"(0:45?) #ui #5\nprogress meter when opening any project.","position":-6.856902003288269,"last_edited":1427813467725,"task_id":"e377b067-9435-4518-bdc8-778b47e11e5d"}
{"desc":"(1:00?) #bug #ui #5\nsnapshots/backups directory should *always* be displayed in date order, no matter what user pref is.","position":-7.3125,"last_edited":1427813418063,"task_id":"f99230e3-df9e-4913-9ad7-14f32a4f827b"}
{"desc":"(0:15?) #help #ui #1\nlink to new youtube video somewhere in help page\n\nhttp://youtu.be/_ff2HdME8MI","position":-7.34375,"last_edited":1426252984403,"task_id":"3da76dd0-c66a-45f2-bb48-335db09e2701","done":1426252983996}
{"desc":"(1:30?) #ipython #5\nprint to pdf via nbconvert\n\nBasically, use `ipython nbconvert --to latex` \n\nFixed: https://mail.google.com/mail/u/0/#inbox/14c05565b8f47040","position":-7.328125,"last_edited":1427206697196,"task_id":"420c1a11-b362-4f18-856d-8d4b7797f206"}
{"desc":"(0:16) (0:15?) #bug #1 #today\n\nwhen copying files between projects.\n\n\"Successfully copied support/2015-03-11-093745-axiom-integral.sagews to support/2015-03-11-093745-axiom-integral.sagews in undefined\"","position":-7.4453125,"last_edited":1427257159757,"task_id":"936146f2-b93f-48ba-8856-dfb14074396f","done":1427257159353}
{"desc":"(0:23) (0:30?) #0 #bug #public #today\nsharing a whole project publicly doesn't seem to make the files in it public, though they are listed as such","position":-7.453125,"last_edited":1427078334355,"task_id":"0f7c8613-01d7-43ae-aba5-9e1ab4004d65","done":1427078333943}
{"desc":"(5:00?) #translate #3\nMake SMC have UI language options for:\n\n  - turkish\n  - russian\n  - English\n  \nUse the code from https://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14c07f4ded3564fe  ","position":-7.326171875,"last_edited":1428069871634,"task_id":"6486c0e1-c56a-45dd-9e43-d76548f76548"}
{"desc":"(3:00?) #1 #ui #bug\nProper file rename and move\n\nE.g., https://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14c0e83cfe2804fe","position":-7.444186325650662,"last_edited":1427813355713,"task_id":"6cb2acb3-019e-4046-b8d5-1aaa782a46ac"}
{"desc":"(0:30?) #bug #sagews\nsagews cython issues\n\n- [ ] clicking on cython code link doesn't pop it up (link is right though)\n\n- [ ] Also, there is a deprecation warning:\n\n        /projects/4a5f0542-5873-4eed-a85c-a18c706e8bcd/.sagemathcloud/sage_server.py:920: DeprecationWarning: \n        Importing tmp_dir from here is deprecated. If you need to use it, please import it directly from sage.misc.temporary_file\n        See http://trac.sagemath.org/17460 for details.\n          code = code_decorator(code)","position":-7.444186321459711,"last_edited":1427838569424,"task_id":"d5453394-1eb3-4246-b0e8-afe114edaca9"}
{"desc":"(2:27+) #today #now (2:00?) #upgrade #ipython #1\nipython3 -- notebook version 4\n\n- [x] (4:00) disconnect and change each; totally breaks sync. Took a long time; fixing major and subtle sync issues...\n- [x] (0:30) ipython upgrade breaks command line sage: `ImportError: cannot import name warn_format_error`:  FIX: https://github.com/sagemathinc/smc-sage/commit/6818fb80e2bf6a61c38b1980e8a91f61a101768e\n\n- [x] (0:29)periodically watch for changes in the actual .ipynb file -- maybe every 5-10 seconds? NO -- too hard for now.   But at least make sure that changing file and opening works.`\n\n- [x] (0:14) notification history and syncdoc file formats...\n- [x] %load_ext sage\n- [x] (5:00) history slider\n\n\n\n\n\n\n\n- [x] (0:36) R kernel support: (follow https://github.com/IRkernel/IRkernel)\n        \n- [x] FAIL (1:04) #new Haskell kernel support - the ubuntu-install script fails to build some graphical tools (hence semicolon below). This build line takes about an hour!?\n\n\n- [x] (1:10) other kernels (e.g., julia), ipython3:\n\n   \t\tsudo pip3 install --upgrade ipython\n        sudo ipython3 kernelspec install-self\n        \n        Then edit /usr/local/share/jupyter/kernels/python3 and add a \"-E\" option in so that python3 can\n        start with the sage -sh environment set.\n        \n- ijulia support:\n\n        umask 022\n        sudo su\n        export JULIA_PKGDIR=/usr/local/share/julia/site/\n        julia\n        julia> Pkg.init()\n        julia> Pkg.add(\"IJulia\")\n \t\tcp -rv \"/root/.sage/ipython-2.3.0.p0/kernels/julia 0.3\" \"/usr/local/share/jupyter/kernels/julia 0.3\"\n        \n        {\n          \"display_name\": \"Julia 0.3.7\",\n          \"argv\": [\n            \"/usr/bin/julia\",\n            \"-i\",\n            \"-F\",\n            \"/usr/local/share/julia/site/v0.3/IJulia/src/kernel.jl\",\n            \"{connection_file}\"\n          ],\n          \"language\": \"julia\"\n        }\n\n\n---\n\nhttps://mail.google.com/mail/u/2/#inbox/14c229fd5f9407ea\n\nIdeas: https://mail.google.com/mail/u/2/#inbox/14c229fd5f9407ea\n\nformat version 4.\n\n    The attached IPython Notebook has the format version 4. This is the\n    default for IPython 3 and upwards. SMC runs IPython 2.3.x, which is\n    too old to understand the version 4 format ... only version 3.\n    Therefore, you have to convert your notebook to v3 before running it\n    on SMC.\n\n    You can do this in the terminal via:\n\n    ipython nbconvert --nbformat=3 --to notebook \"Fails-Answers to Actual\n    Exam 3.ipynb\"\n    \n    \nDoing\n\n- [x] `umask 022` then `sage -sh` then `pip install --upgrade ipython jsonschema mistune`\n- [x] change the ipython notebook logo to jupyter...?\n- [x] testing with this disabled: `websocket_reconnect`\n- [x] disable autosave\n- [x] refactor code out\n- [x] nbviewer stuff: test that public display works and ALSO producing the thing.\n- [x] (1:33) change so instead of /port/port-number one gets the ipython notebook server via /port/jupyter.  This would fix the reconnect issue on server restart/move, simplify code, etc.  It's much, much more logical. \n- [x] (0:23) load jupyter static resources through nginx for much better speed... Change `/usr/local/sage/current/local/lib/python/site-packages/IPython/html/notebookapp.py` as follows (then type `/usr/local/bin/ipython notebook`):\n\n\t\t#static_url_prefix = url_path_join(base_url,'/static/'),\n        static_url_prefix = url_path_join('/static/jupyter/'),\n","position":-7.444186296314001,"last_edited":1428355515395,"task_id":"4983adf9-0549-426c-a9fe-a18281aa9f20","done":1428355514992}
{"desc":"(1:00?) #bug #md\nmarkdown printing title issue\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14c1e1e28cd397b7","position":-6.856901578605175,"last_edited":1427813490605,"task_id":"cb997db0-a22d-43b9-95ee-d58be8633208"}
{"desc":"#bug\nweird PATH issues:\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14c1ad72958f4d28\n\nWhen I do the following I see repeated entries in the PATH variable.\n\n        Ralf\n\n        ~$ for l in $(echo $PATH |sed \"s|$HOME|\\$HOME|g;s/:/ /g\"); do echo $l; done\n        $HOME/.sagemathcloud\n        $HOME/.sagemathcloud\n        $HOME/.sagemathcloud/node_modules/coffee-script/bin/\n        $HOME/.sagemathcloud/node_modules/.bin/\n        $HOME/.sagemathcloud/data/local/bin\n        $HOME/bin\n        $HOME/.sagemathcloud\n        $HOME/.sagemathcloud/node_modules/coffee-script/bin/\n        $HOME/.sagemathcloud/node_modules/.bin/\n        $HOME/.sagemathcloud/data/local/bin\n        $HOME/bin\n        $HOME/.sagemathcloud\n        $HOME/.sagemathcloud/node_modules/coffee-script/bin/\n        $HOME/.sagemathcloud/node_modules/.bin/\n        $HOME/.sagemathcloud/data/local/bin\n        $HOME/bin\n        $HOME/.sagemathcloud\n        $HOME/.sagemathcloud/node_modules/coffee-script/bin/\n        $HOME/.sagemathcloud/node_modules/.bin/\n        $HOME/.sagemathcloud/data/local/bin\n        $HOME/bin\n        /usr/local/bin\n        /usr/bin\n        /bin\n        /usr/local/games\n        /usr/games","position":-6.856901567429304,"last_edited":1426550644045,"task_id":"a3519946-a72f-4ecc-bfc9-71b362efaec5"}
{"desc":"(1:00?) #bug #5\n`bup_storage.py stop` needs to account for lock files, both for user and group\n\n    root@compute4dc1:/projects/509eed88-d82a-4cb8-a66b-b93681b96a3e# bup_storage.py --zpool bup stop 509eed88-d82a-4cb8-a66b-b93681b96a3e\n    stop(project_id=509eed88-d82a-4cb8-a66b-b93681b96a3e,{}):\n    killall(project_id=509eed88-d82a-4cb8-a66b-b93681b96a3e,{}):\n    killall(project_id=509eed88-d82a-4cb8-a66b-b93681b96a3e,{}): killing all processes by user with id 1860766618\n    /usr/bin/killall -u 509eed88d82a4cb8a66bb93681b96a3e\n    /usr/bin/pkill -u 1860766618\n    /usr/bin/killall -9 -u 509eed88d82a4cb8a66bb93681b96a3e\n    /usr/bin/pkill -9 -u 1860766618\n    pgrep -u 1860766618\n    killall(project_id=509eed88-d82a-4cb8-a66b-b93681b96a3e,{}): kill attempt left 0 procs\n    /usr/sbin/userdel 509eed88d82a4cb8a66bb93681b96a3e\n    /usr/sbin/groupdel 509eed88d82a4cb8a66bb93681b96a3e\n    zfs set userquota@1860766618=none bup/projects\n    (0.00465106964111 seconds):\n    zfs set userquota@1860766618=none bup/scratch\n    (0.0046169757843 seconds):\n    fusermount -uz /projects/509eed88-d82a-4cb8-a66b-b93681b96a3e/.snapshots\n    total time: 0.589437007904 seconds\n    root@compute4dc1:/projects/509eed88-d82a-4cb8-a66b-b93681b96a3e# vi /etc/passwd\n    root@compute4dc1:/projects/509eed88-d82a-4cb8-a66b-b93681b96a3e# vi /etc/passwd\n    root@compute4dc1:/projects/509eed88-d82a-4cb8-a66b-b93681b96a3e# /usr/sbin/userdel 509eed88d82a4cb8a66bb93681b96a3e\n    userdel: existing lock file /etc/subuid.lock without a PID\n    userdel: cannot lock /etc/subuid; try again later.\n    root@compute4dc1:/projects/509eed88-d82a-4cb8-a66b-b93681b96a3e# more /etc/subuid.lock\n    root@compute4dc1:/projects/509eed88-d82a-4cb8-a66b-b93681b96a3e# rm /etc/subuid.lock\n    root@compute4dc1:/projects/509eed88-d82a-4cb8-a66b-b93681b96a3e# /usr/sbin/userdel 509eed88d82a4cb8a66bb93681b96a3e\n    userdel: existing lock file /etc/subgid.lock without a PID\n    userdel: cannot lock /etc/subgid; try again later.\n    root@compute4dc1:/projects/509eed88-d82a-4cb8-a66b-b93681b96a3e# ls -lht /etc/subgid.lock\n    -rw------- 1 root root 0 Feb 25 22:43 /etc/subgid.lock\n    root@compute4dc1:/projects/509eed88-d82a-4cb8-a66b-b93681b96a3e# rm /etc/subgid.lock\n    root@compute4dc1:/projects/509eed88-d82a-4cb8-a66b-b93681b96a3e# bup_storage.py --zpool bup stop 509eed88-d82a-4cb8-a66b-b93681b96a3e\n    stop(project_id=509eed88-d82a-4cb8-a66b-b93681b96a3e,{}):\n    killall(project_id=509eed88-d82a-4cb8-a66b-b93681b96a3e,{}):\n    killall(project_id=509eed88-d82a-4cb8-a66b-b93681b96a3e,{}): killing all processes by user with id 1860766618\n    /usr/bin/killall -u 509eed88d82a4cb8a66bb93681b96a3e\n    /usr/bin/pkill -u 1860766618\n    /usr/bin/killall -9 -u 509eed88d82a4cb8a66bb93681b96a3e\n    /usr/bin/pkill -9 -u 1860766618\n    pgrep -u 1860766618\n    killall(project_id=509eed88-d82a-4cb8-a66b-b93681b96a3e,{}): kill attempt left 0 procs\n    /usr/sbin/userdel 509eed88d82a4cb8a66bb93681b96a3e\n    (0.119844913483 seconds):\n    /usr/sbin/groupdel 509eed88d82a4cb8a66bb93681b96a3e\n    zfs set userquota@1860766618=none bup/projects\n    (0.00463485717773 seconds):\n    zfs set userquota@1860766618=none bup/scratch\n    (0.00438094139099 seconds):\n    fusermount -uz /projects/509eed88-d82a-4cb8-a66b-b93681b96a3e/.snapshots\n    total time: 0.684422969818 seconds","position":-6.856901561841369,"last_edited":1427813502174,"task_id":"3790e8f6-d11e-4ddd-aa81-fcf4ce83ecc1"}
{"desc":"(1:30?) #1 #bug\nrewrite ipython daemon startup to work 100% even on load -- not possible to DOS machine.  Probably need a lock file.","position":-7.37890625,"last_edited":1428504016380,"task_id":"b029ef51-09d8-4ebb-ac29-5d4720ed44f3","done":1428504015964}
{"desc":"(0:28) (0:45?) #1 #bug #today\nkeyboard shortcuts for tasks conflict with searching in the notification box.","position":-7.421875,"last_edited":1426826247034,"task_id":"6ac35ebe-a31d-4df2-ba04-d981ff10fe66","done":1426826246628}
{"desc":"(0:45) (1:00?) #1 #today #now\nif `bup_storage.py` fails which results in an error (e.g., traceback when doing status), it should run stop first on that project and try again.  This is important to fix!","position":-7.3828125,"last_edited":1427082144533,"task_id":"79d6cbac-cee4-4cfb-bbe4-620fd20378e6","done":1427082144129}
{"desc":"#install\nmayavi install help\n\nhttps://mail.google.com/mail/u/0/#inbox/14c263be9a282d63","position":-7.367431640625,"last_edited":1427206529905,"task_id":"e825f9a1-da88-4506-a8f9-72fc79db9792"}
{"desc":"(0:30?) #5\nmathbook xml demo \"private beta\"\n\nhttps://mail.google.com/mail/u/0/#inbox/14c25eddde6bd54d","position":-7.444186313077807,"last_edited":1428878865151,"task_id":"95140ab4-e199-4478-9af7-b037ef472ec0","done":1428878864730}
{"desc":"#3\nrequest to build root library from source differently.\n\nhttps://mail.google.com/mail/u/2/#inbox/14c290ca76dcce7c","position":-6.856901559047401,"last_edited":1428069851273,"task_id":"c718ee4d-bf78-4fe4-8f63-a2cac704b504"}
{"desc":"(2:25) #now (1:30?) #1 #today\nrudimentary handling of zip files.","position":-7.46875,"last_edited":1427070747807,"task_id":"17898fb5-8eba-4a87-9446-606ba2a81412","done":1427070747394}
{"desc":"(1:30?) #4\nmake it possible to set the default login shell for a project\n\nSee https://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14c3e57d74c6b183\n\nProbably want to make this part of project configuration, then add to bup_storage.py, etc.","position":-7.373046875,"last_edited":1427812942615,"task_id":"611cd679-8b43-47cf-8474-328e841fab45"}
{"desc":"(0:45?) #2 #speed #unclear\nthe `git-ls` command can be slow; maybe just parse ls (?)","position":1.90625,"last_edited":1427813741555,"task_id":"2041e17c-8274-4d1a-80e9-c4f41ff461ba"}
{"desc":"(0:27) (0:20?) #0 #today #bug\ndisable forever loging for hub, which wastes space","position":-7.4296875,"last_edited":1427080218559,"task_id":"98fbbd4d-01a8-4dc5-92c1-9ccd6ad88e3c","done":1427080218145}
{"desc":"(1:28) (0:30?) archive #today\n- [ ] support .tar.bz2, .tar.gz, .tar","position":-7.43359375,"last_edited":1427088117792,"task_id":"66c7cf38-4929-4308-9fba-e3b44b787ad7","done":1427088117390}
{"desc":"(0:24) change python used for the scripts in ~/.sagemathcloud, to make things more robust in case user messes up their python install.","position":-7.435546875,"last_edited":1427125424437,"task_id":"a99823d6-387c-4f78-a6db-b073b6a8ce4a","done":1427125424026}
{"desc":"(0:42) (1:00?) #today #archive\nmake it so extracting archive will optionally (by default) create a directory if none","position":-7.376953125,"last_edited":1427128056523,"task_id":"d94d9b9d-7bcc-4183-a8f2-43da159a9eff","done":1427128056113}
{"desc":"(2:00?) #ui #1\nre-implement file drag and drop, at least if number of files isn't too big (?)","position":-7.3759765625,"last_edited":1427812924432,"task_id":"359ec701-68f7-46fd-aabd-d1dd1b65dac2"}
{"desc":"(0:30?) #archive #mobile #bug #4\nmake archive mobile-friendly with a close button","position":-7.37548828125,"last_edited":1427812931240,"task_id":"e9d11398-dc1b-47c6-999d-e8f0044fbacb"}
{"desc":"(1:00?) #2 #upgrade\nupgrade codemirror -- https://mail.google.com/mail/u/0/#inbox/14c466515a4ddfc3","position":-6.856901433318853,"last_edited":1428539663867,"task_id":"8bde9fe0-32a3-4389-b798-a62d3a2a9e8b"}
{"desc":"(6:00) (1:30?) #sagews #now\nimplement `raw_input` in sagews\n\n(ended up taking way longer than I thought, and using a completely different approach.  Resulted \nin rewriting some things much more efficiently involving rendering worksheets, which might fix some important bugs.)\n\nreplace the built-in raw_input function by a special SMC one that:\n\n- [ ] sage server: new output type which is called raw_input; implement in server and client\n\n\t     {raw_input:{prompt:'input stuff?', value:'', submitted:false}}\n\n- [ ] as user types, change the document to reflect their input so far; then everybody will see. \n         \n\t     {raw_input:{prompt:'input stuff?', value:'william', submitted:true}}\n         \nOnce somebody sets done=true, all prompts change to have a checkbox or something and be read-only.         \n         \n- [ ] in the `raw_input` python function running in server, after sending the raw_input output, switch to a mode where it waits for exactly one raw_input message in response from client.\n\n- [ ] When done:true for a raw_input when sage server in waiting state,  then local_hub sends message to sage_server containing the value.\n\n- [ ] In raw_input, handle that one raw_input message and move on.","position":-6.856813311576843,"last_edited":1427737349416,"task_id":"eb2b926e-62d4-4879-9972-2c8d76e1333a","done":1427737349013}
{"desc":"(0:15) (0:30?) #install  #today\nfricas as a new Sage optional package\n\nhttps://mail.google.com/mail/u/2/#inbox/14c0e22836d73fef","position":-7.3271484375,"last_edited":1427257177858,"task_id":"ca4727da-86eb-487e-a23a-66f7c8b4c5d2","done":1427257177452}
{"desc":"(0:30?) #sagews #bug\nimplement printing `raw_input`","position":-7.32666015625,"last_edited":1427208196832,"task_id":"7c7f9cce-0f17-4997-8c73-a99d8a3b8a05"}
{"desc":"(1:30?) #sagews #bug\n`raw_input` inside an interact -- need to implement support for clear and delete_last_output, i.e., for the output message series changing...","position":-7.326416015625,"last_edited":1427208178583,"task_id":"bc21522b-116f-4c5d-a2d1-1a6cc0af4892"}
{"desc":"(1:10+) (2:00?) #1 #today\nmake this url display copyright statement, read from a static file (?)\n\n- [ ] https://cloud.sagemath.com/articles/copyright\n- [ ] https://cloud.sagemath.com/articles/terms\n- [ ] https://cloud.sagemath.com/articles/pricing\n- [ ] https://cloud.sagemath.com/articles/privacy\n\nBasically make https://cloud.sagemath.com/articles a static nginx-served site. Also link to each item from within SMC.\n\nAsk if a tl;dr; is dangerous -- https://mail.google.com/mail/u/2/#inbox/14c4cd26fbc6731e","position":-6.856902718544006,"last_edited":1427242736142,"task_id":"5c9974a6-d1df-41f7-8792-111f1533295a","done":1427242735725}
{"desc":"(1:00?) #1 #today\nmake this url display fees, read from a static file (?)\n\n  https://cloud.sagemath.com/articles/pricing","position":-6.856902539730072,"last_edited":1427215962170,"task_id":"042b0739-6a41-49c5-81c8-f8eef1385334","deleted":true}
{"desc":"(0:43) (0:30?) #today\n\n- [ ] make new terms of service live for new accounts and from help page.","position":-7.326904296875,"last_edited":1427245416939,"task_id":"bb1342fb-dbb2-45ea-ae0f-9e5936436869","done":1427245416534}
{"desc":"(0:30?) #latex #feature\nblock comment/uncomment button","position":-7.32763671875,"last_edited":1427285826616,"task_id":"8c7d4c87-ce79-4746-9a89-7583c4ddcf74","deleted":true}
{"desc":"(2:30?) #latex #2\nmake the new latex editing bar live for the latex editor itself.\n\n- [ ] fix the comment/uncomment button to properly work for multiple lines\n\nEmail this when done: https://mail.google.com/mail/u/0/#inbox/14c50d587e1469e6","position":-7.327880859375,"last_edited":1427813366984,"task_id":"4d61c0e4-9d18-46b9-b166-2b199f7a8608"}
{"desc":"(0:30?) #ui #4\nproject tabs should have a tooltip showing the full project name (like file tabs)","position":-7.3277587890625,"last_edited":1427286235627,"task_id":"30bcbfa4-d10e-4857-9847-4fbfbcea0b8e"}
{"desc":"(4:00?) #2 #today\nimplement a first basic single sign on -- will help with growth and commercialization\n\n- [x] (4:20) get a complete basic demo using passport to work; this took forever because of realizing I should rewrite the web server to use express (done), then running into a lot of problems due to changes in Express 4 versus previous versions of Express, which led to silent failure.  Figured out solutions by printing print statements in the passport source code...\n\n- [x] (2:08) (1:00?)  basic demo test using one of google/facebook/github/wordpress (?) or something:\n    - spent about 20m dealing with my own firewall blocking the google oauth server.  Fixed.\n    - next problem: the recommended library passport-google uses openid2, which is deprecated in a few days!   So instead, I have to use oauth2, which is in https://github.com/jaredhanson/passport-google-oauth, which I found by luck!\n    - and many more problems... documented internally. \n- [x] (0:30) (0:45?) similar demo as above, but for github.\n- [x] (0:13) (0:20?) passport for facebook\n- [x] (0:20) (0:20?) passport for dropbox\n- [x] (0:29) (0:20?) passport for bitbucket -- harder due to lack of oauth2...\n- [x] (0:21) (0:20?) passport for wordpress\n- [x] (0:13) (0:20?) passport for twitter\n\n\nJust spent 2:30+ figuring out how these things work, but not implementing anything.  And planning.\n\nIdeas:\n- When creating an account, have a button for username/password, facebook, github, google, and wordpress (for now).\n- When auth'd, record info about user in accounts table for that auth method, so have\n  - fields: 'auth_google', 'auth_local', 'auth_facebook', 'auth_github', 'auth_wordpress', \n  - value: {'id':..., etc.}\n- Move existing password hash field to `auth_local`.\n- Redo the table `email_address_to_account_id` to be: `passport_token_to_account_id`, which is a map:\n        provider-id --> account_id\n  so we make the key the string got by combining the provider and the id, with a dash.\n  This way we can have multiple authentication methods for a user.\n  Will have to change all existing stuff to `local-email_address`.  \n- Add new field to accounts which is called \"search_name\", which replaces existing ones.  The search_name can combine together all name fields, so only have to query that one thing when doing full text search.  Whenever we update auth stuff for a user, also update the search_name field. \n- Extend user search to allow restricting to users that have linked their profile with Google/Github/etc. and do that search separately.\n\nEmails to respond to:\n- https://mail.google.com/mail/u/0/#inbox/149c8ee81aaca138   \n- https://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14bc1d38c071e9ff\n\n\nOn servers to set this up, will need to:\n\n    npm install --upgrade passport\n    npm install passport-dropbox-oauth2\n    npm install passport-facebook\n    npm install passport-github\n    npm install passport-google-oauth\n    npm install passport-local\n    npm install passport-wordpress\n    npm install passport-twitter\n    npm install passport-bitbucket\n    npm install express-session\n    npm install body-parser\n    \nIn Cassandra:\n\n\n    CREATE TABLE passport_settings (\n        strategy varchar PRIMARY KEY,\n        conf     map<varchar:varchar>\n    );\n\nExample of entering some *testing* credentials:\n\n    update passport_settings set conf['auth']='https://william.wstein.org/auth' where strategy='site_conf';\n\n\tupdate passport_settings set conf['clientID']='...' where strategy='google';\n    update passport_settings set conf['clientSecret']='...' where strategy='google';\n    ","position":-7.4405517578125,"last_edited":1427550694181,"task_id":"06ebb41c-cf63-4c65-82f4-8759d315cd9d","done":1427550693775}
{"desc":"(0:07) (0:30?) #today\nmerge in harald's new terms of service\n","position":-7.4365234375,"last_edited":1427289165025,"task_id":"0936c228-3dd0-4b4c-ab7c-5aa2b577f483","done":1427289164612}
{"desc":"(0:30?) #1 #bup #bug #security\nsparse files -- if the user creates a massive sparse file (not in an excluded directory), the bup save process will spin at full cpu forever, basically DOS'ing that computer.  NOT GOOD.\n\n**Solution:** Make use of this bup option!\n\n      --smaller=maxsize\n              don't  back  up files >= maxsize bytes.  You can use this to run\n              frequent incremental backups of  your  small  files,  which  can\n              usually  be  backed  up  quickly, and skip over large ones (like\n              virtual machine images) which take longer.  Then you can back up\n              the  large  files less frequently.  Use a suffix like k, M, or G\n              to  specify   multiples   of   1024,   10241024,   10241024*1024\n              respectively.","position":-7.444186262786388,"last_edited":1428102562298,"task_id":"b57c8e5e-286b-4ca0-b951-d5ec80480f7c"}
{"desc":"#9 #feature #editor\n\nconsider incorporating http://webodf.org/demos/ into SMC, so we can view/edit odf and docx files better.","position":-7.4404296875,"last_edited":1427812838386,"task_id":"089c9fca-924b-496a-9843-635e957e8545"}
{"desc":"(2:25) (2:00?) #today #now #hub\nrewrite hub webserver to use express, so that I can use passport for auth.\n\n- [ ] ** read basics of express\n- [ ] try to migrate simple url parameters\n- [ ] deal with tricky cookies stuff carefully!","position":-7.44091796875,"last_edited":1427332395930,"task_id":"44241df0-64e7-4e36-8f8c-0b846d1fa802","done":1427332395516}
{"desc":"(0:30?) #1 #security #critical\ndelete password immediately after submitting for login\n\n- it seems like maybe on first loging (or account creation?) the DOM still has the user password in it.  That's a security risk and serves no purpose.\n\n","position":-7.440673828125,"last_edited":1427810863757,"task_id":"6125e816-d712-4ade-9882-cc9dd7da645d"}
{"desc":"(1:15?) #optimize #7\nadd an optional in-memory cache for key:value store so don't hit database every time certain queries like this in hub happen:\n\n    database.key_value_store(name:'global_admin_settings').get","position":1.935546875,"last_edited":1427327932804,"task_id":"b0fdaea3-da40-4100-acaa-5b7b718ac343"}
{"desc":"(0:35) (1:00?) #0  #bug #today\nmore usage data link is broken for people who don't own the stats project!  it downloads the file rather than serving it...\n\nThis probably represents a very serious pub in making raw stuff public with the headers.\n\nSimilar bug report about pdf's","position":-7.44415568956174,"last_edited":1427760878789,"task_id":"566f8391-f871-436e-b108-6c782fb6e8e3","done":1427760878382}
{"desc":"","position":-7.3280029296875,"last_edited":1427392026063,"task_id":"d2be34b0-a5ce-45ca-8ea9-3e8ca9de2166","deleted":true}
{"desc":"(0:45?) #bug #tasks #7\ndue date not in red when on the *same* day.  \"E.g., about 21 hours ago\"","position":-7.32781982421875,"last_edited":1427392771559,"task_id":"ba881e23-9292-4e28-bf0f-019608ba0367"}
{"desc":"(1:30?) #5 #com\nidle timeout status. \n\nhave an api and ui that shows how long until the project idle timeouts.   User will see which actions trigger increasing the timer.  Have link to upgrade project right there.  Part of the pitch, but also clarifies things. Critical.\n","position":-7.4423828125,"last_edited":1427812807941,"task_id":"b813180b-f626-4be6-aa3e-2a9a53964990"}
{"desc":"#idea\ncodenvy -- development ideas\n\n - https://codenvy.uservoice.com/forums/183121-general\n - request for feedback: https://mail.google.com/mail/u/0/?pli=1#sent","position":1.93359375,"last_edited":1427812690072,"task_id":"a0b43f77-a039-4670-aa4c-3834b7945ba4"}
{"desc":"(days?) #7\nimplement oauth2 server developer support\n\nSee this email for how -- https://mail.google.com/mail/u/2/#search/api/14c532da99c66c3a\n\nIn particular, will use this library: https://www.npmjs.com/package/node-oauth2-server","position":-7.444091796875,"last_edited":1427812441408,"task_id":"cbe4c7b1-6ade-4db2-9a48-d4c2cd22ca4f"}
{"desc":"#today #passport\n\n- design and make this work properly (including adding new connections), and implement\n\nWhat's the plan?  So, I can now do the oauth dance for google, github, facebook, dropbox, bitbucket, wordpress, twitter.  There are two things to do:\n- allow account creation by clicking on a button for one of those sites; will need a url that returns the *supported* passport sites, e.g., auth/sites; then the client ui can display buttons for them during signup\n- allow linking an existing account with any of these sites.\n- allow disabling local password-based login\n- LATER: use linking for something besides login in some cases.\n- I think facebook/twitter don't have email addresses; that only impacts searching.\n\n## PLAN:\n\n- [x] (0:15) (0:30?) implement auth/strategies url\n- [x] (0:47) (1:00?) implement showing buttons during account creation based on auth/sites\n- [x] (3:49) (2:00?) #now implement account creation via passport for each strategy; will involve making some decisions about how to store profile info in database, dealing with route handling, etc.\n\n        CREATE TABLE passports (\n            id         varchar,\n            strategy   varchar,\n            account_id uuid,\n            profile    varchar,   /* raw user profile that we got from the authentication provider */\n            activated  boolean,\n            PRIMARY KEY(id, strategy)  /* id is first so it is the cluster key, so data more smoothly distributed, rather than grouped by strategy */\n        );\n        \n        alter table accounts add  passports map<varchar, varchar>;\n\n- [x] critical point: we don't want to *trust* the oauth providers to provide valid emails.  E.g., if my account is as wstein@example.com, and some random joe (say at github!) makes a github account with that email by hacking their system, they shouldn't get access to my account.  So when we add a passport, if there is already a login/password account, we should require authentication again before activing the passport.\n\n- [x] (1:30) (2:00?) implement login via passport:\n    - if passport is activated, set remember_me for cookie and login\n- [ ] change the     \n- [ ] (1:00?) in account settings, clicking on button to add linked account\n- [ ] (0:45?) click on button to unlink a linked account.\n- [ ] #invalid (1:00?) If passport is not activated, display a form requesting their password (showing the user profile!) and include a token in it; when submitted it will activate that profile.  \n- [ ] things like \"change email\" that require a password can't require one if passports are *only* auths...\n- [x] Loading 'Undefined\" (spinner) -- should be just Loading...?\n- [x] (1:00?) implement in account settings showing what o-auth strategies are available/setup\n- [ ] (1:00?) let user connect their account with new authentication mechanisms.\n- [x] (0:30?) deal with oauth1 secret issue.\n- [ ] make terms of service purely client side\n- [ ] oauth + registration token --deal with this somehow...\n\n## (Much) LATER?...\n- [ ] (3:00?) enhance collab search with checkboxes to restrict to users who have linked their acocunt using an auth/site","position":-7.4442138671875,"last_edited":1427550377329,"task_id":"ba20b267-791d-4a63-a80e-6c4bc38f4dcf","done":1427550376913}
{"desc":"(2:00?) #1 #com #security\nintroduce a \"number of projects\" quota, since it would be easy to DOS SMC by creating lots of projects.\n\nMake it possible to raise quota via an email request.","position":-7.44415283203125,"last_edited":1428069739509,"task_id":"2069a40e-209b-46bd-aaa9-d0334d973048"}
{"desc":"#now (1:24) (1:00?) #today #passport\npassport: make login use the remember_me cookie to associate with an account (if remember_me is available), rather than using an email search (it will still do search, but instead as warning, and have an option)","position":-7.444188117980957,"last_edited":1427562329325,"task_id":"95fd14cf-751d-482c-8731-fd9d20c7d29d","done":1427562328921}
{"desc":"(1:00?) #today #passport\nif email is already in use, given user the choice of creating new account, or login with that email instead, then link","position":-7.444185972213745,"last_edited":1427583049180,"task_id":"9eedddae-eb7b-4dff-9e69-c727dd3b76e9","done":1427583048772}
{"desc":"(1:00?) #today #passport\nin account settings, when clicking on passport button that isn't already configured, pop up dialog saying \"This will link...\", then actually do it (by popping up separate window to complete process).","position":-7.444160461425781,"last_edited":1427582323636,"task_id":"3185ee57-f0f8-486e-a677-7b9c368bd6b4","done":1427582323230}
{"desc":"(0:45?) #today #passport\nin account settings, when clicking on passport button that is configured, pop up dialog saying \"This will unlink...\".  Implement that backend message to do unlinking.","position":-7.444156646728516,"last_edited":1427582326260,"task_id":"3c709fbe-55f7-4f9f-be13-5a979a817a06","done":1427582325845}
{"desc":"(0:04) (0:30?) #today #passport\ncompletely remove anything related to \"activated\" and passports from the backend code/database setup -- bad idea.","position":-7.4441986083984375,"last_edited":1427551769930,"task_id":"72c8bb47-92b7-4177-b872-20fa19998ad7","done":1427551769528}
{"desc":"#now (0:53) (0:30?) #today #passport\nterms of service requirement when doing passport account creation","position":-7.444190979003906,"last_edited":1427555052185,"task_id":"25e8c271-13bc-4daf-bd36-8e0c71bef65b","done":1427555051778}
{"desc":"(2:25) (1:15?) #now #today #passport\npassport: changing password and change email in account settings need to be aware that user might not have a password/email.\n\n- [ ] (0:45?) setting email in first place, require setting a new password (not getting an old one)\n- [ ] (0:30?) can't set password if no email\n\ntook longer since I ended up having to refactor and revamp a lot of code...","position":-7.444186687469482,"last_edited":1427570857224,"task_id":"f02083e3-5512-4542-badd-11b411865e94","done":1427570856824}
{"desc":"(1:41) (1:30?) #today #passport\nmake it so there are two types of logout: (1) normal sign out on a single client, and (2) sign out everywhere, which invalidates all remember me cookies for all clients, even for oauth-based logins.\n\n- [x] (0:30?) add the remember_me cookies made in passport_login to the accounts table properly.\n- [x] (0:30?) add ui stuff to have two versions of sign out (and move button to the right); put a conf for the second sign out\n- [x] (0:30?) backend messaging for each type of sign out.","position":-7.444186329841614,"last_edited":1427590006092,"task_id":"1511a5d2-115e-492f-aabb-03d0392c7433","done":1427590005681}
{"desc":"(2:30?) #0 #passport\ndeploy passport stuff live\n\n- [x] (0:05?) Create database schemas:\n\n\n        CREATE TABLE passport_settings (\n            strategy varchar PRIMARY KEY,\n            conf     map<varchar, varchar>\n        );\n        \n        CREATE TABLE passports (\n            id         varchar,\n            strategy   varchar,\n            account_id uuid,\n            profile    varchar,   /* raw user profile that we got from the authentication provider */\n            PRIMARY KEY(id, strategy)  /* id is first so it is the cluster key, so data more smoothly distributed, rather than grouped by strategy */\n        );\n        \n        alter table accounts add  passports map<varchar, varchar>;\n        \n- [x] (0:20?) install npm dependencies\n\n        npm install --upgrade passport\n        npm install passport-dropbox-oauth2\n        npm install passport-facebook\n        npm install passport-github\n        npm install passport-google-oauth\n        npm install passport-local\n        npm install passport-wordpress\n        npm install passport-twitter\n        npm install passport-bitbucket\n        npm install express-session\n        npm install body-parser\n    \n\n- [x] (0:05?) make sure to do ./update_version for a commit.\n\n- [x] (0:30?) push code to vm's, restart servers, test\n\n","position":-7.444156169891357,"last_edited":1427722958950,"task_id":"a6b4ebe5-78fb-45fc-b30f-67db04d21085","done":1427722958537}
{"desc":"(0:35+) (2:00?) #1 #passport\nmultiple email addresses per account, with email address verification and do the account creation actions only on email address verification.\n\n- [ ] (0:15?) consider oauth-provided emails as verified\n- [ ] (0:30?) ui button and api calls to send verify email message for non-verified addresses\n- [ ] (0:30?) automatically send verify email whenever email addresses added/changed\n- [ ] (0:45?) handling code for verification link clicking and then doing account creation actions for that email (and marking them done); don't do \"account creation accounts\" until verify happens.\n","position":-7.444155693054199,"last_edited":1427810840855,"task_id":"a6ad7d75-a5a3-4312-878b-dc505165f92e"}
{"desc":"(1:00?)  #passport #1 #security\nrequire secret token, even for social sign up\n\n(could do by setting a random 1-time cookie in browser that's also in db)","position":-7.444153308868408,"last_edited":1428070078476,"task_id":"03138356-45f3-44a9-a450-517591d86101"}
{"desc":"#accounts #feature #unclear #9\nsupport login via multiple accounts at once (?)\n\n- [ ] change the remember_me cookie name to also include the account_id?\n- [ ] have remember_me cookie itself contain the account id's?\n- [ ] in url have a ?account_id= option... or put it in the URL (ugh).   don't know.\n\nNOT SURE if this is a good idea or what. Google's way sucks.","position":1.921875,"last_edited":1427812284688,"task_id":"d92e28db-a2cf-48c6-a85a-8621f57f1bc4","done":0}
{"desc":"(3:00?) #today\nshutdown all compute vm's at dc2\n\nI have no good code for eliminating a machine!\n\n- [x] (0:25) write such code.\n- [x] (0:15) also write backup code\n- [x] create backup and spot check\n- [x] (2:00?) debug/test decommission code, and run...\n","position":-7.4441550970077515,"last_edited":1427694027439,"task_id":"fbefe5c3-d841-4a8b-87e7-e3c9f4f2fdb1","done":1427694027030}
{"desc":"","position":-7.44415420293808,"last_edited":1427812873054,"task_id":"df533abc-721e-429e-b8e6-6685f3ebf44a","deleted":true}
{"desc":"#today#0\n\n","position":-7.444155544042587,"last_edited":1427638995522,"task_id":"24feae13-3bcc-4c8a-ae41-77b077b4eb06","deleted":true}
{"desc":"#install #5\nbokeh request: d3-based python graphics http://bokeh.pydata.org/en/latest/\n\n - https://mail.google.com/mail/u/2/#inbox/14c6302477f502a4","position":-7.444154649972916,"last_edited":1427812365484,"task_id":"53b103ab-7f69-44ee-8983-fa5292442666"}
{"desc":"(0:31) (0:10?) #1 #today\nterms of service -- cremona says \"I fell asleep before I got very far into this, but did notice some references to \"Sage\" which should presumably be changed to \"SageMath\".   \n\nhttps://mail.google.com/mail/u/2/#inbox/14c4cd26fbc6731e","position":-7.4441556866513565,"last_edited":1427925152112,"task_id":"4f719729-032b-4387-8092-794c6a22efbf","done":1427925151704}
{"desc":"(0:30?) #3\nhome directory permissions in bup_storage.py\n\nSee https://mail.google.com/mail/u/0/?pli=1#inbox/14c685fb7a00d98e\n\n    The problem was that the permissions on the HOME directory of your project were wrong.   I have no idea how this could happen - I've never run into this before with SMC.   This is something that a user could cause by typing \"chmod u-rwx $HOME \" in a terminal, so it might have somehow accidentally been caused by a student.  In any case, nothing is deleted and it's fine now.\n\n    I plan to make a change to the project restart script so that it explicitly fixes the permissions, so this exact problem is much less likely to be a problem in the future. \n","position":-7.444155655801296,"last_edited":1427685145190,"task_id":"fff41e93-ae58-4815-b332-ac315485afa2"}
{"desc":"#bug #ui #9\nin firefox at certain zoom, the top navbar gets too tall\n\nhttps://mail.google.com/mail/u/2/#inbox/14c6884b59edaf9a","position":-7.444155637174845,"last_edited":1427812344404,"task_id":"7523d7aa-4c64-4171-92f4-c11015703481"}
{"desc":"#today\n","position":-7.444155674427748,"last_edited":1427688443395,"task_id":"b523d1bc-b232-4e4a-b7f5-7d9dbd4376dd","deleted":true}
{"desc":"(1:30?) #5 #install \nQPA gap package\n\nSee discussion here `[sage-cloud] QPA in SMC`: https://mail.google.com/mail/u/2/#inbox/14c428b7f4e061e5","position":-6.856781005859375,"last_edited":1427813636496,"task_id":"0a1e1ea9-ccec-44a3-a1d4-debc1618c5f7"}
{"desc":"(0:20?) #1 #today\n- [ ] on March 31 -- actually shut off the compute[1-8]dc2 machines.  turn off monitoring too.\n- [ ] note in the screen on cloud3, I'm making a backup... of everything just in case... but that will likely not even get close in time :-(","position":-7.444186061620712,"last_edited":1427907883699,"task_id":"9960ad17-3d38-4c85-a6a9-b6c066e6157e","due_date":1427866833782,"done":1427907883288}
{"desc":"(1:00?) #3\nservices file needs to be changed to ssd's from hd's for cassandra node (so needs to support that)","position":-7.4441556837409735,"last_edited":1427812313493,"task_id":"7c9af2a2-e540-4e55-9247-31253967b7fb"}
{"desc":"(1:30?) #0 #today #passport\nmake passport stuff live, phase 2.\n\n\n- [ ] (1:00?) register apps with each provider and put stuff in database\n\n        update passport_settings set conf['auth']='https://cloud.sagemath.com/auth' where strategy='site_conf';\n\n        update passport_settings set conf['clientID']='...' where strategy='google';\n        update passport_settings set conf['clientSecret']='...' where strategy='google';\n    \n","position":-7.444155688397586,"last_edited":1427768819874,"task_id":"2b3a9f71-b8d7-4981-9021-5b90fb9ca731","done":1427768819469}
{"desc":"(0:21) (0:45?) #0 #today #bug\nrace -- loading account settings can take longer than loading file (?)\n\nI opened a terminal in a fresh browser tab and it had the wrong settings.  This happens every time.  Ugh.","position":-7.444155690725893,"last_edited":1427755735148,"task_id":"077a489d-0bba-4f10-98f1-99b9a8dca5e4","done":1427755734741}
{"desc":"(0:20?) #0 #today\ntry to copy all of gce's bups at least to cloud3.\n\nin progress in screen there.","position":-7.444155684905127,"last_edited":1427907878661,"task_id":"e8788f6b-3998-477a-86b1-61db6a37c8b2","due_date":1427840674325,"done":1427907878256}
{"desc":"(1:13) (1:00?) #sagews #feature #3\nadd insert for modes, including typeset (!) \n\nsee -- https://mail.google.com/mail/u/2/#inbox/14c5767a0bcd2fe2","position":-6.856813132762909,"last_edited":1428689862407,"task_id":"8ee4b83f-1daa-4652-b520-fc617f495e02","done":1428689862003}
{"desc":"(1:00?) #5 #speed\nmake it so downloading SMC page doesn't have to download a separate css for each codemirror mode.","position":1.9296875,"last_edited":1427738803041,"task_id":"e2968de4-759d-41f1-a5fa-800a282a1e91"}
{"desc":"(1:00?) #1 #bug\ncourses with a space in the filename: https://mail.google.com/mail/u/2/#inbox/14c6afc214eb115e","position":-7.443115234375,"last_edited":1427812456800,"task_id":"678da2e9-f515-4ce3-a12b-490327896feb"}
{"desc":"(1:00?) #1 #install\nrequests to install stuff from Anand Surampudi.\n\n- https://mail.google.com/mail/u/2/#inbox/14c6a728ae94ad07\n- https://mail.google.com/mail/u/2/#inbox/14c6f1d3c540cee6","position":-7.4429931640625,"last_edited":1427812570396,"task_id":"867a80df-72cc-4b01-9ed1-3047d6ee60d7"}
{"desc":"","position":-7.44305419921875,"last_edited":1427812976167,"task_id":"6408aa3c-c5ed-42ca-a58f-82aa2534766f","deleted":true}
{"desc":"#0 #today \ngithub oauth issue\n\nsee https://mail.google.com/mail/u/2/#inbox/14c7014976e3d7c2","position":-7.443023681640625,"last_edited":1427810729528,"task_id":"33345261-fb20-461f-988b-69441b7ca64a","done":1427810729118}
{"desc":"#1 #bug (1:00?)\nsafari graphics issue with SVG -- do something about it...\n\nIf client is using Safari, print a WARNING message on rendering SVG, with example of how to get around it and leak to bug.","position":-7.444186317268759,"last_edited":1428069637257,"task_id":"e206124c-3aff-4957-998c-4d9257c5e961"}
{"desc":"(0:30?) #0 #upgrade #today\ncassandra driver.\n\nhttps://mail.google.com/mail/u/0/?pli=1#inbox/14c7533e968b56bc","position":-7.444155685778242,"last_edited":1427951406219,"task_id":"a4d8dcf5-7c20-40a2-a644-169ad073e7f5","done":1427951405808}
{"desc":"(1:00?) #2 #bug #editor #sync \nfix the insanely slow filesystem reverts edits bug\n\nI can replicate this via sshfs right now, and it's surely a sign of something horrible.  CRITICAL.","position":-0.758575439453125,"last_edited":1428355717202,"task_id":"ac03604d-c813-48e2-bae8-bf65b5210584"}
{"desc":"#now (0:15) (0:30?) #0 #bug #sagews #today\nfix `sage_eval` issue\n\nhttps://mail.google.com/mail/u/2/#inbox/14c7b7d4fd43400f","position":-7.444186279550195,"last_edited":1428071804189,"task_id":"7d98c429-1108-4df0-9ac7-db2cf2c8241d","done":1428071803782}
{"desc":"(1:30?) #1\nstart recording account_id in file history recorder\n\ncrucial to implement and start doing this now, so we have the data for when there is a feature to use it later!","position":-6.856901109218597,"last_edited":1428355706534,"task_id":"4a9ec448-5c05-40d3-aeae-dd81baa66c02"}
{"desc":"(0:32) (0:45?) #bug #sagews #1\ninteract checkboxes broken!\n\nhttps://cloud.sagemath.com/projects/4a5f0542-5873-4eed-a85c-a18c706e8bcd/files/support/2015-04-03-122812-checkboxes.sagews\n\nhttps://mail.google.com/mail/u/2/#inbox/14c80bfc05e66b9c","position":-7.44418616220355,"last_edited":1428544704820,"task_id":"9b72841f-7e75-44ec-a20f-984971bff449","done":1428544704406}
{"desc":"(5:00?) #ipython\ndeal with large images embedded in ipynb files better for sync\n\nSee, e.g., https://mail.google.com/mail/u/2/#inbox/14c834545efef7c5 from Julia Chadwick' via Help on Apr 4, 2015\n","position":-7.444186287932098,"last_edited":1428165005597,"task_id":"d678db7e-6068-4552-a0ae-8ef26bbab014"}
{"desc":"#install #ipython #8\nihaskell\n\nI tried for over an hour and failed before.  Maybe try again:\n\nHaskell kernel support - the ubuntu-install script fails to build some graphical tools (hence semicolon below). This build line takes about an hour!?\n\n\t\tgit clone http://www.github.com/gibiansky/IHaskell && cd IHaskell && ./ubuntu-install.sh; ./build.sh ihaskell; sudo cp /home/salvus/.cabal/bin/ihaskell /usr/local/bin/ && ihaskell install && export PATH=/usr/local/bin/:$PATH && ihaskell install && sudo cp -rv /home/salvus/.ipython/kernels/haskell/ /usr/local/share/jupyter/kernels/\n        \n\nFails at this when trying to build the display stuff.  Doing just `./build.sh ihaskell` above isn't enough, since ihaskell won't actually work as an ipython kernel.  It needs the display stuff. \n\n        CMD: cabal install --constraint arithmoi -llvm -j ./. ./ihaskell-display/ihaskell-aeson ./ihaskell-display/ihaskell-basic ./ihaskell-display/ihaskell-blaze ./ihaskell\n        -display/ihaskell-charts ./ihaskell-display/ihaskell-diagrams ./ihaskell-display/ihaskell-hatex ./ihaskell-display/ihaskell-juicypixels ./ihaskell-display/ihaskell-ma\n        gic ./ihaskell-display/ihaskell-parsec ./ihaskell-display/ihaskell-plot ./ihaskell-display/ihaskell-rlangqq ./ihaskell-display/ihaskell-static-canvas ./ihaskell-displ\n        ay/ihaskell-widgets --force-reinstalls --max-backjumps=-1 --reorder-goals\n        Resolving dependencies...\n        cabal: Could not resolve dependencies:\n        trying: ihaskell-0.6.0.0 (user goal)\n        trying: base-4.6.0.1/installed-8aa... (dependency of ihaskell-0.6.0.0)\n        next goal: ihaskell-static-canvas (user goal)\n        rejecting: ihaskell-static-canvas-0.1.0.0 (conflict:\n        base==4.6.0.1/installed-8aa..., ihaskell-static-canvas => base>=4.7 && <4.9)\n        Dependency tree exhaustively searched.","position":-7.4441862921230495,"last_edited":1428878876334,"task_id":"69ecb5d6-078a-47e8-bdca-790c2276957d"}
{"desc":"#ipython\nideas for improvement\n\n- [ ] handle all the other meta information in sync-friendly way.\n- [ ] currently just replacing cells on change rather than modifying in place -- slower, but maybe way more robust?!  changing in place doesn't work at all right now.  See `if false and cell? and cell_data.cell_type == cell.cell_type`\n- [ ] chat\n- [ ] periodically watch for changes in the actual .ipynb file: this will require rewriting how local_hub works and is nontrivial>\n\n","position":1.9365234375,"last_edited":1428355534229,"task_id":"7eaf410c-5b5d-4540-b5fe-6a665fbffbaa"}
{"desc":"(3:00?) #upgrade #1\nupgrade to sage-6.6\n\nconfirm this fixes graphics in %load_ext sage.","position":-0.7585468292236328,"last_edited":1428355584168,"task_id":"d2c87527-bfa8-47f3-afe0-48ca028a66e6"}
{"desc":"(3:00) (2:30?) #upgrade #0 #today\npush out my new jupyter stuff...","position":-7.444186237640679,"last_edited":1428538533005,"task_id":"5e9b841e-dc8b-4951-86a8-5294f223a9f5","done":1428538532598}
{"desc":"#bug #install\nrstan is evidentally broken again.  Harald wrote about it here:\n\nhttps://mail.google.com/mail/u/1/#inbox/14c8e45717d1136e","position":-0.7585525512695312,"last_edited":1428358583061,"task_id":"cce0c98a-1043-49aa-86bf-89529a0d1813"}
{"desc":"#1 billing analytics\nsee https://mail.google.com/mail/u/1/#inbox/14c88ec7c5994b03","position":-0.7585487365722656,"last_edited":1428362937357,"task_id":"2896e758-8479-4094-b2c4-47df49637efe"}
{"desc":"#course\nauto-collect time\n\n> Set an auto-collect time for an assignment once you make it. That is the one \"workflow\" feature I feel like is \"missing\" for me right now.\n\nSee https://mail.google.com/mail/u/1/#inbox/14c81b3bc6282f28","position":-0.7585506439208984,"last_edited":1428363002339,"task_id":"cc291994-7f52-4637-b225-f3525dd82232"}
{"desc":"#course\ngrading scoring\n\n> Easily assigning a score to an assignment while you have it open, and then getting out a spreadsheet (or CSV, etc) file at the end of the term might be a good first approximation to record-keeping.  You'll have to decide how far down this road you want to go (drop low score, partial credit if late, extra credit assignments,...).\n\nSee https://mail.google.com/mail/u/1/#inbox/14c81b3bc6282f28","position":-0.7585515975952148,"last_edited":1428363031285,"task_id":"c99e23ea-0bb6-4aae-9a77-a95ff25299fc"}
{"desc":"#install #python\ninterpy package (easy pip thing; harder to use for anything useful...) -- https://github.com/syrusakbary/interpy","position":-0.7585563659667969,"last_edited":1428503838160,"task_id":"549ad613-9132-4c89-8a97-470c4c407ee3"}
{"desc":"(0:08) (0:10?) #today\nupdate help.html stats/counts\n","position":-7.4441862313542515,"last_edited":1428539629501,"task_id":"4addeb90-9a84-4f9a-90a6-3c6792a0f5b7","done":1428539629094}
{"desc":"#1 \nemail invitations -- \n\n> Seeing this, it occurs to me that it would be interesting to save what people write in their invite messages (since they are interesting candid sales pitches for SMC!), and also see if I can change the reply-to address to the sender rather than help@sagemath.com, at least if the sender has an email registered with SMC. \n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14c96ee188205683","position":-7.44418618734926,"last_edited":1428878894065,"task_id":"6635288a-fe59-4eda-b72c-a6379c739fc8","done":1428878893656}
{"desc":"(0:45?) #3\nadd more oauth options:\n\n- [ ] twitter\n- [ ] bitbucket\n- [ ] dropbox","position":-6.856901399791241,"last_edited":1428539660209,"task_id":"a756b9aa-6091-44b1-bdd0-791d5c08af71"}
{"desc":"(0:20) (1:00?) #today #0 #optimize\nchange sageserver startup to not import lots of stuff and see what a change it makes regarding load time and memory.","position":-7.444155691890046,"last_edited":1428593803772,"task_id":"f422cd6f-cd23-44d8-8819-83cbfb790746","done":1428593803369}
{"desc":"#2 \ndokuwiki questions\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14c99e966642256c","position":-7.444155691307969,"last_edited":1428590736524,"task_id":"745d7c39-bb89-4326-a50c-13aa44f34cf1"}
{"desc":"#1 (1:00?)\nmuch better mathjax CSS styling for dark background\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14c9b3947adb9e61","position":-7.444155691599008,"last_edited":1428590802240,"task_id":"18276ec8-02be-4ec4-8cdf-1cad0c551b8f"}
{"desc":"(0:20?) #0 #today #bug #invalid\ntab cycle keyboard keystrokes are reversed...\n\ni suddenly can't replicate this.  Will keep my eyes out.","position":-7.444155691744527,"last_edited":1428609412747,"task_id":"25357d5a-e743-496c-aaa6-091604edd8cf","done":1428609412345}
{"desc":"#now (0:30?) #0 #today\nfix latex filename issue\n\nhttps://mail.google.com/mail/u/0/#inbox/14c9acdda41158f2","position":-7.444155691671767,"last_edited":1428603977295,"task_id":"7b85c4c2-2ab7-46ea-8d8e-9efc96e154ea","done":1428603976892}
{"desc":"(1:00) #today (0:35?)\nadd a new reply-to and bcc email for sagemathcloud invitations.","position":-7.444155691708147,"last_edited":1428609352489,"task_id":"bb4dd102-ad43-461a-9433-09de5438e99a","done":1428609352078}
{"desc":"#editor\nhtml markdown etc editor preview zoom.\n\nThis div needs a zoom button (in SMC): salvus-editor-html-md-preview-content\ntwo buttons next to that preview button, whcih appear when the preview box is checked.  to increase/decrease font-size.\n\nAlso, zoom should get saved in local storage.","position":-7.4441556914534885,"last_edited":1428610051157,"task_id":"cc69259a-06c1-4cc3-938c-9e88d579fe7f"}
{"desc":"(0:44) (1:30?) #today #0\nrewrite ipython daemon script properly to get the pid without calling ps, etc.\n\n- Let's do this right. ","position":-7.444155691380729,"last_edited":1428622156288,"task_id":"544be16a-27b8-49a0-b393-f61cf6df2799","done":1428622155875}
{"desc":"(1:00?) #jupyter #1 #bug\n2 people editing at once -- cursor looses focus","position":1.937255859375,"last_edited":1428941947253,"task_id":"23c2315d-ca7b-418f-a7ed-4f7cda411d10"}
{"desc":"delet","position":-7.444155691417109,"last_edited":1428687667277,"task_id":"90cedcbf-8790-40d6-ae8f-20733cd8bc01","deleted":true}
{"desc":"#1 (0:30?) #bug\narchive program doesn't support straight tar!","position":-6.85690145008266,"last_edited":1428789506245,"task_id":"5a8ccba2-9201-4344-97c0-d884f6c72911"}
{"desc":"(0:30?) #bug #2\nproject is opening message kept appearing repeatedly during my talk.\n\nNever show it more than once if project open!","position":-7.444186304695904,"last_edited":1428878857973,"task_id":"464bfc44-e0ad-47fd-bab3-887b85a81b8b"}
{"desc":"(0:30?) #3 #course #bug\nbug in help text\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14caaabdbcd8d7c6\t\n\n    Sean Raleigh <sean.raleigh@gmail.com>\n    Apr 11 (2 days ago)\n\n    to help \n    Hi William,\n\n    When I go to \"Help\" in the courses area, it brings up a box that is longer than the screen. I can use my mouse wheel to scroll down and read all of it, but I can't drag the scrollbar on the right side of the screen. I can see the scrollbar, but I can't click anywhere to grab it.\n\n    Let me know if I need to send a screencast to see what I'm seeing.\n\n    Thanks,\n    Sean","position":1.93701171875,"last_edited":1428942712017,"task_id":"ef05ae40-fcf1-4cf6-8c6b-eccdd42b283c"}
{"desc":"(0:25+) (2:30?) #5 #support\nhow to add a 3d background?\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14caa0fea9c20e9a\n\nAnswer is here: it's fairly nontrivial, involving changing how rendering works, etc.  About a 2 hour project.","position":1.9373779296875,"last_edited":1428953066167,"task_id":"9bd6dd14-3c84-4d73-b90d-35107b19bb5a"}
{"desc":"(0:30?) #2\ncomment on discussion forum suggestion\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14ca97e40961b6ac","position":-7.44418632959605,"last_edited":1428951630903,"task_id":"752bb018-2f23-49a3-9a20-46efc37da60c"}
{"desc":"(0:30?) #2\nrespond to this email about Learning Management systems\n\nhttps://mail.google.com/mail/u/1/?pli=1&zx=v6crnjw8ww15#inbox/14ca41f5e6cfd0b9","position":-7.444186329587865,"last_edited":1428951633719,"task_id":"312bbe10-a4a8-43b8-b1e6-c453a944856e"}
{"desc":"(3:00?) #1 #com\ndeploy vm's for commercialization\n\n- [ ] decide on what exactly\n- [ ] put in conf file\n- [ ] udpate template vm\n- [ ] actually turn them on and start them running","position":-0.7585983276367188,"last_edited":1429157091860,"task_id":"159de824-6451-4f3d-8895-9cd05dab854e"}
{"desc":"(0:20) #now (1:00?) #0 #com #today\nupdate stripe api: https://stripe.com/docs/upgrades?since=2015-01-11#api-changelog\n\nin account settings there is a big red button to do the upgrade.","position":-7.444186329690183,"last_edited":1428959328524,"task_id":"fd0e3db7-6de3-4b8d-9ddd-36cfdc1044d6","done":1428959328109}
{"desc":"(0:58) (0:30?) #0 #com #now\nget testing stripe stuff from last month to at least work again in devel1dc5 server.\n\nended up researching tax stuff a lot too.","position":-7.444186329694276,"last_edited":1428957443554,"task_id":"dabe9971-a4b2-4f5c-b21f-614494175065","done":1428957443151}
{"desc":"#now (1:00?) #0 #com #stripe #today\nadd location (country, state) maybe need actual address, so we can charge WA state sales tax properly... if necessary? YES. \n\n- Excellent article: http://www.shopify.com/blog/16480780-should-you-be-charging-sales-tax-on-your-online-store\n- Plus it will be good info to have.\n\nThis site looks nice but doesn't seem to support stripe: http://www.taxjar.com/\n\nStripe sites: https://support.stripe.com/questions/custom-fields-for-tax-tips-shipping-and-more\n\n- [x] (2:37) select country\n- [x] if country == US, show option to select state, and if state = WA, show option to enter zip.","position":-7.44418632968609,"last_edited":1428985761282,"task_id":"aac238cb-fa4d-4f35-8b8a-d535f556f271","done":1428985760874}
{"desc":"(1:30?) #1 #com\nimplement sales tax calculator\n\n(see task in business)","position":-0.7585906982421875,"last_edited":1429157098799,"task_id":"37a232f1-907b-4f4d-ae6e-f1368cf1cc23"}
{"desc":"(2:00?) #0 #com\nfigure out how to move SMC entirely out of UW -- even the free part\n\nhttps://cloud.sagemath.com/projects/92848d19-8432-46c8-ba59-2b0d9521c9f2/files/smc/business-model/pricing/2015-04-14-082244.sagews\n\n\n\t26gb ram, 4 cores, 375gb local ssd, few hundred gb slow hdd, maybe 100gb swap (?)","position":-0.7585830688476562,"last_edited":1429283284132,"task_id":"4ad1dec2-38bd-4d8e-81b5-36cd5d0dd376"}
{"desc":"#today #0 (4:00?) #storage\nadd archive functions to `bup_storage.py` that takes a project and produces two files that don't contain extraneous crap (see http://unix.stackexchange.com/questions/28976/how-to-xz-a-directory-with-tar-using-maximum-compression):\n\n\ttar cvf - --exclude=e2542254-f834-4351-9a69-28c50b0ee6e2/.sagemathcloud  e2542254-f834-4351-9a69-28c50b0ee6e2 | lrzip -l -  > foo.tar\n\n> Harald: .xz is slow, it uses single threaded compression. lrz has better ratio and is faster.\n> Harald: The idea behind lrzip is, that there is a large binary (tar-ball) and it is in a first pass searched through for common parts (rolling checksum? no idea what actually). this uses a lot of memory, but it takes care how much is available and so far never crashed the machine. then it lzma (or lzo) compresses the parts in parallel and merges everything together into one .tar.lrz file. `man lrzip` \n\n- [ ] `project-project_id.tar.?`\n- [ ] `bup-project_id.tar.?`\n\n\t\tbup_storage.py archive-project project-id\n\t\tbup_storage.py archive-bup project-id        \n\nMy plan is to \n\n- [ ] upload archives of all projects to a google cloud storage bucket called projects\n- [ ] upload archives of all bups to a google cloud storage bucket called bups\n\nBackup will involve simply copying any new archives to an offsite (in my house) USB disk as well, etc.\n\nRunning SMC will mean `n` machines that have access to the cloud storage buckets.   \n\nOpening a project will:\n1. check if files already available locally in /projects and /bups, with a version that is at least as new as what's in cloud storage\n2. if not locally available, will download and extract files.\n3. then run exactly as usual.\n\nThe above will happen on two machines, so that while project is active, it is regularly mirrored to other machines for redundancy when machines go down, exactly as is the case now.\n\nPeriodically -- say once per week -- every project that has changed gets its archive updated and posted.\n\nWhen projects not used for a certain amount of time $T$ days, it will get deleted from local cache right after successful archive and upload.   For-pay projects will never be archived.\n\nThis separates storage from compute, while providing excellent speed in practice.  Running a projct on a dedicated machine is also easier to implement.\n\nThe one drawback is that a project that hasn't been opened for $T$ days will open possibly much more slowly.  But that's it.    And the cost to store a typical unused 400MB compressed (say) project will be a penny a month.  A 5GB compressed project is maybe $.20/month.   4TB of project data is 2000*0.27 = \\$54/month, which is fine.\n\nHSY: [gsutil subdirectory](https://cloud.google.com/storage/docs/gsutil/addlhelp/HowSubdirectoriesWork):\n`gsutil cp your-file gs://your-bucket/abc/` will create `gs://your-bucket/abc/file`\n\nHSY: [gsutil custom metadata](https://cloud.google.com/storage/docs/gsutil/addlhelp/WorkingWithObjectMetadata#custom-metadata) `gsutil -h x-goog-meta-reviewer:jane cp mycode.java gs://bucket/reviews`","position":-0.7586021423339844,"last_edited":1429283217208,"task_id":"1ba3d6be-3577-42aa-99ec-85b33acaa2a2","done":1429283216792}
{"desc":"#install\nfigure out how to typeset chinese in LaTeX\n\nsee https://mail.google.com/mail/u/1/#inbox from 徐佳浩 <xujiahao@pku.edu.cn>","position":-0.7586002349853516,"last_edited":1429156982318,"task_id":"062f763f-185c-4182-812c-4032ab7d0f9e"}
{"desc":"#1 #speed\nAccording to the logs, the function `user_search` in cassandra.coffee is resulting in up to 3 second delays blocking the server.  This is sometimes a serious problem.  Usually though it isn't blocking (I checked more).  Hmm.","position":-0.758601188659668,"last_edited":1429283244086,"task_id":"72dc824d-b14d-4d41-8307-876c68fdbac3"}
{"desc":"#0 (2:00?)\nmake bup_storage.py use BTRFS instead of ZFS\n\n- [ ] instructions to create filesystem from device (in comment)\n- ","position":-0.7586007118225098,"last_edited":1429283774250,"task_id":"a6451dc4-8f32-4a1c-9597-89e95c6460cb"}