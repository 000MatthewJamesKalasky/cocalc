# VM's:

- [ ] move compute5 data from cloud5 to cloud2 for now, since it is so huge and that disk will run out soon.

# TOP PRIORITY

  - [ ] copy all projects into database

  - [x] write `storage_server` TCP server:

     - [x] create storage_server user and account and password with limited permissions.
        CREATE USER storage_server WITH PASSWORD '...';
        GRANT MODIFY ON table storage TO storage_server;
        GRANT MODIFY ON table storage_writing TO storage_server;
        GRANT MODIFY ON table storage_chunks TO storage_server;
        GRANT MODIFY ON table storage_servers TO storage_server;
        GRANT SELECT ON table storage TO storage_server;
        GRANT SELECT ON table storage_writing TO storage_server;
        GRANT SELECT ON table storage_chunks TO storage_server;
        GRANT SELECT ON table storage_servers TO storage_server;

  - [ ] code to update migration of a given project using a given host

  - [ ] code to --
         - open_project_somewhere
         - close project
         - save project
         - create_project
         - last_snapshot
         - snapshot project
         - snapshot_listing
         - close_stale_projects
         - storage status

   - [ ] database flag that determines which type of storage is being used for a project

   - [ ] code to ensure storage server is started.

   - [ ] transition everything

   - [ ] remove storage account completely


#####


- [ ] fix this for GOOD!  (line 113 bs)
        salvus@web10:~/salvus/salvus$ vi /home/salvus/salvus/salvus/node_modules/http-proxy/lib/http-proxy/passes/ws-incoming.js

- [ ] change hosts to use UTC


- [ ] rebooting the GCE nodes seems to never succeeds so write the command line code to recreate them.

- [ ] that said, run a stress test and figure out what is wrong with the `execute_code` function!

- [ ] admin monitor FAIL:

        Connected to 10.1.6.2
        ---------------------------------------------------------------------------
        OperationalError                          Traceback (most recent call last)
        <ipython-input-4-dce543985046> in <module>()
        ----> 1 cloud.monitor.go(15,7)

        /home/salvus/salvus/salvus/admin.pyc in go(self, interval, residue)
           1565                 if now % interval == residue:
           1566                     last_time = now
        -> 1567                     self._go()
           1568             time.sleep(20)
           1569

        /home/salvus/salvus/salvus/admin.pyc in _go(self)
           1533     def _go(self):
           1534         all = self.all()
        -> 1535         self.update_db(all=all)
           1536         self.print_status(all=all)
           1537         down = self.down(all=all)

        /home/salvus/salvus/salvus/admin.pyc in update_db(self, all)
           1509         # Fill in disabled field for each compute node; this is useful to record in
           1510         # the monitor, and is used by the move project UI code.
        -> 1511         v = dict(list(cassandra.cursor_execute("SELECT host,disabled FROM storage_topology", user='monitor', password=password)))
           1512         if 'compute' in all:
           1513             for x in all['compute']:

        /home/salvus/salvus/salvus/cassandra.pyc in cursor_execute(query, param_dict, keyspace, timeout, user, password)
            114             print msg
            115             cur = cursor(keyspace=keyspace, use_cache=False, user=user, password=password)
        --> 116             cur.execute(query, param_dict)
            117     finally:
            118         signal.signal(signal.SIGALRM, signal.SIG_IGN)

        /home/salvus/salvus/salvus/data/local/lib/python2.7/site-packages/cql/cursor.pyc in execute(self, cql_query, params, decoder, consistency_level)
             78         prepared_q = self.prepare_inline(cql_query, params)
             79         cl = consistency_level or self.consistency_level
        ---> 80         response = self.get_response(prepared_q, cl)
             81         return self.process_execution_results(response, decoder=decoder)
             82

        /home/salvus/salvus/salvus/data/local/lib/python2.7/site-packages/cql/thrifteries.pyc in get_response(self, cql_query, consistency_level)
             75         if self.use_cql3_methods:
             76             doquery = self._connection.client.execute_cql3_query
        ---> 77             return self.handle_cql_execution_errors(doquery, compressed_q, compress, cl)
             78         else:
             79             doquery = self._connection.client.execute_cql_query

        /home/salvus/salvus/salvus/data/local/lib/python2.7/site-packages/cql/thrifteries.pyc in handle_cql_execution_errors(self, executor, *args, **kwargs)
            103                                        "more nodes were unavailable.")
            104         except TimedOutException:
        --> 105             raise cql.OperationalError("Request did not complete within rpc_timeout.")
            106         except TApplicationException, tapp:
            107             raise cql.InternalError("Internal application error")

        OperationalError: Request did not complete within rpc_timeout.


- [ ] finish first round of migrating projects from -- 3,5,6 (then re-enable for users in database)

- [ ] storage: better schedule for applying streams, which does the right thing when forks happen, multiple start times, etc.  I.e., no matter what even when we don't delete streams.   Basically, we start with the stream with the newest end time, then work back until hitting a stream with 0 interval.   Make *that* the only thing returned by the "def streams" function.

- [ ] storage: trim function that goes through and deletes all (non-fork) streams that would not be applied (except forks)

- [ ] storage: come up with a plan for *how* compute machines will use database + caching of streams sensible... and implement. switch some projects.


# LATER


# OPS

- [ ] add something to monitor somehow that informs me if hubs have tracebacks!
- [ ] get rid of updatedb from
- [ ] monitor: free space on / and vm/images/ filesystems on host!


# UI

- [ ] when opening a sagews file, if sage won't run, still open the file, but with a warning that Sage doesn't work.

- [ ] solid simple GUI editor for %html: https://github.com/guardian/scribe



# DONE

- [x] restore the internal firewalling on compute VM's, namely disallow connections on user ports from anywhere except a
      specific whitelist of external hub VM's.  Right now, it's mainly security by obscurity.
          https://mail.google.com/mail/u/0/?shva=1#inbox/1448b75264eeda11


- [x] storage.coffee: replicate (as storage user, using storage project)

- [x] official ipython upgrade: http://trac.sagemath.org/ticket/14713    ; running tests in scratch on compute13a


- [x] storage: should I use a database (+local streams cache) in order to separate compute from storage, which will make compute much, much more dynamically scalable?  ANS -- YES

   - [x] (2:00?) (12:00 --yep 12 hours) write code to split (into small pieces) and save (in parallel) a big object to the database and test.
         - I wrote this demo code.
         - When saving in parallel (with many threads) I guess across the C* cluster, it's about the same as rsync/scp, but seems more robust:
               it's about 10MB/s across my encrypted network/vpn.
         - can't load a big file directly into memory -- will have to do something with streaming and chunking (more complicated code)
         - I think this is viable, but as a separate keyspace (for security and to use a different replication factor)
         - This will be the long-term storage of projects.   We can still cache on local disk.  But view that only as a cache.
         -

    CREATE KEYSPACE storage WITH replication = {'class': 'NetworkTopologyStrategy', 'DC0': '2', 'DC1': '2'};
    CREATE USER storage0 WITH PASSWORD='random...';
    GRANT ALL ON KEYSPACE storage TO storage0;



- [x] cassandra -- redo to use ZFS -- e.g., 5,6,7 will save 100's of GB's of space (and we could use it there).

DONE: 1,2,5,6,7,4,3,10,11,12,13,14,15,
TODO: 16,17,18,19,20,21


n=7
import admin; reload(admin); cloud = admin.Services('conf/deploy_cloud/'); h = lambda x: cloud._hosts('cassandra%s'%n, x, sudo=True, timeout=3600)
cloud.restart('vm',hostname='cassandra%s'%n)  # may take doing it multiple times...
cloud.wait_until_up('10.1.%s.2'%n)

h('zpool create -f cassandra /dev/vdc')
h('zfs set compression=lz4 cassandra')
h('zfs set atime=off cassandra')
h('zfs set logbias=throughput cassandra')
h('rsync -axH /mnt/cassandra/ /cassandra/')
h('umount /mnt/cassandra')
h('zfs set mountpoint=/mnt/cassandra cassandra')
h('zfs snapshot cassandra@init')
h('zpool export cassandra')

--> Which is the same as log in and...

    # fdisk /dev/vdc
    zpool create -f cassandra /dev/vdc
    zfs set compression=lz4 cassandra
    zfs set atime=off cassandra
    zfs set logbias=throughput cassandra
    time sudo rsync -axH /mnt/cassandra/ /cassandra/
    umount /mnt/cassandra
    zfs set mountpoint=/mnt/cassandra cassandra
    zfs snapshot cassandra@init
    zpool export cassandra


--> remove the old image from services file, then

import admin; reload(admin); cloud = admin.Services('conf/deploy_cloud/'); h = lambda x: cloud._hosts('cassandra%s'%n, x, sudo=True, timeout=3600)

cloud.restart('vm',hostname='cassandra%s'%n)
cloud.wait_until_up('10.1.%s.2'%n)
h('zpool import -f cassandra')
cloud.start('cassandra',host='cassandra%s'%n,wait=True)

print cloud._hosts('cassandra%s'%n, 'cd ~/salvus/salvus; . salvus-env; nodetool status', wait=True)


---> Once it is working, move the cassandra-cassandra.img to TRASH.

---
    Net result for cassandra5 -- it takes up 2.2G on disk instead of 150G :-)

        150G    cassandra5-cassandra.img
        2.2G    cassandra5-cassandra-zfs.img

    And migrating to an encrypted SSD device later will be easy (zfs send/recv).  Plus I can snapshot all nodes for a backup-in-place.
    And I can also make offsites of all nodes via zfs send.

---

- [x] build sage-6.2.beta with ipython update:  git fetch git://git.sagemath.org/sage.git u/ohanar/ipython-upgrade
            use system-wide atlas so it's fast to build and portable.
      - [x] ensure clawpack fully works in new sage version
      - [x] more useful crontab monitoring pools:
            */5 * * * * sudo zpool list projects > /home/storage/.zpool.list.projects && cp /home/storage/.zpool.list.projects /home/storage/zpool.list.projects
            */5 * * * * sudo zpool list storage > /home/storage/.zpool.list.storage&& cp /home/storage/.zpool.list.storage /home/storage/zpool.list.storage
            */5 * * * * sudo zpool list cassandra > /home/storage/.zpool.list.cassandra && cp /home/storage/.zpool.list.cassandra /home/storage/zpool.list.cassandra
      - [x] make storage user have more sudo powers:
            # to manage the zfs pool for other projects
            storage ALL=(ALL) NOPASSWD: /sbin/zfs *
            storage ALL=(ALL) NOPASSWD: /sbin/zpool *
            storage ALL=(ALL) NOPASSWD: /usr/bin/pkill *
            # to create users for projects
            storage ALL=(ALL) NOPASSWD: /usr/local/bin/create_project_user.py *
      - [x] automate put latest smc_storage.py in /home/storage/



   - [x] create a new ZFS pool on each compute machine called "storage" with filesystems -- no dedup and no compression.
        storage/images
        storage/streams

        zpool create storage -f /dev/vdd
        zfs set sync=disabled storage
        zfs create storage/images
        zfs create storage/streams
        chown storage. /storage/streams
        chown storage. /storage/images
        chmod og-rwx /storage/streams
        chmod og-rwx /storage/images
        zpool export storage

    (x) done at UW

- [x] create 425GB/each storage devices on all of 3.1.x.4 for x=1,2,..,8, attach and configure (with care!)
      (only 8 remains)

- [x] export and delete storage on 3.1.x.4 for x=1,2,3.
- [x] create zpool image ubuntu-base-salvus-qcow, and copy over data.

- [x] pexpect bug -- fix in base image and update
       /usr/local/sage/sage-6.2/local/lib/python2.7/site-packages/pexpect.py

- [x] transition the 8 compute machines at Google from Debian to Ubuntu:
       - [x] setup compute-base-disk and run doctests
       - [x] worry about startup script and switch 10.3.4.4 first, since no projects are running there.
          - [x] 10.3.4.4
          - [x] 10.3.3.4
          - [x] 10.3.1.4
          - [x] 10.3.2.4
          - [x] 10.3.5.4
          - [x] 10.3.6.4
          - [x] 10.3.7.4
          - [x] 10.3.8.4

ssh-keygen -f "/home/salvus/.ssh/known_hosts" -R 10.3.1.4; ssh-keygen -f "/home/salvus/.ssh/known_hosts" -R 10.3.2.4; ssh-keygen -f "/home/salvus/.ssh/known_hosts" -R 10.3.3.4; ssh-keygen -f "/home/salvus/.ssh/known_hosts" -R 10.3.4.4; ssh-keygen -f "/home/salvus/.ssh/known_hosts" -R 10.3.5.4; ssh-keygen -f "/home/salvus/.ssh/known_hosts" -R 10.3.6.4; ssh-keygen -f "/home/salvus/.ssh/known_hosts" -R 10.3.7.4; ssh-keygen -f "/home/salvus/.ssh/known_hosts" -R 10.3.8.4


 - [x] Make sure to do this: "zfs set sync=disabled storage" on storage1-8 on gce nodes.

- [x] (1:03) fix bug with raw http server failing.

The top of the log for a failed project is:

    start debug: info: starting tcp serverdebug: read '/proinfo: listening on port 40414
    info: starting raw server...
    info: raw server (port=47050), host='10.1.16.4', base='/3702601d-9fbc-4e4e-b7ab-c10a79e34d3b/raw/'
    sername":"3702601d9fbc4e4eb7abc10a79e34d3b","path":".","host":"10.1.16.4","port":22},"base_url":""}
    error: Uncaught exception: Error: listen EADDRNOTAVAIL
    Trace
        at process.daemon.pidFile (/projects/3702601d-9fbc-4e4e-b7ab-c10a79e34d3b/.sagemathcloud/node_modules/local_hub.js:2160:24)
        at process.EventEmitter.emit (events.js:126:20)
    debug: PARENT: received connection
    debug: PARENT: received connection
    debug: received control mesg {"event":"codemirror_get_session","path":"./.sagemathcloud.log","project_id":"3702601d-9fbc-4e4e-b7ab-c10a79e34d3b","id
    ":"ce075976-4157-4c87-847e-05d57d8397c3"}

(1) what is this /proinfo thing?



- [x] try setting up a cassandra 2.x storage cluster from scratch on *bare metal* (/dedicated public ip GCE's there later) with everything SSL encrypted.

   - [x] read security section of docs
   - [x] <http://www.datastax.com/documentation/cassandra/2.0/cassandra/install/installDeb_t.html>

           add-apt-repository ppa:webupd8team/java; apt-get update; apt-get install oracle-java7-installer libjna-java
               # if the above goes wrong, do this:
               #  rm /var/lib/dpkg/info/oracle-java7-installer*; apt-get purge oracle-java7-installer*; rm /etc/apt/sources.list.d/*java*

           echo "deb http://debian.datastax.com/community stable main" | sudo tee -a /etc/apt/sources.list.d/cassandra.sources.list
           curl -L http://debian.datastax.com/debian/repo_key | sudo apt-key add -
           apt-get update; apt-get install dsc20; service cassandra stop; rm -rf /var/lib/cassandra/data/system/*

   - [x] setup insecure cassandra 2.x cluster for testing.

       created and put in /etc/cassandra/
            salvus/conf/deploy_cloud/storage/*.yaml

            NOTE!! -- I forgot to put: "auto_bootstrap: false" at the bottom of cassandra.yaml, which costs me about 2 hours. DANG.

       data location:
            mkdir /home/salvus/vm/images/storage
            chown -R cassandra. /home/salvus/vm/images/storage

       start the seed nodes one at a time, and then start the rest of the nodes:
            service cassandra start
            tail -f /var/log/cassandra/system.log

   - [x] test/benchmark writing using my storage system:
          my 1.4GB blob:
            limit   chunk_size      write        read
              5         10          35-55           51
              5         64          56
          Basically it takes about 55 seconds to send 1400MB.
          To send with scp is about the same.
          With iperf it would be about 18 seconds (?), so there
          is a lot of encryption overhead, evidently.

          Reading and sending are at about the same speed, but one has to happen before the other can... hmm.

          I just tried storing a 380MB file via the DB in cassandra versus my bare metal setup... and
          it took 94s on VM's and 14s on bare metal...

          So this is a GO.

          Testing pushing projects 0-999 into the DB to see how that goes tomorrow morning...





- [x] upgrade python:

   sage -sh
   umask 022; easy_install -U distribute
        # pip install --upgrade clawpack   ## NOT YET

- [x] temporary (line 113 bs)
        salvus@web10:~/salvus/salvus$ vi /home/salvus/salvus/salvus/node_modules/http-proxy/lib/http-proxy/passes/ws-incoming.js



- [x] benchmark a cassandra setup on raw hardware but over VPN: it's 90 seconds to write my 1.4GB test file instead of 60 seconds.
by the way:
salvus@cloud3:~/salvus/salvus$ time openssl aes-128-cbc -in blob -out blob.ssl -pass file:blah
real    0m16.047s

- [x] setup clean cassandra server

- [x] write table that records only active writes

x={};require('cassandra').storage_db((e,d)->x.d=d;x.c=x.d.chunked_storage(id:'3702601d-9fbc-4e4e-b7ab-c10a79e34d3b') )



- [x] write scrub command that deletes anything that is in the active table, but is sufficiently old (based on timestamp)

- [x] during the save this sometimes happens (when pushing load hard):  Make it retry with exponential backoff... like the Netflix code does.
    coffee> error: Query cql('UPDATE storage_chunks SET chunk=?, size=? WHERE chunk_id=?',params=[[16,138,14,232,246,161,0,253,95,133,...) caused a CQL error:
    ResponseError: Operation timed out - received only 0 responses.
    s.verbose=1


- [x] rewrite database code to not use find -- ugly; doesn't clean up properly...
        debug: execute_code: "find /home/salvus/streams//06049aff-157e-4cf1-9f72-adf1aafcd29e -type f -printf %s %P
        "
        debug: Spawn the command find with given args /home/salvus/streams//06049aff-157e-4cf1-9f72-adf1aafcd29e,-type,f,-printf,%s %P
        events.js:72
                throw er; // Unhandled 'error' event
                      ^
        Error: spawn EMFILE
            at errnoException (child_process.js:980:11)
            at ChildProcess.spawn (child_process.js:927:11)
            at Object.exports.spawn (child_process.js:715:9)
            at async.series.exit_code (/home/salvus/salvus/salvus/node_modules/misc_node.js:334:27)
            at /home/salvus/salvus/salvus/node_modules/async/lib/async.js:548:21

    These tests suggest it does work fine:

        coffee> m=require('misc_node');async=require('async');0;
        0
        coffee> f=(i,c)->m.execute_code(command:'find', args:['/tmp/'], cb:(e,out)->c(e))
        [Function]
        coffee> async.mapSeries([0..1000],f,(e)->console.log(e))
        undefined
        coffee> null



- [x] I was able to trigger the find error by pushing the entire directory tree of `node_modules` twice... but the problem was due to not closing fd when calling put.  Very important to fix this.

- [x] error storing a too-large file:

        debug: storage_migrate: done syncing 00bffa4f-314b-4d33-b46c-5b8a1bf78161 in 7.086999893188477 seconds
        DONE { '006a0178-f833-40f0-8fbf-fc6326d482d2':
           { name: 'ResponseError',
             message: 'unable to make int from \'2529408766\'',
             info: 'Represents a error message from the server',
             code: 8704,
             isServerUnhealthy: false,

    change size type to bigint fixes.


- [x] add user/password auth to db:

        ALTER KEYSPACE system_auth WITH REPLICATION = {'class' : 'NetworkTopologyStrategy', 'DC0' : 3, 'DC1' : 3};
