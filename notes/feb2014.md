# February 2014 -- these are my goals:

- [x] (0:30?) (0:05) monitor: cassandra phase 1 check is often wrong - make more robust

- [x] (1:00?) (0:41) don't bother to backup projects that have never been open, like these 'f9372541-a2d9-44e4-91ce-ce8163bd176e', 'fdd137ba-5b7a-4ea3-be03-3f2bc8a9ad79', 'ffaf662a-0662-4d60-9da1-ac890d6991d8'.  We could do this by setting the status to 'new', which would change to opened once they are opened once.   Then ignore anything set to 'new' when doing backup.

--> - [ ] (1:30?) (0:27+) login email address is case sensitive -- make it not case sensitive #95
         - x canonicalize on account creation
         - x make login checking code use canonicalized email address.
         - x change all my code like this ".email_address.toLowerCase()" to call a function in misc and first check that the type is string.
         - x fully test on my laptop vm install.
         - x make database snapshot
         - x fully dump backups of any tables we're going to modify: accounts and email_address_to_account_id

         - write code to update db
           Considerations:
             - deal with accounts that have same email up to case:
                  - for each, lowercase the one that has the most recent login, as determined by
                       select * from successful_sign_ins where account_id=f70dc55e-eeec-434e-ab03-12a5713d009f
             - write code to go through email_address_to_account_id table and create record with lower cased email_address.toLowerCase()
             - write code to go through accounts table and replace record by one with email_address.toLowerCase()

           Algorithm:
             - get list of all pairs (account_id, email_address)
             - use to make map  {lower_email_address:[[email_address, account_id], ... }
             - for each key of that map:
                   - if multiple addresses, query db to see which was used most recently
                   - set accounts record with given account_id to lower_email_address
                   - set email_address_to_account_id --> accounts mapping to map lower_email_address to account_id.
                   

         - test db update on vm
         - now the scary part:
               - push new code to web servers;
               - restart servers
               - make another database table dump
               - run above database update code.

- [ ] (3:00?) project move (dialog to provide info about targets).

- [ ] (0:20?) (sunday eve after 6pm) verify encrypted copy of backup vm is copied to bsd, then restart backup vm again.

- [ ] (4:00?) implement one basic cgroups controls on projects

- [ ] (1:00?) monitor script: add check that scratch on all compute machines is actually *working*

- [ ] (1:30?) monitor: should alert me somehow when exceptions occur regularly in hubs

- [ ] (1:00?) Add a link to the "error opening" dialog to open project settings with the "Restart" pane highlighted #94

- [ ] (1:30?) truncate large output in worksheets -- https://github.com/sagemath/cloud/issues/93
- [ ] (0:45?) fix this printing issue -- https://mail.google.com/mail/u/0/?shva=1#inbox/14367e63a3fa1052
- [ ] (1:30?) storage: zfs quota reporting; fix, make much more visible, etc. -- https://github.com/sagemath/cloud/issues/78

- [ ] (0:20?) answer email from australia.


- [ ] (0:30?) make the default setting for "delete trailing whitespace" be false.

- [ ] (1:30?) command line "open" command not showing the right tab (buggy, since not done)
- [ ] keyboard shortcuts
- [ ] write a user's guide
- [ ] write a developer's guide

- [ ] (1:30?) SMC in SMC -- get it working again

- [ ] (1:00?) bug -- sometimes other users cursors don't animate away, e.g., if their connection is dropped at the wrong time.
- [ ] (1:00?) switch to route 53 dns
- [ ] (1:00?) re-automate "nodetool cleanup"
- [ ] (1:30?) automate "zpool scrub" -- code in storage.coffee (?)
      - should do "zpool status" on each machine in parallel
      - parse output to seen when last scrub was successful or if there are errors
      - if output indicates any errors, notify me
      - if it was one week ago or more, do another scrub

- [ ] (3:00?) bug: fuse (and nodejs) is now broken for some users. UGH. -- this is because of BIG uid's....
      Idea to fix this:
          - figure out what the uid cutoff is in both npm and fuse; it's probably the same and fairly universal.
          - figure out the uid's of all existing projects; how many exceed the cutoff?
          - fix the ones that exceed the cutoff, somehow.
          - for the ones that don't leave 'em.
          - store the account uid in the projects database; changing code of create_project_user to take uid as non-optional input.
          - when creating a new project, choose a random uid, check if it is in use, and if not grab it, then check again (to avoid race).
- [ ] (2:00?) properly renaming files -- https://github.com/sagemath/cloud/issues/4
- [ ] (2:00?) properly deleting files -- https://github.com/sagemath/cloud/issues/36
- [ ] (2:00?) proper worksheet restarting, with much better ui and actually working!
- [ ] (1:00?) inverted hashtag selection -- https://github.com/sagemath/cloud/issues/88
- [ ] (3:00?) 2FA -- https://github.com/sagemath/cloud/issues/85
- [ ] (1:00?) latex escape mode for worksheet printing -- https://github.com/sagemath/cloud/issues/82
- [ ] (2:00?) upgrade to sage-6.1

- [ ] (2:00?) zfs replication: several errors that aren't getting sorted out.  RESOLVE.

- [ ] quota watch:
        94a3a0b8-0257-43ef-9986-89d7fc789a72 -- a bunch of texing, but has used 5GB in *snapshots*.
        6ff32b4a-1747-4760-9f83-aaf694e17006
        9ac5a8ca-7dbf-4b27-adea-4709b0fb7105
        e51a48b0-8b47-4d20-ac2d-e9aa7a4462ba
- [ ] (1:30?) update fontawesome: https://github.com/FortAwesome/Font-Awesome/wiki/Upgrading-from-3.2.1-to-4
- [ ] (1:30?) update coffeescript: http://ihackernews.com/comments/7139175
- [ ] (1:30?) update node.js
- [ ] (1:30?) update node.js proxy library, and see if it solves this -- res isn't even defined in
        /home/salvus/salvus/salvus/node_modules/http-proxy/lib/http-proxy/passes/ws-incoming.js
      so it is a bug in the proxy library.  DANG.   Check on upstream.  For today, just edit manually.
      I just *temporarily* commented out the whole emit line, since "emit is not defined".
- [ ] (5:00?) upgrade to bootstrap 3: http://stackoverflow.com/questions/17974998/updating-bootstrap-to-version-3-what-do-i-have-to-do
- [ ] (2:00?) storage: write code to scan and find all projects that are within 90% of running out of space.
- [ ] (3:00?) copy: enhance copy functionality to send/recv a file to/from all linked projects via a command line function for now
- [ ] (1:30?) fix franco's security issue: https://mail.google.com/mail/u/0/?shva=1#search/franco/143ca2f6db753e56
- [ ] (1:00?) upgrade to jquery 2.1 -- http://blog.jquery.com/2014/01/24/jquery-1-11-and-2-1-released/
- [ ] (1:00?) ensure rebooting and/or restarting the cassandra nodes works; maybe have to put some zpool import functionality in admin/startup script.
- [ ] (1:30?) upgrade sockjs, which has seen new development: https://github.com/sockjs/sockjs-client/commits/master
- [ ] (2:00?) storage: edge case replication loop -- in this case 10.1.12.4 gets deleted one time, then 10.1.14.4 overwrites it in stage 2, ad infinitum.
        project_id: 306cce9f-fa4a-481b-93ef-afd69a7fb5b4
        current location: 10.3.3.4
        usage: {"avail":"4.97G","used":"26.9M","usedsnap":"8.03M"}
        last_replication_error: {"error":{"src-10.1.14.4-dest-10.1.12.4":"problem -- destination has snapshots that the source doesn't have -- destroying the target (really
         safely renaming)"},"timestamp":"2014-01-20T15:23:13"}
        snapshots:
                10.1.5.4 (dc 0): 2014-01-13T19:32:08, 2014-01-13T19:32:41, 2014-01-13T19:31:43, 2014-01-13T19:30:34, ...
                10.1.1.4 (dc 0): 2014-01-13T19:32:08, 2014-01-13T19:32:41, 2014-01-13T19:31:43, 2014-01-13T19:30:34, ...
        (old)   10.1.12.4 (dc 1): undefined, undefined, undefined, undefined, ...
        (old)   10.1.14.4 (dc 1): 2014-01-13T19:32:41, 2014-01-13T19:31:43, 2014-01-13T19:30:34, 2014-01-13T19:25:19, ...
                10.3.4.4 (dc 2): 2014-01-13T19:32:08, 2014-01-13T19:32:41, 2014-01-13T19:31:43, 2014-01-13T19:30:34, ...
                10.3.3.4 (dc 2): 2014-01-13T19:32:08, 2014-01-13T19:32:41, 2014-01-13T19:31:43, 2014-01-13T19:30:34, ...

    In this case, fix by doing: s.destroy_project(project_id:'306cce9f-fa4a-481b-93ef-afd69a7fb5b4',host:'10.1.14.4',safe:true)

- [ ] (0:30?) hit return for submit on password reset dialog
- [ ] (0:30?) enter password twice in password reset dialog
- [ ] (0:45?) codemirror unindent bug
- [ ] (1:00?) rotate out very long .sagemathcloud.log's
- [ ] (0:30?) on first run: first /home/salvus/salvus/salvus/data/local/sbin/tincd --kill   then normal tinc
- [ ] (1:30?) run at least one web node on GCE
- [ ] (2:00?) run database on GCE
- [ ] (1:00?) add to monitor: root fs disk usage on compute machines (due to storage temp files)
- [ ] (1:00?) see "# TODO: must fix this -- it could overwrite a user bash or ssh stuff.  BAD." in create_project_user.py


# IDEAS:

- [ ] idea for port forwarding into vm's: "ssh -L cloud1.math.washington.edu:4567:10.1.2.4:4567 ce2d267d00df42deab4464509a5f3e74@10.1.2.4"
- [ ] sigmajs?  http://sigmajs.org/

# NEXT MONTH:

- [ ] (1:00?) create a temporary (for the next 3 months) very-easy-to-recover from backup mechanism for all projects, that could have slight corruption:
      NO:
         - create a 3.9TB salvus volume on disk.math
         - rsync the 7 compute[x]-projects.qcow2 images to it periodically. (prob 5 hours per image).
         - if everything is destroyed, but those images aren't destroyed, then we can very easily get back up and running using them, with minimal loss of work.
      OR -- NOPE.
         - create a bup volume on cloud1
         - copy all 7 images into it.
         - depending on size, do similar to disk.
         - depending on size, do similar to usb disk in my office that I offline.
         - WAIT: it takes 10 hours to make the backup of a 400-ish GB image locally; since restore would be serial and no better, it would take at least 1 *week* to restore.  That's NOT acceptable.
      OR -- OK, actually implement that dump of all ZFS filesystems, after all. That really is the way to go.

         time sudo zfs send -R projects/4a5f0542-5873-4eed-a85c-a18c706e8bcd@2014-02-07T00:42:54 > a
         gzip -9 a.gz   # of course, do in one step; decompress is fast, and savings is worth it
         openssl aes-128-cbc -in a.gz -out a.gz.ssl -pass file:blah # encrypt
         [type password twice]
         time openssl aes-128-cbc -d -in a.gz.ssl -out c.gz -pass file:blah # decrypt
         # 1. create gzip-9'd stream on compute vm
         # 2. copy that stream back to backup control vm
         # 3. encrypt on backup machine (so only it knows key) --?
         # 4. copy somewhere else...

- [ ] backup/storae: write recover code...



# DONE

- [x] (0:15?) monitor: add visudo for zpool list for storage use to base vm's.
- [x] (0:15?) monitor: fix bug in zpool monitoring.
- [x] (0:15?) (0:06) admin monitor: raise timeouts, since dns test seems to fail too much
- [x] (0:30?) (0:13) backup script: make it run repeatedly.
- [x] (0:45?) (0:38) backup script: move projects out of the way and retry once on fail (and start running)
- [x] (1:00?) (0:50) close_stale_projects is deciding what is closed/open based on location, which doesn't get reset on close, so it does WAY too many closes; so stupid that it really slows things down for a few minutes, even now.
   - ideas:
       - add a state field to projects, which is one of: 'opened', 'closed'.  On opening a project, set to opened.  On closing a project, set to closed.
       - state would impact whether the killer bothers to kill all procs of process
       - state could also impact UI at some point.
       - could have boolean: `is_open` instead of a state.  last flexible, but less room for error


- [x] (1:00?) (1:08) add an "always confirm on page close" setting; off by default
    alter table accounts add other_settings     varchar;
- [x] (0:20?) (0:54) answer question about r whitespace at http://stackoverflow.com/questions/21591225/suppress-the-extra-white-space-from-compiling-in-r, http://ask.sagemath.org/question/3500/is-there-any-way-to-suppress-the-extra-white-space
- [x] (0:30?) (1:21) install fenics -- http://fenicsproject.org/download/ubuntu_details.html
- [x] fix some /scratch issues: zfs create -o quota=64G -o mountpoint=/scratch projects/scratch; zfs set compression=lz4 projects/scratch    ;  chmod a+rwx /scratch
- [x] (1:00?) monitor: check available space on each project zpool: "ssh storage@10.1.19.4 'sudo zpool list projects'"

- [x] (0:45?) add to my normal monitoring script that every ip address that cloud.sagemath.com maps to actually responds when directly connected to.


- [x] (1:00?) new encrypted offsite backup -- disconnect from internet--done
          time kvm-img convert  -f qcow2 -O qcow2 -o encryption=on,cluster_size=2M  backup1-projects.img  ENCRYPTED-backup1-projects.img
          # real 866m20.407s

- [x] (1:00?) (0:31) opaque background behind a user's name next to their cursor -- https://github.com/sagemath/cloud/issues/2
- [x] (1:00?) (0:35) pretty print broken -- https://github.com/sagemath/cloud/issues/45
- [x] (1:00?) (0:22) another block parser bug -- https://github.com/sagemath/cloud/issues/46
- [x] (1:00?) (0:20) funny filenames -- https://github.com/sagemath/cloud/issues/67
- [x] (0:30?) (0:15) highlight play button -- https://github.com/sagemath/cloud/issues/68
- [x] (0:30?) (0:29) add haskell editor syntax highlighting support.
- [x] (0:30?) (0:10) increase file open timeout to 45 seconds; right now it is shorter than the time it often takes to open a closed project
- [x] (0:30?) (0:01) snap: delete snap cassandra user in database credentials: "DROP USER snap"
- [x] (0:30?) (0:27) new project dialog -- modal-body div looks weird.
- [x] (0:30?) update faq about /scratch (?)

# NOT DOING
- [ ] (1:00?) implement new ZFS backup, which just dumps the whole project (never diffs) to a very compressed file, if it has changed.   Store in a big directory.  Inconsistent histories -- keep both versions.






