{"desc":"#idea\nincremental tar \n\nBasically do\n\n     tar --listed-incremental=incremntal.data -cvf project_id-timestamp.tar project_id/\n     tar --listed-incremental=incremntal.data -cvf project_id-timestamp.tar project_id/\n\netc. and to extract\n\n     tar --listed-incremental=incremntal.data -xvf project_id-timestamp.tar\n\nwhere incremntal.data just grows with more info over time.\n\nTEST:\n\n\ttime tar --listed-incremental=/tmp/inc -cvf - 5ec67a33-4346-4769-a1f1-b1dd6bb88a34 | lz4 - > /tmp/a.tar.lz4","position":-1,"last_edited":1430814539716,"task_id":"f28cc862-9a58-40e1-96f7-8148af79e9bb","done":1430814539716}
{"desc":"- [x] make a GCS bucket called smc-tar\n- [ ] tar_save: to smc_compute like archive, but with target incremental tar output\n- [ ] tar_pull: opens if necessary and gets the incrementals, optionally making snapshots as you go.","position":-2,"last_edited":1430814540441,"task_id":"a925f69f-cb8f-4d99-8722-f8f12e9fc514","done":1430814540441}
{"desc":"incremental tar -- total  FAIL.\n\nnext idea:\n\n- k nodes each with a 1TB PD ZPOOL with no dedup but yes compression.\n- put each project on 2 of the four nodes\n- in database have column locations that maps timestamps to hostnames\n- run my old bup_server code, but without the bup stuff at all\n- make the rolling ZFS snapshots nicely available to users\n- periodically rsync for replication (but nothing to do with snapshot times, except rsync last snapshot maybe)\n","position":0,"last_edited":1430817907287,"task_id":"b980e216-295d-40d7-b0f3-ea76f92381de","done":1430817906866}
{"desc":"(0:30?) create one more powerful storage node from that backup I was making -- restart those going, but with more --excludes.","position":1,"last_edited":1430817922846,"task_id":"451e23b7-b9b5-42dd-954f-4c4a71ba0ba1","done":1430817922437}
{"desc":"#now (1:00?)  add function to smc_compute.py to save/open/close project using this new method.","position":2,"last_edited":1430820343167,"task_id":"f6fce875-d897-4bc5-a2f3-6f741a41c291","done":1430820342758}
{"desc":"#0\n(1:30?) change compute.coffee to check in db to see if project is using this new method and if so, use it instead on a node that can use it (like experimental).  get this to fully work on test projects.","position":3,"last_edited":1430862561460,"task_id":"b0e84fc9-bc12-43f5-8877-e03b8c03aa91","done":1430862561045}
{"desc":"#0 (1:00?) #now\n- [ ] once the rsync from uw is done, make a snapshot at that point.\n- [ ] setup something that rsync's from the 6 machines right now in a loop periodically, and run that.\n- [ ] setup rolling snapshots (find some scripts)","position":3.125,"last_edited":1430862575338,"task_id":"43d2e4bc-0cb4-460c-bfde-a8ce7e4889f8"}
{"desc":"#idea OK, so the fastest imaginable way to do this is to:\n\n- use the rsync daemon: about 4GB/minute\n- using ssh with the right options: about 3GB/minute\n\nSECURITY:\n\n- i could make a storage daemon and have all moving of files be done *from* there for better security, so the compute vm's don't have to do anything dangerous regarding write... exporting snapshot dirs, which gives full read access to an attacker.","position":3.5,"last_edited":1430855014673,"task_id":"2f812913-5b26-4f91-8f01-b1c0b89b6a95","done":1430855014260}
{"desc":"#1\n(1:00?) implement read-only nfs mounting of snapshots from storage server to compute servers","position":5,"last_edited":1430855028676,"task_id":"29e7bf18-8fd9-4224-8bf4-f403d5bbd0c0"}
{"desc":"#1\n(1:00?) implement way for users to browse their snapshots.  HOW?!??!\n\n1. make it so when git-ls requests listing for `.snapshots/timestamp`, only include  .snapshots/timestamp/project-id in listing....\n2. on client side when user clicks on .snapshots/timestamp/, instead open .snapshots/timestamp/project-id/ instead.\n\n\n","position":6,"last_edited":1430855031336,"task_id":"7e7f0e1c-214b-45f7-9d8a-11738bede73f"}
{"desc":"#0\n(2:00?) make new cluster and switch everything over somehow (?)","position":3.25,"last_edited":1430855289185,"task_id":"e163e304-f412-4d0c-be84-e81aa60b6138"}
{"desc":"#1\n(2:00?) make storage server redundant\n- snapshot disk\n- start another similar machine called storage1\n- have the rsync_save process just save to one at random and do something (e.g., timestamp of directory or database entry) so that server knows to push to other\n- have the rsync_open process just try to load from one at random, and if fails, try the other.\n- periodic sync by backend on changed directories","position":3.375,"last_edited":1430855268149,"task_id":"f08f063d-a244-4d29-b808-9d9c88e42bb9"}
{"desc":"3GB/m openin scrollbar.","position":3.4375,"last_edited":1430860740197,"task_id":"7c98e4e8-9d00-4f15-a08e-ce6735d07080"}
{"desc":"#1\nsnapshot browser should have default option to restrict to only snapshots where you (or project or some users) were active, based on database....","position":3.1875,"last_edited":1430864667936,"task_id":"7b1c85e6-8755-4a33-90fa-d8aacd759454"}