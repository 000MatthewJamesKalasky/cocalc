{"desc":"#1 #backup\ncheck on tar_backup results on storage0-us (the crontab)","position":-1,"last_edited":1431469396620,"task_id":"c458cbcd-24fc-4924-af22-0c8d77b0a61e","due_date":1431399467060,"done":1431469396201}
{"desc":"#1 #backup\nstart making periodic offsite backups of SMC projects by downloading tar_backup's directly from storage machine.","position":0.328125,"last_edited":1431544090987,"task_id":"a8b28233-c00a-4519-92a3-609c9b46c148","due_date":1431485920667,"done":1431544090575}
{"desc":"#5\nmake a purely \"client-side\" version of bup snapshots for projects.\n\n    bup init\n    open .snapshots-bup/master/\n    bup index -x .; bup save . -n master --strip \n    bup fuse .snapshots-bup\n\n- Make the frequency, whether or not enabled, etc., be user-configurable. \n- Have button to reset them (or trim when implemented).\n- Nice graphical browser of them.","position":-0.5,"last_edited":1432587501986,"task_id":"3fa638fd-c455-4d4a-bfb9-36fd780dc335"}
{"desc":"#0 #upgrade\nsage\n\n- sage-6.7.beta build here: `salvus@compute2-us:/projects/sage/sage-6.7.beta4 logout`\n\n","position":1.3463541666666665,"last_edited":1431963301666,"task_id":"e60f436f-2e36-4bc4-b433-b1265dc4c803","deleted":true}
{"desc":"#2 (1:00?)\n#upgrade cassandra-driver\n\nhttps://mail.google.com/mail/u/0/#inbox/14d4d3ab8d7ca263","position":2.1666666666666665,"last_edited":1431544110335,"task_id":"e60b9960-0438-41f9-8f49-a4c8ea8b9516"}
{"desc":"#0 (0:30?) (0:04)\nremove UW donation links for SMC","position":2.9375,"last_edited":1431531748215,"task_id":"aa13e48b-75b0-4dbd-8def-449591861595","done":1431531747798}
{"desc":"#3\nidea: create a read-only mounted 10GB persistent HDD image with \"secrets\" \n\n(passwords, etc.) that gets mounted by smc machines.  Use a different one for devel machines.  Have an automated update/remount option?  \n\nThis might be a bad idea.","position":1.75,"last_edited":1432582803866,"task_id":"64532c8f-468b-42a3-86b4-05c8f02e9714"}
{"desc":"#2\n(2:00?) make storage server redundant\n- snapshot disk\n- start another similar machine called storage1\n- have the rsync_save process just save to one at random and do something (e.g., timestamp of directory or database entry) so that server knows to push to other\n- have the rsync_open process just try to load from one at random, and if fails, try the other.\n- periodic sync by backend on changed directories\n\nIdeas: If I change all the read-only snapshots to be read-write (but still mount read-only via sshfs), then I can replicate even the snapshots using rsync.","position":3.39581298828125,"last_edited":1431906835141,"task_id":"f08f063d-a244-4d29-b808-9d9c88e42bb9"}
{"desc":"#2 haproxy -- make the test for functionality also take into account the proxy server failing.\n\nEITHER: don't tie the proxy server and hub, or require both to work or fail whole thing...  ","position":3.46875,"last_edited":1430907685595,"task_id":"29e9fc1b-d22e-4642-98da-d07e3004797d"}
{"desc":"#2 #storage\ndecide how to make storage not a single point of failure\n\nIf I change all the read-only snapshots to be read-write (but still mount read-only via sshfs), then I can replicate even the snapshots using rsync.","position":3.277777777777778,"last_edited":1431906822981,"task_id":"781c73ca-2de5-434b-97c4-73e22fe5f48c","deleted":true}
{"desc":"#2 #storage\ndecide how to make storage not a single point of failure\n\nIf I change all the read-only snapshots to be read-write (but still mount read-only via sshfs), then I can replicate even the snapshots using rsync.","position":3.3263888888888893,"last_edited":1431906837977,"task_id":"311dbf36-dabd-4d26-9006-482e634a53d5","deleted":true}
{"desc":"#3\ndelete all accounts of users that are running whenever restart compute server (?) --  at least users whose project isn't on this computer.  otherwise they can ssh in and get very confused... this is hard to do.","position":3.229166666666667,"last_edited":1431481487413,"task_id":"148dfa6d-b128-4d12-bf9f-a7840e9fe8f5"}
{"desc":"#3\ndelete all accounts of users that are running whenever restart compute server (?) --  at least users whose project isn't on this computer.  otherwise they can ssh in and get very confused... this is hard to do.","position":3.1145833333333335,"last_edited":1431564238268,"task_id":"f8783667-ea6f-4a4e-8803-0992dd3ce0c4"}
{"desc":"#3 #security\nThe storage server only needs to have write access to google cloud storage.","position":1.6875,"last_edited":1431557445591,"task_id":"236dfd92-3c02-4a74-a34a-d112bf4709c2"}
{"desc":"#1 \ndevel firewall metadata...","position":1.71875,"last_edited":1431557640039,"task_id":"8ddd978d-4659-49aa-8ea9-1453538b9683"}
{"desc":"(0:27) #0 #billing (0:30?) #now\nremove/disable the move project ui stuff when billing enabled.","position":-0.25,"last_edited":1431635166239,"task_id":"cc1b4cf7-9f37-423b-baa0-a72b0362597d","done":1431635165830}
{"desc":"#0 #billing (1:30?)\nstripe functionality to create a charge that the user needs to pay:\n\n- will be clearer when above is all done.\n- for now I can manually create some via the stripe website.\n\nhttps://stripe.com/docs/api#invoices\n\n\nstore in database a list of charges for a given account:\n\n\taccount_id, invoice_id, date created, date due, description, amount, when paid","position":-0.125,"last_edited":1431632053970,"task_id":"7f110a03-7347-4e46-930f-25804e60e000","deleted":false,"done":1431632053556}
{"desc":"#0 #billing (1:00?)\napi to get a list of due charges for a given account and display in billing tab\n\n- [ ] message\n- [ ] handle in hub\n- [ ] handle on client","position":-0.375,"last_edited":1431623002401,"task_id":"05e7077a-1369-4c86-8fdc-82205eb2b293","done":1431623001978}
{"desc":"#0 #billing (1:30?)\nrethink ui to display charges (both paid and due) -- basically have something for this already, but via stripe.","position":-0.03125,"last_edited":1431632152864,"task_id":"5d869f3d-5c9b-442b-a130-7842e7e7e9e3","deleted":true}
{"desc":"#0 #billing (1:30?)\n","position":-0.1875,"last_edited":1431609294593,"task_id":"211d3c5d-0cad-4b74-921c-a09dd753b8e1","deleted":true}
{"desc":"#2 #billing (0:30?)\nmake site/#billing URL work.","position":-0.037109375,"last_edited":1431651767954,"task_id":"e58d63e8-cbe5-4d97-9dec-8fca4bff38b4"}
{"desc":"#0 #billing\ndownload invoice as pdf\n\nuse: https://github.com/MrRio/jsPDF","position":-0.015625,"last_edited":1431632039622,"task_id":"f5b83cf8-f94f-41b4-8d22-1433f13e3f80","deleted":true}
{"desc":"#0 #billing\ndownload receipt as pdf\n\nhttps://github.com/MrRio/jsPDF","position":-0.0078125,"last_edited":1431632038112,"task_id":"716c1dff-e386-4da7-b732-64507840e748","deleted":true}
{"desc":"(3:09) #0 #billing (1:00?) #now\n\nwas very hard because stripe's template is missing key information, e.g., credit card last 4... so had to do it from scratch using pdfkit. \n\nMake it so receipts like this are served by the hub, with URL based on the invoice id:\nhttps://dashboard.stripe.com/emails/receipts/invrc_162RweGbwvoRbeYxsjHDiHSS\n\nPlan: copy the html and then modify it via some javascript.  Ugly but will look consistent with stripe emails, which is important. \n\nUse the cookie to authenticate this?","position":-0.0546875,"last_edited":1431646602750,"task_id":"8d891dcb-5750-4ce9-a6cc-81e633830516","done":1431646602334}
{"desc":"#0 #billing (1:00?)\nbetter payment history info","position":-0.0341796875,"last_edited":1431651774608,"task_id":"f60066ef-d904-4347-bf28-abe4cb1b09d7","done":1431651774203}
{"desc":"#0 #billing (1:00?) #now\nmake #download receipt/invoice thing use the email receipt permalink.","position":-0.04296875,"last_edited":1431651762146,"task_id":"ebe6e0b0-9a2a-41ff-a415-ba92f2be1d11","done":1431651761736}
{"desc":"#1 #billing (2:00?)\nWA state sales tax","position":-0.048828125,"last_edited":1432592039830,"task_id":"dd143602-b2d7-4f49-98a1-0bd642a2c5ac"}
{"desc":"#0 #billing #now\nemail invoice/receipt (?)","position":-0.0517578125,"last_edited":1431646509729,"task_id":"0c28ce50-7fca-43ce-aeda-f020a94a5bf8","deleted":true}
{"desc":"#1 #bug\noften the markdown editor preview appears messed up!  This is a horrendous critical bug!","position":-0.0458984375,"last_edited":1432051298372,"task_id":"43d036fb-db5f-4cf0-96bb-17e1bc83560a"}
{"desc":"idea - show what caused latex error!","position":-0.04443359375,"last_edited":1431814967394,"task_id":"b085ac6f-b88e-48d7-94f4-addda9767b75"}
{"desc":"#0 #upgrade (2:30?)\nbuild and release sage-6.7 for SMC\n\nAnnounce:\n\n- follow-up to this: https://mail.google.com/mail/u/0/#inbox/14d6bb45f5339f3b\n\nIssues:\n\n- make sure this issue gets fixed: https://mail.google.com/mail/u/1/#inbox/14d2816abad6f406\n","position":-0.04736328125,"last_edited":1432040496007,"task_id":"a3165154-cd00-4fa2-b9ec-5ae686637aa4"}
{"desc":"#0\nturn off and move everything off of compute3-us -- save money by spending less; don't need that machine.","position":-0.0447998046875,"last_edited":1431906396471,"task_id":"03ed16b4-00f3-42bd-992a-22b78956efab","deleted":true}
{"desc":"#4\nfricas eval issue -- https://mail.google.com/mail/u/0/#inbox/14d5f3f02841e2c5","position":-0.046630859375,"last_edited":1431926009173,"task_id":"42d91da2-25f9-40c0-8a8b-b865d8fa19ee"}
{"desc":"#0 (0:30?)\nupdate gce pricing","position":-0.048095703125,"last_edited":1432008687355,"task_id":"7b1bc325-a927-4536-8b2a-a72ad4013683","done":1432008686936}
{"desc":"#2\nsage-6.7 follow-up\n\n- [ ] `install_neuron()`\n\n- [ ] `pymc`","position":-0.0469970703125,"last_edited":1432513066963,"task_id":"474b8fba-7368-49dc-adc1-afd4b3d6922d"}
{"desc":"#1 (1:00?)\nbug in published ipython notebooks in firefox\n\nhttps://mail.google.com/mail/u/1/#inbox/14d596418a618bb0","position":-0.04718017578125,"last_edited":1432082759617,"task_id":"0090703f-682a-4b12-a6a6-3aaefc118ea3"}
{"desc":"#1 (1:00?) #bug\nmathjax in ipython notebooks\n\nhttps://mail.google.com/mail/u/1/#inbox/14d6cf1c40302290","position":-0.047271728515625,"last_edited":1432082790629,"task_id":"056aafef-fdd5-49f5-a93e-f24808c69c68"}
{"desc":"#1 #bug\nmake it so this eventual consistency can't happen:\n\n       H |                                                                     G\n                                                   hutchinsolm2@vcu.edu | 29643009-4800-48aa-93ee-f4beffe2001b |                                  Hutchi\n    nson |                                                                 Laura\n                                                   hutchinsolm2@vcu.edu | 482e1413-9473-4296-a68e-5795b61dc6f3 |                                  Hutchi\n    nson |                                                                 Laura\n                                                   hutchinsolm2@vcu.edu | a9231357-e282-48a0-bbce-fe4cdef7fbde |                                  Hutchi\n    nson |                                                                 Laura","position":-0.0473175048828125,"last_edited":1432144190293,"task_id":"56ff67a8-a4b2-4f41-a2bd-73207995def2"}
{"desc":"#2\ncomment on making realtime preview hookable.\n\nhttps://mail.google.com/mail/u/1/?pli=1#inbox/14c99e966642256c","position":-0.04734039306640625,"last_edited":1432483385511,"task_id":"f29d677f-1726-466b-aeb6-955795e7a4f4"}
{"desc":"#3 #ui\nway to change the tab switch bindings in SMC, or at least disable them.\n\nhttps://mail.google.com/mail/u/1/?pli=1#inbox/14d7e8adda0ca50e","position":-0.047328948974609375,"last_edited":1432485963723,"task_id":"75d0b0f1-9a08-4822-b727-15eafc7a74d6"}
{"desc":"#0 #now\nsetup devel environment\n- [x] change database password -- solution -- just replace password secrets with empty files.\n- [x] sendgrid -- empty file\n- [x] change ssl key  --\n\topenssl req -new -x509 -days 365 -nodes  -out nopassphrase.pem -keyout nopassphrase.pem\n- [x] https://dev.sagemath.com\n- [x] change ssh keys on storage, compute and smc nodes\n- [x] ssh keys\n- [x] sshfs config with project\n- [x] advertise.","position":-0.75,"last_edited":1432494888038,"task_id":"9a81581b-4385-4663-ac41-165fefbb3bfa","done":1432494887624}
{"desc":"#1 #bug\nfirefox and ipython notebook publishing and mathjax\n\nhttps://mail.google.com/mail/u/1/?pli=1#inbox/14d596418a618bb0","position":-0.4375,"last_edited":1432495057613,"task_id":"8b074ff7-772f-4eed-bef6-57a4f40d89d5"}
{"desc":"#0 #bug\ncompute server needs to set some more environment variables:\n\n    USER\n    USERNAME\n    declare -x LOGNAME=\"root\"\n    declare -x MAIL=\"/var/mail/root\"","position":-0.047351837158203125,"last_edited":1432574437733,"task_id":"6ea342e2-5f30-4ea8-9311-93a96db5f67b","done":1432574437061}
{"desc":"#idea\nincremental tar \n\nBasically do\n\n     tar --listed-incremental=incremntal.data -cvf project_id-timestamp.tar project_id/\n     tar --listed-incremental=incremntal.data -cvf project_id-timestamp.tar project_id/\n\netc. and to extract\n\n     tar --listed-incremental=incremntal.data -xvf project_id-timestamp.tar\n\nwhere incremntal.data just grows with more info over time.\n\nTEST:\n\n\ttime tar --listed-incremental=/tmp/inc -cvf - 5ec67a33-4346-4769-a1f1-b1dd6bb88a34 | lz4 - > /tmp/a.tar.lz4","position":-1.5,"last_edited":1430814539716,"task_id":"f28cc862-9a58-40e1-96f7-8148af79e9bb","done":1430814539716}
{"desc":"- [x] make a GCS bucket called smc-tar\n- [ ] tar_save: to smc_compute like archive, but with target incremental tar output\n- [ ] tar_pull: opens if necessary and gets the incrementals, optionally making snapshots as you go.","position":-2,"last_edited":1430814540441,"task_id":"a925f69f-cb8f-4d99-8722-f8f12e9fc514","done":1430814540441}
{"desc":"incremental tar -- total  FAIL.\n\nnext idea:\n\n- k nodes each with a 1TB PD ZPOOL with no dedup but yes compression.\n- put each project on 2 of the four nodes\n- in database have column locations that maps timestamps to hostnames\n- run my old bup_server code, but without the bup stuff at all\n- make the rolling ZFS snapshots nicely available to users\n- periodically rsync for replication (but nothing to do with snapshot times, except rsync last snapshot maybe)\n","position":0.6640625,"last_edited":1430817907287,"task_id":"b980e216-295d-40d7-b0f3-ea76f92381de","done":1430817906866}
{"desc":"(0:30?) create one more powerful storage node from that backup I was making -- restart those going, but with more --excludes.","position":1.0052083333333333,"last_edited":1430817922846,"task_id":"451e23b7-b9b5-42dd-954f-4c4a71ba0ba1","done":1430817922437}
{"desc":"#now (1:00?)  add function to smc_compute.py to save/open/close project using this new method.","position":2.583333333333333,"last_edited":1430820343167,"task_id":"f6fce875-d897-4bc5-a2f3-6f741a41c291","done":1430820342758}
{"desc":"#0\n(1:30?) change compute.coffee to check in db to see if project is using this new method and if so, use it instead on a node that can use it (like experimental).  get this to fully work on test projects.","position":2.7604166666666665,"last_edited":1430862561460,"task_id":"b0e84fc9-bc12-43f5-8877-e03b8c03aa91","done":1430862561045}
{"desc":"#0 (1:00?) #now\n- [ ] once the rsync from uw is done, make a snapshot at that point.\n- [x] setup something that rsync's from the 6 machines right now in a loop periodically, and run that.\n- [ ] setup rolling snapshots (find some scripts)","position":3.125,"last_edited":1430907605995,"task_id":"43d2e4bc-0cb4-460c-bfde-a8ce7e4889f8","done":1430907605580}
{"desc":"#idea OK, so the fastest imaginable way to do this is to:\n\n- use the rsync daemon: about 4GB/minute\n- using ssh with the right options: about 3GB/minute\n\nSECURITY:\n\n- i could make a storage daemon and have all moving of files be done *from* there for better security, so the compute vm's don't have to do anything dangerous regarding write... exporting snapshot dirs, which gives full read access to an attacker.","position":3.5,"last_edited":1430855014673,"task_id":"2f812913-5b26-4f91-8f01-b1c0b89b6a95","done":1430855014260}
{"desc":"#1\n(1:00?) implement read-only nfs mounting of snapshots from storage server to compute servers","position":5,"last_edited":1431137105302,"task_id":"29e7bf18-8fd9-4224-8bf4-f403d5bbd0c0","done":1431137104895}
{"desc":"#1\n(1:00?) implement way for users to browse their snapshots.  HOW?!??!\n\n1. make it so when git-ls requests listing for `.snapshots/timestamp`, only include  .snapshots/timestamp/project-id in listing....\n2. on client side when user clicks on .snapshots/timestamp/, instead open .snapshots/timestamp/project-id/ instead.\n\n\n","position":6,"last_edited":1431137110029,"task_id":"7e7f0e1c-214b-45f7-9d8a-11738bede73f","done":1431137109609}
{"desc":"#0 (2:00?) \nmake new cluster and switch everything over\nPLAN:\n- [x] setup new compute0 that is upgraded and works -- test (make compute0 experimental).\n- [ ] #now make it so smc_compute close on old nodes does an rsync right after a normal close.\n\n(currently getting this error on move open):\n\n        2015-05-07T03:39:58.450Z - debug: mesg (hub <- compute0-us): {\"event\":\"error\",\"error\":{\"errno\":19,\"code\":\"SQLITE_CONSTRAIN\n        T\"},\"id\":\"4ca30a1c-9bc0-4a8c-b08b-fba1d6b74124\"}\n        2015-05-07T03:39:58.450Z - debug: ComputeServerClient.call(hub --> compute0-us): got response -- {\"event\":\"error\",\"error\":\n        \"[object]\",\"id\":\"4ca30a1c-9bc0-4a8c-b08b-fba1d6b74124\"}\n        2015-05-07T03:39:58.451Z - debug: ComputeServerClient.call(hub --> compute0-us): error = [object Object]\n        2015-05-07T03:39:58.452Z - debug: ProjectClient(project_id='666c7f0b-277f-4ed6-868c-9d6df7d8d59c','compute0-us')._action(a\n        ction=open): error calling compute server -- [object Object]\n        DONE { errno: 19, code: 'SQLITE_CONSTRAINT' }\n\n- [x] test save on project with sshfs mounts...\n- [x] ensure rsync save failures are recorded somewhere so I can look at them all\n- [x] make it so any newly opened projects open on compute0 by making old compute nodes experimental and making new compute0 NOT experimental anymore. test moving some projects.\n- [x] spin up compute1, compute2, compute3.\n- [x] amazon dns for compute vm's\n- [ ] move all projects to new cluster\n- [ ] shut down old cluster\n- [ ] switching europe smc nodes to use europe database servers and update all smc servers (so shorter mintime)\n\n- [x] **WORRY:** if error when checking out project, later save will delete everything!!?  Could track state in local DB.  Or only allow save when running except with a force option, and make getting to running require open to succeed.","position":3.25,"last_edited":1431137039575,"task_id":"e163e304-f412-4d0c-be84-e81aa60b6138","done":1431137039158}
{"desc":"#2\n(2:00?) make storage server redundant\n- snapshot disk\n- start another similar machine called storage1\n- have the rsync_save process just save to one at random and do something (e.g., timestamp of directory or database entry) so that server knows to push to other\n- have the rsync_open process just try to load from one at random, and if fails, try the other.\n- periodic sync by backend on changed directories","position":3.416656494140625,"last_edited":1431540161235,"task_id":"a74cf911-e2bc-4da3-8a04-ca3edb6fc343"}
{"desc":"3GB/m open scrollbar.","position":3.4375,"last_edited":1431137089349,"task_id":"7c98e4e8-9d00-4f15-a08e-ce6735d07080","done":1431137088940}
{"desc":"#1\nsnapshot browser should have default option to restrict to only snapshots where you (or project or some users) were active, based on database....","position":3.1875,"last_edited":1431295355120,"task_id":"7b1c85e6-8755-4a33-90fa-d8aacd759454","deleted":true}
{"desc":"#0 #backup\nneed new cassandra backups to nearline cloud storage and offline...","position":3.1572265625,"last_edited":1431308237064,"task_id":"a131158f-c259-4544-9f5a-ee5a10f479d1","done":1431308236648}
{"desc":"#2\ncritical -- MUST make system immune to user fork bombs!","position":3.498046875,"last_edited":1431295404362,"task_id":"7690b55b-5ecf-4a03-9cb8-6b48d4eecf35","deleted":true}
{"desc":"#0\nupgrade to Ubuntu 15.04 \n- [x] make base image bigger.\n- [x] may fix btrfs crashes, compile sage problems.\n\n      libghc-gtk-dev libghc-gtk-doc libghc-hint-dev libghc-hint-doc\n      libghc-io-storage-dev libghc-lens-dev libghc-lens-doc\n      libghc-nats-dev libghc-nats-doc libghc-pango-dev libghc-pango-doc\n      libghc-pointedlist-dev libghc-pointedlist-doc libghc-polyparse-dev\n      libghc-prelude-extras-dev libghc-prelude-extras-doc\n      libghc-profunctors-dev libghc-profunctors-doc libghc-reflection-dev\n      libghc-reflection-doc libghc-regex-tdfa-dev libghc-regex-tdfa-doc\n      libghc-scientific-dev libghc-scientific-doc\n      libghc-semigroupoids-dev libghc-semigroupoids-doc\n      libghc-semigroups-dev libghc-semigroups-doc libghc-src-exts-dev\n      libghc-tagged-dev libghc-tagged-doc libghc-terminfo-dev\n      libghc-terminfo-doc libghc-transformers-compat-dev\n      libghc-uniplate-dev libghc-unix-compat-dev libghc-utf8-string-dev\n      libghc-utf8-string-doc libghc-utility-ht-dev libghc-void-dev\n      libghc-void-doc libghc-vty-dev libghc-vty-doc\n      libghc-xdg-basedir-dev libghc-yi-doc libginac2 libgrail6 libgrip0\n      libisl10 libmagick++5 libmagickcore5 libmagickcore5-extra\n      libmagickwand5 libmirclient8driver-mesa libmircommon2\n      libnunit2.6-cil libopenvg1-mesa libpci-dev libpoppler46\n      libprotobuf-lite8 libprotobuf8 libtorque2 libts-0.0-0\n      libwayland-egl1-mesa linux-headers-3.16.0-34\n      linux-headers-3.16.0-34-generic linux-headers-3.16.0-36\n      linux-headers-3.16.0-36-generic linux-headers-3.16.0-37\n      linux-headers-3.16.0-37-generic linux-image-3.16.0-34-generic\n      linux-image-3.16.0-36-generic m17n-contrib python-greenlet\n      ruby-commander ruby-highline ruby-maruku ruby-nokogiri\n      ruby-rdiscount ruby-redcloth tsconf","position":3.15625,"last_edited":1430947367228,"task_id":"f7bae4fc-909e-44b0-859f-55937762870b","done":1430947366818}
{"desc":"#1 (0:30?) #now\nmove admin machine to us-central1-c","position":3.3125,"last_edited":1431150341584,"task_id":"2cc763bb-bfc3-41b3-8aae-fc68eb74267d","done":1431150341179}
{"desc":"#0 (0:30?)\n","position":3.21875,"last_edited":1430961901874,"task_id":"e80d9aca-4843-453c-98c8-9377fb76e195","deleted":true}
{"desc":"#0 (2:00?)\nimplement snapshot system\n\n- [ ] when opening a project, create symlinks for each snapshot in the NFS share\n- [ ] when saving, update this list\n\nThis will basically work and can be improved.  Since old snapshots get deleted sometimes, this will sometimes break.  Good enough for now.","position":3.28125,"last_edited":1430996629883,"task_id":"c96e3ff8-261a-4b5a-ad5f-e6e81d6caf40","done":1430996629462}
{"desc":"#1\nre-enable automatic failover\n","position":3.265625,"last_edited":1431137054100,"task_id":"f7c6ba55-3e56-4838-b634-e7e059e201e9","done":1431137053688}
{"desc":"#0\nsnapshots -- on save maybe also make tons of local btrfs snapshots of the project subvolume... ?","position":3.2578125,"last_edited":1430996627259,"task_id":"25111dba-a386-4ab6-825c-d3ead86575f4","done":1430996626830}
{"desc":"#0 (0:10?) (0:04)\nSee console.log message when loading a public page\n\n\topts.content=","position":3.25390625,"last_edited":1431555975669,"task_id":"f4a382e8-168a-4019-9c5c-415c1f8726c4","done":1431555975259}
{"desc":"#0\ncan't start nfs snapshots while firewall up.","position":3.255859375,"last_edited":1431137051856,"task_id":"01f80029-bedd-4d7f-971f-4654522854a9","done":1431137051443}
{"desc":"#1 (1:00?) #compute\nrestarting compute needs to open service firewall for all projects that are running and have network access.\n\nhttps://mail.google.com/mail/u/1/#inbox/14d31c56059bfd51j","position":3.1650390625,"last_edited":1431539296580,"task_id":"186f14ed-ae4b-4be0-9ea9-8fc0a8416d98","done":1431539296169}
{"desc":"#1 #invalid \nrewrite status/state/etc. functionality to not call python script at all -- have compute directly do those things.","position":3.1796875,"last_edited":1431539485701,"task_id":"b5df689e-7602-4288-893f-ddacc07b47ab","done":1431539464734}
{"desc":"#0 (1:00?)\nsetup devel cluster\n\n- [x] #now fix so this is automatic\n\n        salvus@smc0-devel-us-central1-c:~/salvus/salvus/data/cassandra-0$ ln -s ../local/cassandra/lib .\n        salvus@smc0-devel-us-central1-c:~/logs$ rm cassandra.log ; ln -s /home/salvus/salvus/salvus/data/cassandra-0/logs/system.log cassandra.log\n\n","position":3.1640625,"last_edited":1431295504006,"task_id":"1e99abdc-a12a-4631-bdd2-4b82f0984a5b","done":1431295503594}
{"desc":"#2 #storage\ndecide how to make storage not a single point of failure\n\nIf I change all the read-only snapshots to be read-write (but still mount read-only via sshfs), then I can replicate even the snapshots using rsync.","position":3.34375,"last_edited":1431556006666,"task_id":"3feebda3-50a1-4c68-ba57-566bafc41c39"}
{"desc":"#1 (0:30?) #now\ncompletely redo the europe database.\n\nDO NOT FORGOT to turn of auto_bootstrap False this time!!!!","position":3.15966796875,"last_edited":1431315977604,"task_id":"fe4bb9a4-04d2-4aa4-9813-7b3ba7829024","done":1431315977185}
{"desc":"#0\nideas to make storage0 better\n- it could itself be a cache with something else that is ","position":3.169921875,"last_edited":1431188504363,"task_id":"4811648d-9c04-4f9d-aa27-fd2ba3b300c0","deleted":true}
{"desc":"#0 (1:00?) #backup\nupdate nearline backup of all projects that changed in the last 3 days...\n\n- [x] spot checks\n- [x] (0:09) (0:20?) copy all projects data files (but no tarballs) to /backups on storage0 via rsync: `time rsync -axvH --exclude *lz4 backup0:/backups/ /backups/ 1>sync_from_backups.log 2>sync_from_backups.err`\n- [x] #now (0:30?) add function to compute.coffee that runs tarball update on all projects modified since a given point in time.\n- [x] (0:10?) upload new backups to nearline\n- [ ] (0:10?) and offsite...\n- [ ] (0:10?) and delete from local cache\n- [x] (0:30?) setup crontab on storage to update /backups periodically for now...","position":3.158203125,"last_edited":1431313135008,"task_id":"875a1fc7-68ae-4fe8-9a85-c557cf23f2f9","done":1431313134601}
{"desc":"#0 \ngit-ls don't show broken symlinks in .snapshots dir.","position":3.16455078125,"last_edited":1431274838689,"task_id":"57e5e2e6-45e7-4dd9-b1cb-d173c6745e1f","done":1431274838278}
{"desc":"#0 #monitor #now (0:15) (0:15?)\naws health checks and dns","position":3.159912109375,"last_edited":1431345707987,"task_id":"44174bc5-3c03-4441-af60-ddaa3edf8994","done":1431345707575}
{"desc":"#0 #monitor (1:10?)\nadmin monitor script\n- [ ] get it to work (0:30?)\n- [ ] reset disk usage thresh (0:10?)\n- [ ] setup email notification (0:30?)","position":3.165771484375,"last_edited":1431404072098,"task_id":"bcefdbb2-e7cd-4e4f-bf75-ba74b3e3b7c5","done":1431404071675}
{"desc":"#0 (0:30?) (2:28) #storage #devel #now\nsetup devel cluster: storage server\n\ntook a long time since I automated a lot more... and it was complicated","position":3.1663818359375,"last_edited":1431555737914,"task_id":"68073817-533c-4f55-84c0-576072d999db","done":1431555737499}
{"desc":"#now #0 (1:00?) #devel\ngce.py script to stop/start all nodes in devel cluster to save money","position":3.16552734375,"last_edited":1431315236811,"task_id":"6f4d8d39-ee12-42a5-9716-b91a9d824f5e","done":1431315236403}
{"desc":"#1 (0:30?) #compute\nthat RAM usage thing in quotas looks dumb -- hide or fix...","position":3.1669921875,"last_edited":1431539458579,"task_id":"665b4e46-53df-4c44-9461-3968ed4ec953","done":1431539458168}
{"desc":"#0 #now\nrestart each cassandra to get rid of incremental backups.","position":3.1591796875,"last_edited":1431308217537,"task_id":"2316ad65-955f-47ea-9798-a7a328d4897b","done":1431308217120}
{"desc":"","position":3.15869140625,"last_edited":1431313008583,"task_id":"3ead3628-d687-4df2-a628-0719bf4fc8ce","deleted":true}
{"desc":"#0 (1:00?) #critical #now\nrewrite smc_compute.py to use setuid instead of su -- it will be massively faster. GAME CHANGER.\n\n- http://stackoverflow.com/questions/25928190/python-run-command-as-normal-user-in-a-root-script\n- http://stackoverflow.com/questions/1770209/run-child-processes-as-different-user-from-a-long-running-process\n\n\n\t\t>>> os.setuid(uid)\n        >>> os.system(\"cd /projects/97145daf-9bea-4b42-b075-807e07950981/.sagemathcloud && ./status\")\n        {\"sage_server.pid\": false, \"secret_token\": false, \"raw.port\": false, \"sage_server.port\": false, \"installed\": true, \"version\": 1430868307, \"local_hub.pid\": false, \"local_\n        hub.port\": false, \"console_server.pid\": false, \"console_server.port\": false}\n        0\n        >>> os.system(\"cd /projects/97145daf-9bea-4b42-b075-807e07950981/.sagemathcloud && whoami\")\n        97145daf9bea4b42b075807e07950981\n        \n        \nor\n\n        >>> import os\n        >>> os.setuid(12090511)\n        >>> os.chdir(\"/projects/c5e7c26c-93bb-4d95-8622-fca228b6cb1c/.sagemathcloud\")\n        >>> os.popen(\"./status\").read()\n        '{\"sage_server.pid\": 2844, \"secret_token\": \"LUgJopyLhEofMY08qt24ylFBbhU2DEw1Lrs74liDurLy5makwLQka93R9rBqv+U//DxbGLJnk/MM6+3idqRzCq9Ei3wjosGypmTPv7ws81l/lbchV3gSzwpBJ1wLO\n        XVF9HfkVO/IkNlYWpQeFjn98z1zcnV8MnvqzX7iEK3yg74=\", \"raw.port\": 54297, \"sage_server.port\": 36738, \"installed\": true, \"version\": 1430868307, \"local_hub.pid\": 2423, \"local_h\n        ub.port\": 56005, \"console_server.pid\": false, \"console_server.port\": false}\\n'","position":3.162109375,"last_edited":1431380566435,"task_id":"add378d2-6d9f-46d4-8a09-b87b6167b6c4","done":1431380566017}
{"desc":"#now\ndelete snapshots\n\njust finish it...","position":3.1611328125,"last_edited":1431359327627,"task_id":"e8d98fbe-46d0-4d81-9459-965fee4313fd","done":1431359327200}
{"desc":"(1:00?) #0\nchange smc_compute.py to not use btrfs operations at all?\n\n- [x] just rsync the .sagemathcloud template\n- [x] just mkdir the project home\n- [x] use traditional quotas (later)\n\nIt's not clear if this helped or not.   It seemed to remove a bottlekneck.","position":3.1630859375,"last_edited":1431371707919,"task_id":"55fabe80-8261-411f-a389-13d3e0ae182e","done":1431371707511}
{"desc":"(1:00?) #0 #now\nspin up commercial machine and move projects there as requested","position":3.16357421875,"last_edited":1431367004244,"task_id":"79b829c1-df62-4319-a8e6-90de4f9e7342","done":1431367003823}
{"desc":"#0 redo machines\n- [x] redo compute1\n- [x] redo compute2\n- [x] redo compute3\n- [x] #now -- redo compute0","position":3.15997314453125,"last_edited":1431401834337,"task_id":"b67af385-9150-43c5-9f65-0a09e31a54c9","done":1431401833914}
{"desc":"#0\n- [ ] adjust failover thresh\n- [ ] restart hubs in europe with new database","position":3.1600341796875,"last_edited":1431402281158,"task_id":"118dd43f-9cd4-4333-aae2-5dca548b5211","done":1431402280737}
{"desc":"#0 #now\nquotas\n\n- [ ] how does it work traditionally...?\n\nFollow this nice clean guide: https://www.digitalocean.com/community/tutorials/how-to-enable-user-and-group-quotas\n\nFail and fix this way: http://askubuntu.com/questions/109585/quota-format-not-supported-in-kernel\n\n    apt-get install linux-image-extra-virtual\n    \n    ","position":3.160003662109375,"last_edited":1431413425277,"task_id":"10fce686-7031-472f-81ca-ca139ea932ae","done":1431413424863}
{"desc":"#1\nadd a 'for pay' attribute to projects and to compute servers, etc...\n\n- and an index?","position":3.16668701171875,"last_edited":1431539453807,"task_id":"7d1d4614-7703-4bf0-8a5d-7797e420b721","deleted":true}
{"desc":"#0 persist quotas\n\n- [x] mintime\n- [x] network\n- [x] disk_quota\n\n- [ ] cores     \n- [ ] memory    \n- [ ] cpu_shares","position":3.164794921875,"last_edited":1431419295820,"task_id":"29bd68c6-a31e-407b-abb5-865fc205299c","done":1431419295409}
{"desc":"#2 (1:00?)\ndelete invalid entries from cgrules...\n\n- [ ] when compute server is restarted rewrite cgrules file based on what is running according to db (basically all open/running)","position":3.1649169921875,"last_edited":1431540157207,"task_id":"32a21811-fbb9-4718-9791-f2a9d0ac5c35"}
{"desc":"#0 #now\ncritical -- look into all `/projects/*/.sagemathcloud-open-failed`","position":3.16497802734375,"last_edited":1431539257796,"task_id":"c1d89745-7c44-40bf-bca9-c5402499b926","done":1431539257378}
{"desc":"#3\ndelete all accounts of users that are running whenever restart compute server (?) --  at least users whose project isn't on this computer.  otherwise they can ssh in and get very confused... this is hard to do.","position":3.165008544921875,"last_edited":1431481487413,"task_id":"c79b338b-7e8c-46bd-bb41-58cab5029592"}
{"desc":"#feature\n\nstarring files to bookmark them. i.e. instead of opening the log to see where you have been recently, browse a list of bookmarked files.","position":3.359375,"last_edited":1432588175933,"task_id":"efe6db4f-1cc7-47bd-94a6-760ead2cfe49"}
{"desc":"#feature\n\n### better templates for new projects and files\n\n* setup .gitconfig:\n   * user.name, user.email\n   * add a ~/gitignore file with `*.sage-chat` and other files, probably such that git init in \\$HOME is not adding too much\n   * set core.excludesfile = ~/gitignore\n\nbetter template for LaTeX, etc.","position":3.3671875,"last_edited":1432588428923,"task_id":"7fc87d74-c61b-4900-94a5-4998786c18ee"}
{"desc":"#feature #sagews\n\npagebreaks for PDF and html renderings of a sagews\n\nhttps://github.com/sagemath/cloud/issues/82","position":3.37109375,"last_edited":1432589110968,"task_id":"4ec2ea0c-d06c-4c45-9979-96d8f5a87ba7"}
{"desc":"#sagews\n\nThe parsing of \"cell/string\" decorators is too aggressive, since this fails:\n\n    print(\"%s\"\n          % \"hi\")\n\nhttps://github.com/sagemath/cloud/issues/135","position":3.373046875,"last_edited":1432589284073,"task_id":"d8a5d731-3620-42ad-90c1-297b2a940520"}
{"desc":"#ui #files\n\nbetter status information when opening/reloading a project (add explanation about this with a link to restarting the project, progress information about loading the data files, etc.)\n\nhttps://github.com/sagemath/cloud/issues/94","position":3.3740234375,"last_edited":1432589419022,"task_id":"389d910a-4a2b-4592-b7c1-f9889a8eadd4"}
{"desc":"#sagews download button next to save button\n\nhttps://github.com/sagemath/cloud/issues/90","position":3.37451171875,"last_edited":1432590075102,"task_id":"2531ede6-aed4-4240-84a2-1a40c55cbeac"}
{"desc":"#sagews improve error reporting of line numbers \n\nhttps://github.com/sagemath/cloud/issues/47","position":3.374755859375,"last_edited":1432590300105,"task_id":"3db1bb00-84c4-44d8-9cf9-75608df4151b"}
{"desc":"#sagews2pdf small fix for plotting larger images\n\nhttps://github.com/sagemath/cloud/issues/103","position":3.3748779296875,"last_edited":1432590800562,"task_id":"59b3c0cd-8559-491c-9689-fce7444d314e"}
{"desc":"#sagews record start/stop time of computations\n\nhttps://github.com/sagemath/cloud/issues/177","position":3.37493896484375,"last_edited":1432590938236,"task_id":"cd0fa473-5e1c-42f3-b872-faec02311543"}
{"desc":"#email send new users a short welcome email, such that they can search for it in the future and come back (include keywords like SageMathCloud etc.)\n\nhttps://github.com/sagemath/cloud/issues/87","position":3.374969482421875,"last_edited":1432591398651,"task_id":"5a1c47c6-246c-45c6-a486-c579c187fc34"}
