{"desc":"(1:30?) \n`salvus/sync/timesync.coffee`\n\ncreate this file and put current SyncString class there, and make things work","position":-1,"last_edited":1442204534647,"task_id":"0ee2390a-d68a-4e23-9a32-de7b1ba9099d","done":1442204534229}
{"desc":"think through what we really need:\n\n- need a robust synchronized key:value store, where key's are time-uuid's.\n- on that, building sync is pretty easy.\n- how to do it?\n- using rethinkdb should make it much more robust, since it has guarantees about messages not being lost\n- using rethinkdb means efficient use of memory vs disk.\n- using rethinkdb means editing of documents that aren't *in* projects, and possibly a better security model.\n- fear about rethinkdb is... what if it can't take the load? \n- also, multi-data center is worrisome. \n- this will reduce load on local_hubs/compute vm's\n- multi-data center can be done by having a timesync table for each data center with primary write replicas only in each DC.\n- load coming from sync table can be dealt with by putting shards only on certain hosts.\n\n-----\n\nHow to build robust sync'd key:value on database?\n\nAs now:\n  - do query and get results\n  - changefeed and send\n\n\n\n\n","position":0,"last_edited":1442191088299,"task_id":"0053c1ff-a1f5-423d-918c-9a6fc24c6e1f","done":1442191088299}
{"desc":"(1:30?) move SyncTable from client.coffee to salvus/sync/table.coffee and make things work","position":-0.52734375,"last_edited":1442207467679,"task_id":"a8f8f08b-957b-4bdf-af45-5cac12d88dc3","done":1442207467256}
{"desc":"(2:00?) make it so local_hub backend can use synctable","position":-0.0546875,"last_edited":1442207481361,"task_id":"c62df0fd-78c9-4fbf-8c28-83412de765fb"}
{"desc":"(1:30?) make it so sync/table has a sequence number:\n\n- [ ] (0:30?) add number when sending changefeed message from rethink.coffee backend\n- [ ] (0:30?) add number to \"list of changefeed id's\" thing on backend\n- [ ] (0:30?) make client reset if number gets out of sync","position":-0.046875,"last_edited":1442191263832,"task_id":"5f56c0e3-1c95-428e-8a10-ab47e451968a"}
{"desc":"(2:00?) integrate new sync with syncdoc in a selectable way","position":-0.10638427734375,"last_edited":1442201222834,"task_id":"8f2f7ccf-067a-433a-9d93-15d3b0660bdb"}
{"desc":"(1:00?) make it so local_hub backend can use syncstring","position":-0.052734375,"last_edited":1442207494691,"task_id":"d99ae8fc-5f8a-49fe-9f14-f4395607172c"}
{"desc":"(0:45?) (0:04) #optimize #now\n- [ ] store patches in database in compact format as defined in diffsync.","position":-0.291015625,"last_edited":1442211421155,"task_id":"4b859fc0-57fe-4727-859e-bb23434c624e","done":1442211420749}
{"desc":"(0:45?) #optimize #now\nmake it so syncstring doesn't recompute result of applying all patches every time.\n\nWow, this is an interesting algorithmic question!\n\nThe input is an immutable js map from time uuid's (to patches) and past information that we chose to keep.\nThe output is the result of applying in order (by uuid) the patches.\n\nIdeas:\n\n- simplest is what we have, which is just do the full thing every time.  This is O(n*log(n)), where\nthere are n patches.  Have to sort O(n*log(n)), then apply each patch in order O(n). Much bigger constant for second O(n), and also that assumes patches have bounded size, which is false.\n\n- suppose we know the full *last* immutable js map, the last result of concatenating all patches in order, and a list of the time-uuid's that are the keys of the map. Suppose we get one new time->patch key/value.  We could find the position of this new time in the previous list.  Apply the inverses of all the patches after it to the final string.  Apply our new patch.  Then apply the patches that were after it.   Since newly inserted ones will be near the end (and can be bounded time back by assumption), this algorithm is O(1) (modulo constant depending on patch size).\n\nWe really need to store sorted list:\n\n   [ .... {time patch objects} ...]\n   \nwith the patch object having the actual time included.     \n\nProblem with the above: Inverting patch probably only work if the patch applies cleanly.  Patches may not apply cleanly.  So the above isn't an option.\n\n**THIS:** But we know if patch did or didn't apply cleanly.  If it didn't, we can compute one that would\napply cleanly and store that locally for use if needed.  This should be very rare.  We can have a cleaning process so that after a certain window, we replace patches so that they always apply cleanly.\n\n- suppose we have\n\n    [ ... {patch object} ... ]\n    \nwhere patch object has the time and also -- for the most recent k patches -- a copy of the full\ndocument at that point in time.   As we add more of these we delete the copy of the document.\n\nThis is very worrisome, since if k=50, and we edit a 2MB document, that's 100MB.  \nAnd memory is usually the issue.    \n\nWe could define a too late to insert new docs in window at say 30s.\nThen we store the version of the document from around 30s ago and the time-uuid for that.\nWhen new patch comes in, if time uuid newer than all so far, we just apply it.   Also,\napply older patch to 30s ago version of the document.  If new patch comes in and time uuid\nis *NOT* newer than all so far, if new patch is >= window, then we delete all back to the window\nand re-apply from there.    If patch is older than window, start over (?).\n","position":-0.261474609375,"last_edited":1443285596689,"task_id":"3d4857fd-cf07-491d-be91-ae9197735c8b","done":1443285596267}
{"desc":"(1:30?) \nfigure out how to store snapshots","position":-0.11376953125,"last_edited":1443285602029,"task_id":"d0562180-9aae-4338-93b2-95cc4afe65f0","done":1443285601616}
{"desc":"(2:00?) implement way to resolve conflicts (or apply on top) when user wasn't able to insert changes because they were offline.","position":-0.084228515625,"last_edited":1442207697363,"task_id":"42b4e6f2-7edf-4fee-9616-9fe342e6f5f0"}
{"desc":"(1:30?)\nCorrectly support permissions for a syncstring being defined by a project_id and path to being defined by an id.\n\nHave a second table that has all syncstrings:\n\n- for a given project\n- possibly later for other things\n\nBut then permissions are trickier.  But this is the right thing to do.\n\nSee the critical remarks in schema.coffee about what we have to do.\nI particular, have to have a good way of reporting and handling errors\nin case of a time-uuid conflict.  Should probably only ever happen in\ncase of a malicious user, but still.","position":-0.23193359375,"last_edited":1443134522171,"task_id":"126d13d8-4f50-4f14-b6ed-d190e6df53cf","deleted":true}
{"desc":"(2:00?)\nmake it so doing a query on the syncstring table only returns the results up to the more recent snapshot, not everything.  I don't know how to do this yet, but it must be possible.","position":-0.06207275390625,"last_edited":1443285617751,"task_id":"058534ae-9ddf-4b69-adff-25bd1cb0f475","done":1443285617346}
{"desc":"(2:00?) user's clock synchronization","position":-0.202392578125,"last_edited":1443285600121,"task_id":"215a1559-71f5-4475-bc3b-a6ceedfe1609","done":1443285599714}
{"desc":"","position":-0.1876220703125,"last_edited":1442210766182,"task_id":"6c1855d8-f987-4c41-8c3a-5fbcc04f7112","deleted":true}
{"desc":"#now (1:00?) (0:43)\n\ntry to rewrite syncstring to use compound primary key","position":-0.2762451171875,"last_edited":1443134505240,"task_id":"a945b2ca-b578-42f1-9f6d-4c62ec2ef76b","done":1443134504821}
{"desc":"restructe ","position":-0.2467041015625,"last_edited":1443134516256,"task_id":"81ce3f7d-014c-4856-b6b2-75aaadb78cea","deleted":true}
{"desc":"(0:55) restructure data with two tables:\n\n- syncstrings: \n   - string_id=primary key\n   - project_id if permissions are to be determined by a project.\n   - other info like last snapshot time_id.\n   - users: {account_id:\n\n- patches: what is currently the syncstrings table but make it so time queries are possible, so maybe\n   - primary_key is: [string_id, time, account_id], so account_id can break ties and can do range queries\n   - patch\nand that is it.\n\n","position":-0.19500732421875,"last_edited":1443138585765,"task_id":"8eba2a30-4821-4bd8-a3ac-f6211327277c","done":1443138585346}
{"desc":"(2:00?)\nmake secure regarding access to tables","position":-0.0989990234375,"last_edited":1443138616404,"task_id":"cc06eccc-8f4d-4aa1-8867-d69f2f4b7211"}
{"desc":"readonly mode -- store in state document in database and toggle","position":-0.102691650390625,"last_edited":1443289864148,"task_id":"c12de9ab-f2b4-41d0-a761-6d2b4791f95f"}
{"desc":"filename changing... (due to move)","position":-0.1008453369140625,"last_edited":1443289871865,"task_id":"53af0dbf-0e5a-4514-8d83-252248651eed"}
{"desc":"cursors table","position":-0.09992218017578125,"last_edited":1443289875576,"task_id":"ec026d61-5fa8-4bfe-b266-efad592b5a83"}
{"desc":"robustness -- no matter what if in any way the client re-connects, we need to reset\nthe changefeed right now.  \n\nCould overcome this by only doing this if there were new changes (according to backend)","position":-0.110076904296875,"last_edited":1443409751614,"task_id":"6c3772eb-9b40-4017-ab98-98cce2de5f1f","done":1443409751209}
{"desc":"These parameters in diffsync.coffee:\n\n    dmp.Match_Threshold = 0.3   # make matching more conservative\n    dmp.Patch_DeleteThreshold = 0.3  # make deleting more conservative\n\nChanging them would change the value of the document and its history... if patches didn't apply.\nScary.   Could they be stored in the syncstring object in the db and set before each patch apply?","position":-0.1082305908203125,"last_edited":1443293415785,"task_id":"a7ad1b32-d1b9-4e61-a1d6-4f59f6126c92"}
{"desc":"(1:00?) address this todo in synctable.coffee: \n\n\t# TODO: group all queries in one call.","position":-0.1119232177734375,"last_edited":1443409744694,"task_id":"797fa391-777b-4a21-8ec5-f93b2671ba8f"}
{"desc":"(0:30?)\nsync_table -- change to use opts and change everything that calls it","position":-0.10915374755859375,"last_edited":1443411606715,"task_id":"9b9c218f-d8eb-4c26-9c70-0900cad4a291"}