{"desc":"#0 #critical #f1 (1:00?)\nInvoice download is broken!\n\nhttps://cloud.sagemath.com/invoice/sagemathcloud-william_a__stein-receipt-2016-03-28-in_17u1mGGbwvoRbeYxknzGboWn.pdf Failed to load resource: the server responded with a status of 504 (Gateway Time-out)\n\non web0 (didn't affect hsy, only me, possibly because new transaction done via stripe web ui):\n\n```\n/home/salvus/logs/hub1.log-4382549-2016-03-28T14:56:40.134Z - debug: Uncaught exception: Error: Stripe: I require argument \"id\", but I got: null\n/home/salvus/logs/hub1.log-4382550-2016-03-28T14:56:40.235Z - debug: Error: Stripe: I require argument \"id\", but I got: null\n/home/salvus/logs/hub1.log-4382551-  at Object.retrieve (/home/salvus/smc/src/smc-hub/node_modules/stripe/lib/StripeMethod.js:47:15)\n/home/salvus/logs/hub1.log-4382552-  at /home/salvus/smc/src/smc-hub/stripe-invoice.coffee:27:32\n/home/salvus/logs/hub1.log-4382553-  at /home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:713:13\n/home/salvus/logs/hub1.log-4382554-  at iterate (/home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:262:13)\n/home/salvus/logs/hub1.log-4382555-  at /home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:274:29\n/home/salvus/logs/hub1.log-4382556-  at /home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:44:16\n/home/salvus/logs/hub1.log-4382557-  at /home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:718:17\n/home/salvus/logs/hub1.log-4382558-  at /home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:167:37\n/home/salvus/logs/hub1.log-4382559-  at /home/salvus/smc/src/smc-hub/stripe-invoice.coffee:22:31\n/home/salvus/logs/hub1.log-4382560-  at [object Object]._onTimeout (/home/salvus/smc/src/smc-hub/node_modules/stripe/lib/StripeResource.js:87:34)\n/home/salvus/logs/hub1.log-4382561-  at tryOnTimeout (timers.js:224:11)\n/home/salvus/logs/hub1.log-4382562-  at Timer.listOnTimeout (timers.js:198:5)\n/home/salvus/logs/hub1.log-4382563-\n```","position":-1,"last_edited":1459271380080,"task_id":"caab1ee7-73bc-4ad8-a4e9-148c91895c1e","due_date":1459263487528,"done":1459271379639}
{"desc":"#course #0 (1:00?) (0:45)\nThe \"(has never used project)\" column in courses is wrong.  \n\nIt always says that no matter what.","position":0,"last_edited":1459278824911,"task_id":"5485acd0-7fce-4a6d-a056-fe98b887db8b","done":1459278824499}
{"desc":"#0 (1:00?) (0:17) #now\nrecompact table\n\n> danielmewes: The idea is to do something like this `r.db(...).table(...).update({dummy: null}, {durability: \"soft\"})` followed by `r.db(...).table(...).update({dummy: r.literal()}, {durability: \"soft\"})` to remove the `dummy` field again.\n\nimplement a command in rethink.coffee to do recompact, with a limit argument so we don't kill things.  then run on blobs.","position":-2,"last_edited":1459262021768,"task_id":"c824875d-c49d-456c-958a-488233523262","done":1459262021353}
{"desc":"#sync (1:00?)\nmassive number of writes per second when synctable keeps trying to rewrite patches\n\n> There is definitely some bug in the new sync code causing some clients to write a huge number of times to the patches table. Run query_stats on come web hubs instantly indicates this (by some huge set:n counts). So it will likely be easy to fix when I get time (probably tonight - definitely tomorrow). This will greatly reduce the db load from what it is now.","position":-1.5,"last_edited":1459267692349,"task_id":"75eca34a-dce2-49e4-ab97-17862833b87d"}
{"desc":"#1 (0:30?)\nsaw this in my console\n\n    invalid client query: not allowed to access key 'id' of 'project_log'; query={\"project_log\":{\"id\":\"6460ec8b-fa4b-437a-9d58-31643af1a1fb\",\"project_id\":\"369491f1-9b8a-431c-8cd0-150dd15f7b11\",\"account_id\":\"3c40513b-7e7c-450c-aa13-bf4f3411cf33\",\"time\":\"2015-10-09T11:17:22.439Z\",\"event\":{\"event\":\"open\",\"filename\":\"work/2015-10-09.sage-chat\",\"type\":\"chat\"}}}\n    client.js:2 _save('project_log') error: not allowed to access key 'id' of 'project_log'","position":-1.25,"last_edited":1459271395127,"task_id":"0955918b-95d7-4875-85f4-9da2b94e745a"}
{"desc":"#now #0 #sync (1:00?)\nMake table option that causes hub to reject multiple identical writes.\n\nThis is just defensive against other bugs to reduce database load.","position":-1.375,"last_edited":1459271397909,"task_id":"63efd4ef-fe58-4fea-a4aa-0b94a8fdf792","done":1459271397498}
{"desc":"#1 #critical (1:30?)\nThis should be empty but due to a bug isn't:\n\n\ttail -f ~/logs/hub*.log |grep uniq","position":1,"last_edited":1459272454746,"task_id":"8bdcc0da-0682-4a8b-9462-a8fa0f49d080"}
{"desc":"#0 (0:30?)\nJupyter files in the notifications are still wrong.  Still.","position":0.5,"last_edited":1459275956031,"task_id":"74a99008-4feb-4396-8ca4-ceed79905b1f"}