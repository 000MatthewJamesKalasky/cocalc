{"desc":"#0 #critical #f1 (1:00?)\nInvoice download is broken!\n\nhttps://cloud.sagemath.com/invoice/sagemathcloud-william_a__stein-receipt-2016-03-28-in_17u1mGGbwvoRbeYxknzGboWn.pdf Failed to load resource: the server responded with a status of 504 (Gateway Time-out)\n\non web0 (didn't affect hsy, only me, possibly because new transaction done via stripe web ui):\n\n```\n/home/salvus/logs/hub1.log-4382549-2016-03-28T14:56:40.134Z - debug: Uncaught exception: Error: Stripe: I require argument \"id\", but I got: null\n/home/salvus/logs/hub1.log-4382550-2016-03-28T14:56:40.235Z - debug: Error: Stripe: I require argument \"id\", but I got: null\n/home/salvus/logs/hub1.log-4382551-  at Object.retrieve (/home/salvus/smc/src/smc-hub/node_modules/stripe/lib/StripeMethod.js:47:15)\n/home/salvus/logs/hub1.log-4382552-  at /home/salvus/smc/src/smc-hub/stripe-invoice.coffee:27:32\n/home/salvus/logs/hub1.log-4382553-  at /home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:713:13\n/home/salvus/logs/hub1.log-4382554-  at iterate (/home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:262:13)\n/home/salvus/logs/hub1.log-4382555-  at /home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:274:29\n/home/salvus/logs/hub1.log-4382556-  at /home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:44:16\n/home/salvus/logs/hub1.log-4382557-  at /home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:718:17\n/home/salvus/logs/hub1.log-4382558-  at /home/salvus/smc/src/smc-hub/node_modules/async/lib/async.js:167:37\n/home/salvus/logs/hub1.log-4382559-  at /home/salvus/smc/src/smc-hub/stripe-invoice.coffee:22:31\n/home/salvus/logs/hub1.log-4382560-  at [object Object]._onTimeout (/home/salvus/smc/src/smc-hub/node_modules/stripe/lib/StripeResource.js:87:34)\n/home/salvus/logs/hub1.log-4382561-  at tryOnTimeout (timers.js:224:11)\n/home/salvus/logs/hub1.log-4382562-  at Timer.listOnTimeout (timers.js:198:5)\n/home/salvus/logs/hub1.log-4382563-\n```","position":-1,"last_edited":1459271380080,"task_id":"caab1ee7-73bc-4ad8-a4e9-148c91895c1e","due_date":1459263487528,"done":1459271379639}
{"desc":"#course #0 (1:00?) (0:45)\nThe \"(has never used project)\" column in courses is wrong.  \n\nIt always says that no matter what.","position":0,"last_edited":1459278824911,"task_id":"5485acd0-7fce-4a6d-a056-fe98b887db8b","done":1459278824499}
{"desc":"#0 (1:00?) (0:17) #now\nrecompact table\n\n> danielmewes: The idea is to do something like this `r.db(...).table(...).update({dummy: null}, {durability: \"soft\"})` followed by `r.db(...).table(...).update({dummy: r.literal()}, {durability: \"soft\"})` to remove the `dummy` field again.\n\nimplement a command in rethink.coffee to do recompact, with a limit argument so we don't kill things.  then run on blobs.","position":-2,"last_edited":1459262021768,"task_id":"c824875d-c49d-456c-958a-488233523262","done":1459262021353}
{"desc":"#2 #sync (1:00?)\nmassive number of writes per second when synctable keeps trying to rewrite patches\n\n> There is definitely some bug in the new sync code causing some clients to write a huge number of times to the patches table. Run query_stats on come web hubs instantly indicates this (by some huge set:n counts). So it will likely be easy to fix when I get time (probably tonight - definitely tomorrow). This will greatly reduce the db load from what it is now.","position":-1.5,"last_edited":1459281659475,"task_id":"75eca34a-dce2-49e4-ab97-17862833b87d"}
{"desc":"#1 (0:45?)\nsaw this in my console\n\n    invalid client query: not allowed to access key 'id' of 'project_log'; query={\"project_log\":{\"id\":\"6460ec8b-fa4b-437a-9d58-31643af1a1fb\",\"project_id\":\"369491f1-9b8a-431c-8cd0-150dd15f7b11\",\"account_id\":\"3c40513b-7e7c-450c-aa13-bf4f3411cf33\",\"time\":\"2015-10-09T11:17:22.439Z\",\"event\":{\"event\":\"open\",\"filename\":\"work/2015-10-09.sage-chat\",\"type\":\"chat\"}}}\n    client.js:2 _save('project_log') error: not allowed to access key 'id' of 'project_log'\n    \nIssue is server assigned; it should never get sent with synctable updates.  Need a way to enforce that (just make client-side synctable not set fields it doesn't have the right to set)    ","position":-1.25,"last_edited":1460124478745,"task_id":"0955918b-95d7-4875-85f4-9da2b94e745a"}
{"desc":"#now #0 #sync (1:00?)\nMake table option that causes hub to reject multiple identical writes.\n\nThis is just defensive against other bugs to reduce database load.","position":-1.375,"last_edited":1459271397909,"task_id":"63efd4ef-fe58-4fea-a4aa-0b94a8fdf792","done":1459271397498}
{"desc":"#1 #critical #bug (1:30?)\nThis should be empty but due to a bug isn't:\n\n\ttail -f ~/logs/hub*.log |grep uniq\n    \nThis might be fixed if all clients update.","position":1,"last_edited":1460124487259,"task_id":"8bdcc0da-0682-4a8b-9462-a8fa0f49d080"}
{"desc":"#0 (0:30?) (0:31) #now\nJupyter files in the notifications are still wrong.  Still.","position":0.5,"last_edited":1459280817290,"task_id":"74a99008-4feb-4396-8ca4-ceed79905b1f","done":1459280816880}
{"desc":"#3 (0:30?)\nslow markdown preview\n\nThe markdown preview gets really slow if the doc is big. I now understand that using underscore.debounce would trivially fix that problem – don’t update the preview until user stops typing for a couple seconds.","position":2,"last_edited":1460124512193,"task_id":"9040bcad-ce9c-4f6b-9b4d-31fa4d133e9c","done":1460124511781}
{"desc":"#0 (0:30?)  (0:24)\non project restart delete ~/.snapshots","position":3,"last_edited":1459453757565,"task_id":"b19f7f23-25e0-45f0-b820-db1d8b4271ab","done":1459453757155}
{"desc":"#0 (0:30?) (0:22)\nmake \"delete output\" not apply to any cell with hidden input.","position":4,"last_edited":1459452126041,"task_id":"8f46b1c1-c9e5-4135-99c1-e3e50c75b683","done":1459452125470}
{"desc":"#1 (1:00?)\ntime anomalies remain\n\n- My project list shows that I edited 'The Sandbox' recently, but I haven't.\n- The log has \"Cody Ryu opened .test.sagews.sage-history 100 years from now\" in it -- maybe the log should use the server time instead, now that it is sync'd.","position":5,"last_edited":1459449904803,"task_id":"1f553544-98ca-45bd-b75c-e0f940020530"}
{"desc":"#1(1:00?) #bug\nterminals keep dieing for no good reason\n\nwhy???","position":1.5,"last_edited":1459992569586,"task_id":"d5da1382-5a92-4e04-92cf-97a976af1a90"}
{"desc":"#1\nevery tab change calls project ls.  Why?","position":1.25,"last_edited":1460001266310,"task_id":"09b233ac-8bfc-4c52-a3b7-82a11baf9958"}
{"desc":"#0 #bug #critical\nsync disaster involving saving\n\nsometimes project gets in a state where files won't save to disk.\nOf course patches do save so open/close of file is ok and history is ok.\n\n- closing and opening the file on the client *does* fix things.\n\n- it seems like the backend instantly resets the save request to not save as the *backend* reconnects that sync table.\n\n- too hard to tell what exactly is happening because logging shortens things too much: need to raise a lot of debug logging from 200-ish to 400-ish.\n\n- here's what is happening: EVERYTHING is working perfectly, except what is being written is just wrong.  A slightly different version of the file is being written to disk.   The file is being changed -- it is just missing some patch.\n\n- in fact, everything is totally working perfectly and file is saving.  What is failing is for s.hash_of_saved_version() to be updated!\n\n- I think we are writing the request to save with a hash in it, then getting back the update to the save field with state:done but not applying that change for some reason.\n\n- What is **really happening**.  The client changefeed for syncstring_table is not working.  We are getting no updates for some reason this breaks knowing that the save worked.  And, in fact, `s._syncstring_table._id` is not in the output of `smc.client.query_get_changefeed_ids({cb:function(a,b){window.a=a;window.b=b}})`.  So the nightmare scenario that I haven't robustly dealt with, namely that a synctable thinks it is getting updated but it isn't... needs to get dealt with better!\n\n- Doing this fixed it: `delete s._syncstring_table._state; s._syncstring_table._reconnect()`\n\nSo... I'm going to put a check in for all synctables.  Every n minutes, while the client is connected to the server, it will simply check that the particular changefeed id is valid.  If not, it does `delete s._syncstring_table._state; s._syncstring_table._reconnect()`.\n\nPossibly better: once every k seconds the hub just sends (without any request) to each connected client their current valid changefeeds.  The clients then cache this info and the changefeeds themselves use them to verify that they are still valid or reconnect otherwise.  The client does an `@emit('changefeed_ids', map from valid ids)`, and the syncstrings could all subscribe to that event.\n\nAlternatively, whenever a synctable attempts a write it includes the changefeed id, and if that changefeed isn't valid, the write fails with 'no_changefeed'.  On the client side, if a write fails with 'no_changefeed', it will reset the changefeed.\n\nAnother idea: if client tries to write a change and get *nothing* back from server after k seconds, reset changefeed.\n","position":1.125,"last_edited":1460008665686,"task_id":"1ea68d09-eac5-4da7-a495-ed276669e5ad","done":1460008665263}
{"desc":"#1 (0:45?) #critical\ncreating new file via open in terminal creates incorrectly read-only file!","position":1.1875,"last_edited":1460124491092,"task_id":"9cf02bc5-772d-44bb-b775-6d461b333106"}
{"desc":"#1 (1:00?) #critical\nHave a way to force clients to refresh if they aren't sufficiently up to date.  \n\nOtherwise basically disconnect them.","position":0.75,"last_edited":1460070472149,"task_id":"d844ea05-f82d-4e53-b39d-b442d65cc803"}
{"desc":"#1 #sagews #critical #bug (0:30?)\nif output is hidden and evaluate, it gets shown until first output appears.  Is totally wrong.","position":1.21875,"last_edited":1460124496148,"task_id":"ca4357cc-f5df-46aa-8f39-de6a25951669"}
{"desc":"#1 #sync (2:00?)\nadd copy and revert buttons to time travel\n\nhttps://github.com/sagemathinc/smc/issues/500","position":-1.125,"last_edited":1460070464270,"task_id":"4038ecfd-cc1c-48ac-8790-ceeb1f77ca3c"}
{"desc":"#1 #sync (1:00?)\nadd something to the ui to indicate the difference between saved to the database and saved to disk.","position":-1.1875,"last_edited":1460124482363,"task_id":"46608900-12a5-40de-b4f2-411b9d538f4a"}
{"desc":"#0 #changefeeds (1:30?) (1:42)\nimplement additional \"heartbeat\" idea to ensure robustness of client side changefeeds.\n\n- [x]  periodically update a list of valid changefeed ids, via a message from the server\n- [x] clients use this information to check that their changefeeds are valid (via an event)\n- [x] if not, they reconnect\n\n\nDeploy: \n - update version\n - update hubs\n - update compute servers!","position":1.0625,"last_edited":1460131902430,"task_id":"c8fb4317-b35b-4c57-83d2-b9b637cc85c5","done":1460131902017}
{"desc":"#0 (0:45?) #syncstring\ngetting this in my log:\n\n\tfailed to save snapshot -- you may not change the sent time once it is set\n    \nDid I break snapshots?","position":1.234375,"last_edited":1460174239629,"task_id":"d92a27ce-35bc-4636-8e1f-036b7f986b8b","done":1460174239220}
{"desc":"#0 #critical #synctable\nuniqueness\n\nthings I wish:\n\n- limit the number of changefeeds per client to 300 (say)\n- make it so client can have at most one copy of a given changefeed:\n  - dedup on client\n  - on server don't *allow* more than one\n- force clients to upgrade\n- when client gets list of its changefeeds, any it doesn't actually care about should get a \"cancel_changefeed\" message.\n\nFor now:\n\n- raise the max reconnect time for changefeeds from 20s to something bigger, just to reduce the load.  This should never be needed at all...\n- if number of changefeeds for a specific clients exceeds a number (maybe 250), just cancel\n\nSo:\n\nBut I also have a real plan, which will involve:\n\n  - ensuring exact sync between which changefeeds the client has and\nthe server thinks it has\n\n  - limiting the number of changefeeds a client is allowed to create\n(maybe automatically killing old ones)\n\n  - forcing clients to upgrade (basically allow nothing but them\nshowing a \"you must update\" message)\n\n  - deduping changfeeds on both sides, so a given changefeed (for a\nquery) can only be created once on the client (or server) to avoid\nsome small inefficiencies.\n\nI'll get up early tomorrow and work on this.","position":-1.4375,"last_edited":1460178699705,"task_id":"e422480d-5aa3-4b82-b475-6f1f9552904d"}