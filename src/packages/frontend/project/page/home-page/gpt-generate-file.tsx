/*
 *  This file is part of CoCalc: Copyright © 2023 Sagemath, Inc.
 *  License: AGPLv3 s.t. "Commons Clause" – see LICENSE.md for details
 */

import { Button, Input, Radio, RadioChangeEvent } from "antd";
import { useState, useEffect } from "react";

import {
  redux,
  useActions,
  useTypedRedux,
} from "@cocalc/frontend/app-framework";
import {
  Icon,
  Markdown,
  Paragraph,
  Text,
  Title,
} from "@cocalc/frontend/components";
import OpenAIAvatar from "@cocalc/frontend/components/openai-avatar";
import ProgressEstimate from "@cocalc/frontend/components/progress-estimate";
import { webapp_client } from "@cocalc/frontend/webapp-client";
import { Block } from "./block";

const LANGS = {
  python: "Python",
  r: "R",
  sage: "SageMath",
} as const;

// TODO instead of hardcoding, this should be based on the actual available kernels
const KERNELS = {
  python: "python3",
  r: "ir",
  sage: "sage-9.8",
} as const;

type Languages = keyof typeof LANGS;

const LANG_OPTIONS: { label: string; value: Languages }[] = [
  { label: "Python 3", value: "python" },
  { label: "R Statistics", value: "r" },
  { label: "SageMath", value: "sage" },
];

const PLACEHOLDERS: { [key in Languages]: string } = {
  python:
    "Fit a statistical model to this time-series of monthly values: 72, 42, 63, 44, 46, 51, 47, 39, 21, 31, 19, 22. Then plot it with extrapolation.",
  r: "Fit a statistical model to these monthly values: 72, 42, 63, 44, 46, 51, 47, 39, 21, 31, 19, 22. Then plot it.",
  sage: "Generate a random 5x5 matrix over GF_2 and calculate its determinant.",
} as const;

const LANG_EXTRA: { [key in Languages]: string } = {
  python:
    "Prefer using the standard library or the following packages: numpy, matplotlib, pandas, scikit-learn, sympy, scipy, sklearn, seaborn, statsmodels, nltk, tensorflow, pytorch, pymc3, dask, numba, bokeh",
  r: "Prefer using the standard library or the following: tidyverse, tidyr, stringr, dplyr, data.table, ggplot2, car, mgcv, lme4, nlme, randomForest, survival, glmnet",
  sage: "Use all functions in SageMath.",
} as const;

export function GPTGenerateFile(props: { project_id: string }) {
  const { project_id } = props;

  const projectActions = useActions({ project_id });
  const current_path = useTypedRedux({ project_id }, "current_path");

  const [lang, setLang] = useState<Languages>("python");
  const [prompt, setPrompt] = useState<string>("");
  const [querying, setQuerying] = useState<boolean>(false);
  const [error, setError] = useState<string>("");
  const [placeholder, setPlaceholder] = useState<string>("");

  useEffect(() => {
    setPlaceholder(PLACEHOLDERS[lang]);
    if (!prompt || Object.values(PLACEHOLDERS).includes(prompt))
      setPrompt(PLACEHOLDERS[lang]);
  }, [lang]);

  async function generate() {
    setQuerying(true);

    const langName = LANGS[lang];
    const input = `Explain directly and to the point, how to compute the following task in the programming language "${langName}". ${LANG_EXTRA[lang]}. Break down all blocks of code into small snippets. Explain each snippet with a concise description. Skip formalities. Do not add a summary. Do not put it all together.\n\n${prompt}`;

    try {
      const raw = await webapp_client.openai_client.chatgpt({
        input,
        project_id,
        model: "gpt-3.5-turbo",
      });
      await writeNotebook(lang, raw);
    } catch (err) {
      setError(
        `Error: ${err}\n\nOpenAI [status](https://status.openai.com) and [downdetector](https://downdetector.com/status/openai).`
      );
    } finally {
      setQuerying(false);
    }
  }

  /**
   * The text string contains markdown text with code blocks. This split this into cells of type markdown and code.
   */
  function splitCells(
    text: string
  ): { cell_type: "markdown" | "code"; source: string[] }[] {
    const ret: { cell_type: "markdown" | "code"; source: string[] }[] = [
      {
        cell_type: "markdown",
        source: [
          `# ChatGPT generated notebook\n\n`,
          `This notebook has been generated by [ChatGPT](https://chatgpt.cocalc.com) using the prompt:\n\n`,
          prompt
            .split("\n")
            .map((line) => `> ${line}`)
            .join("\n") + "\n\n",
        ],
      },
    ];

    let lines = text.split("\n");
    let cell_type: "markdown" | "code" = "markdown";
    let source: string[] = [];
    for (const line of lines) {
      if (line.startsWith("```")) {
        if (source.length > 0) {
          ret.push({ cell_type, source });
          source = [];
        }
        cell_type = cell_type == "markdown" ? "code" : "markdown";
      } else {
        // have to end each one with a newline, don't ask me why
        source.push(`${line}\n`);
      }
    }

    if (source.length > 0) {
      ret.push({ cell_type, source });
    }

    return ret;
  }

  function getTitle(prompt: string): string {
    return prompt
      .split("\n")
      .join("_")
      .replace(/[^a-zA-Z0-9 ]/g, "")
      .replace(/\s+/g, "_")
      .trim()
      .slice(0, 100);
  }

  function getTimestamp(): string {
    return new Date()
      .toISOString()
      .slice(0, 16)
      .replace(":", "")
      .replace("-", "")
      .replace("T", "-");
  }

  async function writeNotebook(lang: Languages, text: string): Promise<void> {
    // constructs a proto jupyter notebook the given kernel
    const nb = {
      cells: splitCells(text),
      metadata: {
        kernelspec: {
          language: lang,
          name: KERNELS[lang],
          display_name: LANGS[lang],
        },
      },
    };
    const title = getTitle(prompt);
    const prefix = current_path ? `${current_path}/` : "";
    const timestamp = getTimestamp();
    const path = `${prefix}${title}-${timestamp}.ipynb`;

    // we don't check if the file exists, because the prompt+timestamp should be unique enough
    await webapp_client.project_client.write_text_file({
      project_id,
      path,
      content: JSON.stringify(nb, null, 2),
    });
    projectActions?.open_file({
      path,
      foreground: true,
    });
  }

  if (!redux.getStore("projects").hasOpenAI(project_id)) {
    return null;
  }

  return (
    <Block style={{ padding: "0 15px" }}>
      <Title level={2}>
        <OpenAIAvatar size={24} /> GPT Notebook Generator
      </Title>
      <Paragraph>
        Generate a Jupyter Notebook using the following programming language:
      </Paragraph>
      <Paragraph>
        <Radio.Group
          options={LANG_OPTIONS}
          onChange={({ target: { value } }: RadioChangeEvent) =>
            setLang(value as Languages)
          }
          value={lang}
          size="middle"
          optionType="button"
          buttonStyle="solid"
        />
      </Paragraph>
      <Paragraph>
        Explain its content with as many details you can think of:
      </Paragraph>
      <Paragraph>
        <Input.TextArea
          rows={4}
          maxLength={1000}
          placeholder={placeholder}
          value={prompt}
          onChange={({ target: { value } }) => setPrompt(value)}
        />
        <br />
        <Text type="secondary">
          For example: <i>"{placeholder}"</i>
        </Text>
      </Paragraph>
      <Paragraph>
        <Button type="primary" onClick={generate} disabled={querying}>
          <Icon name="jupyter" /> Generate Notebook
        </Button>
      </Paragraph>
      {!error && querying && <ProgressEstimate seconds={30} />}
      {error && (
        <Paragraph>
          <Markdown value={error} />
        </Paragraph>
      )}
    </Block>
  );
}
