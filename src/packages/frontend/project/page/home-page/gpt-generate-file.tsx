/*
 *  This file is part of CoCalc: Copyright © 2023 Sagemath, Inc.
 *  License: AGPLv3 s.t. "Commons Clause" – see LICENSE.md for details
 */

import { Alert, Button, Input, Radio, RadioChangeEvent } from "antd";
import { useState, useEffect } from "react";
import getKernelSpec from "@cocalc/frontend/jupyter/kernelspecs";
import type { KernelSpec } from "@cocalc/frontend/jupyter/types";
import {
  redux,
  useActions,
  useTypedRedux,
} from "@cocalc/frontend/app-framework";
import {
  A,
  Icon,
  Loading,
  Markdown,
  Paragraph,
  Text,
  Title,
  HelpIcon,
} from "@cocalc/frontend/components";
import OpenAIAvatar from "@cocalc/frontend/components/openai-avatar";
import ProgressEstimate from "@cocalc/frontend/components/progress-estimate";
import { webapp_client } from "@cocalc/frontend/webapp-client";
import { Block } from "./block";

const LANGS = {
  python: "Python",
  r: "R",
  sage: "SageMath",
} as const;

// TODO instead of hardcoding, this should be based on the actual available kernels
const KERNELS = {
  python: "python3",
  r: "ir",
  sage: "sage-9.8",
} as const;

type Languages = keyof typeof LANGS;

const LANG_OPTIONS: { label: string; value: Languages }[] = [
  { label: "Python 3", value: "python" },
  { label: "R Statistics", value: "r" },
  { label: "SageMath", value: "sage" },
];

const PLACEHOLDERS: { [key in Languages]: string } = {
  python:
    "Fit a statistical model to this time-series of monthly values: 72, 42, 63, 44, 46, 51, 47, 39, 21, 31, 19, 22. Then plot it with extrapolation.",
  r: "Fit a statistical model to these monthly values: 72, 42, 63, 44, 46, 51, 47, 39, 21, 31, 19, 22. Then plot it.",
  sage: "Generate a random 5x5 matrix over GF_2 and calculate its determinant.",
} as const;

const LANG_EXTRA: { [key in Languages]: string } = {
  python:
    "Prefer using the standard library or the following packages: numpy, matplotlib, pandas, scikit-learn, sympy, scipy, sklearn, seaborn, statsmodels, nltk, tensorflow, pytorch, pymc3, dask, numba, bokeh",
  r: "Prefer using the standard library or the following: tidyverse, tidyr, stringr, dplyr, data.table, ggplot2, car, mgcv, lme4, nlme, randomForest, survival, glmnet",
  sage: "Use all functions in SageMath.",
} as const;

export function GPTGenerateFile(props: { project_id: string }) {
  const { project_id } = props;
  const [kernelSpec, setKernelSpec] = useState<KernelSpec[] | null | string>(
    null
  );
  useEffect(() => {
    (async () => {
      try {
        setKernelSpec(null);
        setKernelSpec(await getKernelSpec(project_id));
      } catch (err) {
        setKernelSpec(
          "Unable to load Jupyter kernels.  Make sure the project is running and Jupyter is installed."
        );
      }
    })();
  }, [project_id]);

  const projectActions = useActions({ project_id });
  const current_path = useTypedRedux({ project_id }, "current_path");

  const [lang, setLang] = useState<Languages>("python");
  const [prompt, setPrompt] = useState<string>("");
  const [querying, setQuerying] = useState<boolean>(false);
  const [error, setError] = useState<string>("");
  const [placeholder, setPlaceholder] = useState<string>("");

  useEffect(() => {
    setPlaceholder(PLACEHOLDERS[lang]);
    if (!prompt || Object.values(PLACEHOLDERS).includes(prompt))
      setPrompt(PLACEHOLDERS[lang]);
  }, [lang]);

  if (kernelSpec == null) {
    return <Loading />;
  }

  if (typeof kernelSpec == "string") {
    return (
      <Alert message="Error" description={kernelSpec} type="error" showIcon />
    );
  }

  async function generate() {
    setQuerying(true);

    const langName = LANGS[lang];
    const input = `Explain directly and to the point, how to compute the following task in the programming language "${langName}". ${LANG_EXTRA[lang]}. Break down all blocks of code into small snippets and wrap each one in triple backticks. Explain each snippet with a concise description. Skip formalities. Do not add a summary. Do not put it all together.\n\n${prompt}`;

    try {
      const raw = await webapp_client.openai_client.chatgpt({
        input,
        project_id,
        model: "gpt-3.5-turbo",
      });
      await writeNotebook(lang, raw);
    } catch (err) {
      setError(
        `Error: ${err}\n\nOpenAI [status](https://status.openai.com) and [downdetector](https://downdetector.com/status/openai).`
      );
    } finally {
      setQuerying(false);
    }
  }

  /**
   * The text string contains markdown text with code blocks. This split this into cells of type markdown and code.
   */
  function splitCells(
    text: string
  ): { cell_type: "markdown" | "code"; source: string[] }[] {
    const ret: { cell_type: "markdown" | "code"; source: string[] }[] = [
      {
        cell_type: "markdown",
        source: [
          `# ChatGPT generated notebook\n\n`,
          `This notebook has been generated by [ChatGPT](https://chat.openai.com/) using the prompt:\n\n`,
          prompt
            .split("\n")
            .map((line) => `> ${line}`)
            .join("\n") + "\n\n",
        ],
      },
    ];

    let lines = text.split("\n");
    let cell_type: "markdown" | "code" = "markdown";
    let source: string[] = [];
    for (const line of lines) {
      if (line.startsWith("```")) {
        if (source.length > 0) {
          ret.push({ cell_type, source });
          source = [];
        }
        cell_type = cell_type == "markdown" ? "code" : "markdown";
      } else {
        // have to end each one with a newline, don't ask me why
        source.push(`${line}\n`);
      }
    }

    if (source.length > 0) {
      ret.push({ cell_type, source });
    }

    return ret;
  }

  function getTitle(prompt: string): string {
    return prompt
      .split("\n")
      .join("_")
      .replace(/[^a-zA-Z0-9 ]/g, "")
      .replace(/\s+/g, "_")
      .trim()
      .slice(0, 100);
  }

  function getTimestamp(): string {
    return new Date()
      .toISOString()
      .slice(0, 16)
      .replace(":", "")
      .replace("-", "")
      .replace("T", "-");
  }

  async function writeNotebook(lang: Languages, text: string): Promise<void> {
    // constructs a proto jupyter notebook the given kernel
    const nb = {
      cells: splitCells(text),
      metadata: {
        kernelspec: {
          language: lang,
          name: KERNELS[lang],
          display_name: LANGS[lang],
        },
      },
    };
    const title = getTitle(prompt);
    const prefix = current_path ? `${current_path}/` : "";
    const timestamp = getTimestamp();
    const path = `${prefix}${title}-${timestamp}.ipynb`;

    // we don't check if the file exists, because the prompt+timestamp should be unique enough
    await webapp_client.project_client.write_text_file({
      project_id,
      path,
      content: JSON.stringify(nb, null, 2),
    });
    projectActions?.open_file({
      path,
      foreground: true,
    });
  }

  if (!redux.getStore("projects").hasOpenAI(project_id)) {
    return null;
  }

  function info() {
    return (
      <HelpIcon title="OpenAI GPT">
        <Paragraph style={{ maxWidth: "300px" }}>
          This tool sends your message to{" "}
          <A href={"https://chat.openai.com/"}>ChatGPT</A> in order to get a
          well structured answer back. This reply will be post-processed and
          turned into a Jupyter Notebook. When it opens up, check the result and
          evaluate the cells. Not everything might work on first try, but it
          should give you some ideas towards your given task. If it does not
          work, try again with a better prompt!
        </Paragraph>
      </HelpIcon>
    );
  }

  return (
    <Block style={{ padding: "0 15px" }}>
      <Title level={2}>
        <OpenAIAvatar size={30} /> GPT Notebook Generator {info()}
      </Title>
      <Paragraph>
        Generate a Jupyter Notebook using the following programming language:
      </Paragraph>
      <Paragraph>
        <Radio.Group
          disabled={querying}
          options={LANG_OPTIONS}
          onChange={({ target: { value } }: RadioChangeEvent) =>
            setLang(value as Languages)
          }
          value={lang}
          size="middle"
          optionType="button"
          buttonStyle="solid"
        />
      </Paragraph>
      <Paragraph>
        Provide a detailed description of the content. Include as many relevant
        details as possible.
      </Paragraph>
      <Paragraph>
        <Input.TextArea
          rows={4}
          maxLength={1000}
          placeholder={placeholder}
          value={prompt}
          disabled={querying}
          onChange={({ target: { value } }) => setPrompt(value)}
        />
        <br />
        <Text type="secondary">
          For example: <i>"{placeholder}"</i>
        </Text>
      </Paragraph>
      <Paragraph>
        <Button type="primary" onClick={generate} disabled={querying}>
          <Icon name="jupyter" /> Generate Notebook
        </Button>
      </Paragraph>
      {!error && querying && <ProgressEstimate seconds={30} />}
      {error && (
        <Paragraph>
          <Markdown value={error} />
        </Paragraph>
      )}
    </Block>
  );
}
